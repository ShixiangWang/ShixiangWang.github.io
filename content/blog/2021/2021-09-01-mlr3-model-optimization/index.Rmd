---
title: mlr3（三）模型优化
author: 王诗翔
date: '2021-09-01'
slug: mlr3-model-optimization
categories:
  - Blog
tags:
  - R
  - mlr3
  - 机器学习
rmd_source: ''
keywords: rstats
editor_options:
  chunk_output_type: console
---

<!-- Links -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 7, fig.height = 6
)

options(htmltools.dir.version = TRUE)

# If using lightbox for plots, set `fig.show = FALSE`
# Usage: lightbox_img(knitr::fig_chunk("chunk-name", "png"))
lightbox_img <- function(url, alt = "", caption = "", preview = TRUE) {
  if (preview) {
    glue::glue(
      '<a href="{url}" data-featherlight="image">
      <div class="figure">
      <img src="{url}" alt="{alt}">
      <p class="caption">{caption}</p>
      </div>
      </a>
      '
    )
  } else {
    if (alt == "") alt <- "static image of the plot"
    glue::glue('<a href="{url}" data-featherlight="image">{alt}</a>')
  }
}
```

来源：<https://mlr3book.mlr-org.com/optimization.html>

**模型优化**

机器学习算法为其超参数设置了默认值。不管怎样，用户需要更改这些超参数，以在给定的数据集上实现最佳性能。不建议手动选择超参数值，因为这种方法很少能获得最佳性能。为了证实所选超参数（=调优）的有效性，建议进行数据驱动的优化。为了优化机器学习算法，必须指定（1）搜索空间，（2）优化算法(又称调优方法)，（3）评估方法，即重采样策略，（4）性能度量。

总而言之，关于调优的小节介绍：

- 进行经验超参数选择
- 选择优化算法
- 简洁地指定搜索空间
- 触发调优
- 自动调优

本小节还需要包mlr3tuning，这是一个支持超参数调优的扩展包。

**特征选择**

本章的第二部分介绍特征选择，也称为变量选择。特征选择是寻找数据相关特征子集的过程。执行选择的一些原因：

- 增强模型的可解释性
- 加速模型拟合
- 通过降低数据中的噪声来提高学习性能

在本文中，我们主要集中在最后一个方面。有不同的方法来识别相关的特征。在特征选择的分章中，我们强调了三种方法：

- 运用过滤算法根据分数独立地选择特征
- 根据变量重要性过滤选择特征
- 包装器方法迭代地选择特性以优化性能度量

注意，过滤器不需要学习器。变量重要性过滤器需要一个学习器，该学习器在训练时可以计算特征的重要性值。获得的重要值可用于数据子集，然后可用于训练学习器。包装器方法可以用于任何学习器，但需要对学习器进行多次训练。


**嵌套重采样**

为了更好地估计泛化性能并避免数据泄漏，外部（性能）和内部（调优/特征选择）重采样过程都是必要的。本章将讨论以下特点：

- 嵌套重采样中的内重采样和外重采样策略
- 嵌套重采样的执行
- 执行重采样迭代的评估

本小节将提供如何实现嵌套重采样的说明，包括mlr3中的内重采样和外重采样。

## 超参数调优

超参数是机器学习模型的二阶参数，虽然在模型估计过程中往往没有明确优化，但会对模型的结果和预测性能产生重要影响。通常，超参数在训练模型之前是固定的。但是，由于模型的输出可能对超参数的规范很敏感，因此通常建议对哪些超参数设置可以产生更好的模型性能做出明智的决定。在许多情况下，超参数设置可能是预先选择的，但在将模型拟合到训练数据上之前，尝试不同的设置可能是有利的。这个过程通常被称为模型“调优”。

超参数调优是通过mlr3tuning扩展包支持的。下面是这个过程的说明：

![](https://mlr3book.mlr-org.com/images/tuning_process.svg)

mlr3tuning的核心是R6类：

TuningInstanceSingleCrit，TuningInstanceMultiCrit：这两个类描述调优问题并存储结果。

Tuner：这个类是调优算法实现的基类。

### TuningInstance\* 类

下面的小节审查了皮马印度糖尿病数据集上的简单分类树的优化。

```{r}
library("mlr3verse")
task = tsk("pima")
print(task)
```

我们使用rpart中的分类树，并选择我们想要调优的超参数的子集。这通常被称为“调优空间”。

```{r}
learner = lrn("classif.rpart")
learner$param_set
```

这里，我们选择调优两个参数：

- 复杂度 `cp`
- 终止准则 `minsplit`

调优空间需要有边界，因此需要设置上下限：

```{r}
search_space = ps(
  cp = p_dbl(lower = 0.001, upper = 0.1),
  minsplit = p_int(lower = 1, upper = 10)
)
search_space
```

接下来，我们需要明确如何评估性能。为此，我们需要选择重采样策略和性能度量。

```{r}
hout = rsmp("holdout")
measure = msr("classif.ce")
```

最后，必须选择可用的预算来解决这个调优实例。这是通过选择一个可用的终结者：

- 在给定时间后终止 TerminatorClockTime
- 在给定的迭代量之后终止 TerminatorEvals
- 在达到特定性能后终止 TerminatorPerfReached
- 当优化没有改善时终止 TerminatorStagnation
- 以ALL或ANY的方式组合上述内容 TerminatorCombo

在这篇简短的介绍中，我们指定了20次计算的预算，然后把所有东西放在一个TuningInstanceSingleCrit中：

```{r}
library("mlr3tuning")

evals20 = trm("evals", n_evals = 20)

instance = TuningInstanceSingleCrit$new(
  task = task,
  learner = learner,
  resampling = hout,
  measure = measure,
  search_space = search_space,
  terminator = evals20
)
instance
```

要开始调优，我们仍然需要选择应该如何进行优化。换句话说，我们需要通过Tuner类选择优化算法。


### Tuner 类

以下算法目前在mlr3调优中实现：

- 网格搜索 TunerGridSearch
- 随机搜索 TunerRandomSearch
- 广义模拟退火 TunerGenSA
- 非线性最优化 TunerNLoptr

在本例中，我们将使用一个简单的网格搜索，网格分辨率为5。

```{r}
tuner = tnr("grid_search", resolution = 5)
```


由于我们只有数值参数，TunerGridSearch将在各自的上界和下界之间创建一个等距网格。由于我们有两个分辨率为5的超参数，二维网格由5^2=25个配置组成。每个配置都作为先前定义的学习器的超参数设置，然后使用提供的重采样将其拟合到任务上。所有配置都将由调优器检查（以随机顺序），直到所有配置都被评估或终结者发出耗尽预算的信号。

### 触发调优

要开始调优，只需将TuningInstanceSingleCrit传递给初始化的Tuner的`$optimize()`方法。调谐器的工作过程如下：

1. Tuner建议至少一个超参数配置（Tuner可能建议多个点来改善并行性，这可以通过设置batch_size进行控制）。
2. 对于每个配置，给定的学习器使用提供的重采样将其分派到任务上。所有计算都存储在TuningInstanceSingleCrit的存档中。
3. 如果预算耗尽，终结者会被询问。如果预算未耗尽，则使用第一步重新启动，直到耗尽为止。
4. 确定具有最佳观察性能的配置。
5. 在实例对象中存储最佳配置结果。可以从实例访问最佳超参数设置(`$result_learner_param_vals`)和相应的测量性能(`$result_y`)。

```{r}
tuner$optimize(instance)
```

```{r}
instance$result_learner_param_vals
instance$result_y
```

我们可以调查所有进行的重采样，因为它们存储在TuningInstanceSingleCrit的存档中，可以使用`as.data.table()`访问：

```{r}
as.data.table(instance$archive)
```

总之，在终结者停止调优之前，网格搜索以随机顺序评估20/25个不同的网格配置。

相关的重采样迭代可以在BenchmarkResult中访问:

```{r}
instance$archive$benchmark_result
```


uhash列将重新采样迭代链接到`instance$archive$data`中已评估的配置。例如，可以对所包含的ResampleResults进行不同的评分。

```{r}
instance$archive$benchmark_result$score(msr("classif.acc"))
```

现在，优化的超参数可以使用之前创建的Learner，设置返回的超参数，并在完整的数据集上训练它。

```{r}
learner$param_set$values = instance$result_learner_param_vals
learner$train(task)
```

经过训练的模型现在可以用来对外部数据进行预测。注意，应该避免根据任务中出现的观察结果进行预测。模型在调优期间已经看到了这些观察结果，因此结果在统计上是有偏差的。因此，由此产生的性能度量将过于乐观。相反，为了获得当前任务的统计无偏性能估计，需要嵌套重采样。

### 自动化调优

AutoTuner包装了一个学习器，并通过对给定超参数集的自动调优增强了它。因为AutoTuner本身继承自Learner基类，所以它可以像任何其他学习器一样使用。类似于前面的小节，创建了一个新的分类树学习器。这个分类树学习器使用内部重采样(holdout)自动调整参数cp和minsplit。我们创建了一个允许10次计算的终止符，并使用一个简单的随机搜索作为调优算法：

```{r}
learner = lrn("classif.rpart")
search_space = ps(
  cp = p_dbl(lower = 0.001, upper = 0.1),
  minsplit = p_int(lower = 1, upper = 10)
)
terminator = trm("evals", n_evals = 10)
tuner = tnr("random_search")

at = AutoTuner$new(
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  search_space = search_space,
  terminator = terminator,
  tuner = tuner
)
at

```

我们现在可以像使用其他学习器一样使用学习器，调用`$train()`和`$predict()`方法。

```{r}
at$train(task)
```

我们也可以将它传递给`resample()`和`benchmark()`。这被称为嵌套重采样，下一章将对此进行讨论。

## 搜索空间调优

在运行优化时，务必告知优化算法哪些超参数是有效的。这里每个超参数的名称、类型和有效范围都很重要。所有这些信息都与ParamSet类的对象进行通信，ParamSet类在paradox中定义。虽然可以使用它的`$new`构造函数创建paramset对象，但是使用ps快捷键要短得多，可读性也强得多，这将在这里介绍。

注意，ParamSet对象存在于两个上下文中。首先，参数集对象用于定义学习器（和其他对象）的有效参数设置空间。其次，它们用于定义用于调优的搜索空间。我们主要对后者感兴趣。例如，我们可以考虑rpart学习器classif的minsplit参数。与学习器相关联的参数集有一个下限，但没有上限。但是，为了优化该值，必须给出一个上下限，因为优化搜索空间需要有界。对于初学者或PipeOp对象，通常使用“无界”参数集。然而，在这里，我们将主要关注于创建可用于调优的“有边界的”参数集。有关使用参数集为用例定义参数范围的更多细节，请参阅深入的paradox章节。

### 创建 ParamSet

一个空的ParamSet——还不是很有用——可以只用ps调用来构造：

```{r}
library("mlr3verse")

search_space = ps()
print(search_space)
```

ps接受被转换为参数的命名参数。classif.svm学习器可能的搜索空间举例：

```{r}
search_space = ps(
  cost = p_dbl(lower = 0.1, upper = 10),
  kernel = p_fct(levels = c("polynomial", "radial"))
)
print(search_space)
```

可用的参数构造器：

| Constructor |             Description              |            Is bounded?             |                       Underlying Class                       |
| :---------: | :----------------------------------: | :--------------------------------: | :----------------------------------------------------------: |
|   `p_dbl`   |   Real valued parameter (“double”)   | When `upper` and `lower` are given | [`ParamDbl`](https://paradox.mlr-org.com/reference/ParamDbl.html) |
|   `p_int`   |          Integer parameter           | When `upper` and `lower` are given | [`ParamInt`](https://paradox.mlr-org.com/reference/ParamInt.html) |
|   `p_fct`   | Discrete valued parameter (“factor”) |               Always               | [`ParamFct`](https://paradox.mlr-org.com/reference/ParamFct.html) |
|   `p_lgl`   |     Logical / Boolean parameter      |               Always               | [`ParamLgl`](https://paradox.mlr-org.com/reference/ParamLgl.html) |
|   `p_uty`   |          Untyped parameter           |               Never                | [`ParamUty`](https://paradox.mlr-org.com/reference/ParamUty.html) |


这些构造函数接收以下的参数：

- lower, upper：上下边界
- levels：因子水平
- trafo：转换函数
- depends：依赖
- tags：有关参数的进一步信息，例如由 hyperband 使用的参数
- default：值对应于未给出参数时的默认行为。不用于调优搜索空间
- special_vals：除通常接受的参数值外的有效值。不用于调优搜索空间
- custom_check：检查给定给p_uty的值是否有效的函数。不用于调优搜索空间。

lower、upper或level形参总是在各自构造函数的第一个(或第二个)位置，所以最好在定义ParamSet时省略它们，以提高简洁性：

```{r}
search_space = ps(cost = p_dbl(0.1, 10), kernel = p_fct(c("polynomial", "radial")))
```

### 转换

我们可以使用paradox函数generate_design_grid来查看网格搜索将评估的值。(我们在这里使用`rbindlist()`，因为`$transpose()`的结果是一个更难读的列表。另一方面，如果我们没有使用`$transpose()`，我们在这里研究的转换就不会应用。)

```{r}
library("data.table")
rbindlist(generate_design_grid(search_space, 3)$transpose())
```

我们注意到cost参数是线性的。然而，我们假设，0.1和1之间的成本差异应该具有与1和10之间的差异类似的效果。因此，在对数尺度上调整它更有意义。这是通过使用转换(trafo)完成的。这是一个被调谐器采样后应用于参数的函数。我们可以在对数尺度上调整cost，方法是在线性尺度上抽样[- 1,1]，然后从这个值计算10^x。

```{r}
search_space = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("polynomial", "radial"))
)
rbindlist(generate_design_grid(search_space, 3)$transpose())
```

甚至可以将另一个转换作为一个整体附加到ParamSet上，在执行单个参数的转换之后执行该转换。它通过.extra_trafo参数给出，应该是一个带有参数x和param_set的函数，接受x中的参数值列表并返回修改后的列表。此转换可以访问评估的所有参数值，并通过交互修改它们。甚至可以添加或删除参数。(下面是一个有点傻的例子。)

```{r}
search_space = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("polynomial", "radial")),
  .extra_trafo = function(x, param_set) {
    if (x$kernel == "polynomial") {
      x$cost = x$cost * 2
    }
    x
  }
)
rbindlist(generate_design_grid(search_space, 3)$transpose())
```

搜索空间参数的可用类型是有限的：连续、整数、离散和逻辑标量。然而，有许多机器学习算法采用其他类型的参数，例如向量或函数。这些参数不能在搜索空间参数集中定义，通常在学习器的参数集中以 ParamUty的形式给出。在尝试对这些超参数进行调优时，需要执行更改参数类型的Transformation。

一个例子就是SVM的`class.weights`参数，它采用一个命名的类权重向量，每个目标类有一个条目。

```{r}
search_space = ps(
  class.weights = p_dbl(0.1, 0.9, trafo = function(x) c(spam = x, nonspam = 1 - x))
)
generate_design_grid(search_space, 3)$transpose()
```

### 自动化因子水平转换

一个常见的用例是必须指定一个应该全部尝试（或从其中取样）的值列表。有一种情况是，超参数接受函数对象作为值，应该尝试某个函数列表。也可能是应该尝试选择一个特殊的数值。为此，p_fct构造函数的级别参数可以是一个不是字符向量的值，而是其他的值。例如，如果cost参数只有0.1、3和10应该尝试，即使是在进行随机搜索时，那么下面的搜索空间可以实现：

```{r}
search_space = ps(
  cost = p_fct(c(0.1, 3, 10)),
  kernel = p_fct(c("polynomial", "radial"))
)
rbindlist(generate_design_grid(search_space, 3)$transpose())
```

这等价于：

```{r}
search_space = ps(
  cost = p_fct(c("0.1", "3", "10"),
    trafo = function(x) list(`0.1` = 0.1, `3` = 3, `10` = 10)[[x]]),
  kernel = p_fct(c("polynomial", "radial"))
)
rbindlist(generate_design_grid(search_space, 3)$transpose())
```

这可能看起来很愚蠢，但考虑到阶乘优化参数总是字符值，这是有意义的：

```{r}
search_space = ps(
  cost = p_fct(c(0.1, 3, 10)),
  kernel = p_fct(c("polynomial", "radial"))
)
typeof(search_space$params$cost$levels)
```

但是，请注意，这会导致一个“无序”超参数。使用参数排序信息的优化算法（如遗传算法或基于模型的优化）在这样做时，性能会更差。对于这些算法，用更合适的流量定义p_dbl或p_int可能更有意义。

如果只有少量的情况，也可以这样设定：

```{r}
search_space = ps(
  class.weights = p_fct(
    list(
      candidate_a = c(spam = 0.5, nonspam = 0.5),
      candidate_b = c(spam = 0.3, nonspam = 0.7)
    )
  )
)
generate_design_grid(search_space)$transpose()
```

### 参数依赖

有些参数只有在另一个参数具有某个值或多个值中的一个时才相关。例如，支持向量机的度参数只在核为“多项式”时有效。这可以使用depends参数指定。该表达式必须包含其他参数，其形式为`<param> == <scalar>`，`<param> %in% <vector>`，或由&&链接的这些参数的倍数。要调优度参数，需要执行以下操作：

```{r}
search_space = ps(
  cost = p_dbl(-1, 1, trafo = function(x) 10^x),
  kernel = p_fct(c("polynomial", "radial")),
  degree = p_int(1, 3, depends = kernel == "polynomial")
)
rbindlist(generate_design_grid(search_space, 3)$transpose(), fill = TRUE)
```

### 从其他参数集创建调优参数集

为已经拥有参数集信息的学习器定义调优参数集似乎有些不必要的乏味，确实有一种方法可以从学习器的参数集创建调优参数集，利用尽可能多的可用信息。

这是通过将学习器的ParamSet值设置为所谓的TuneTokens来实现的，TuneTokens是通过to_tune调用构造的。这与将其他超参数设置为特定值的方法相同。可以将其理解为标记用于以后调优的超参数。用于调优的结果ParamSet可以使用`$search_space()`方法检索。

```{r}
learner = lrn("classif.svm")
learner$param_set$values$kernel = "polynomial"  # for example
learner$param_set$values$degree = to_tune(lower = 1, upper = 3)

print(learner$param_set$search_space())

rbindlist(generate_design_grid(learner$param_set$search_space(), 3)$transpose())
```

这里可以省略lower，因为它可以从degree参数本身的下界推断出来。对于其他已经有界的参数，完全可以不给出任何界限，因为它们的范围已经有界。一个例子是逻辑超参数shrinking：

```{r}
learner$param_set$values$shrinking = to_tune()

print(learner$param_set$search_space())
```

```{r}
rbindlist(generate_design_grid(learner$param_set$search_space(), 3)$transpose())
```

to_tune也可以用Domain对象来构造，比如用`p_***`调用来构造。通过这种方式，可以用离散值调优连续参数，或者给出trafos或依赖项。例如，可以在三个给定的特殊值上调整如上所述的cost，并引入对其进行shrinking的依赖关系。注意，`to_tune(<levels>)`是`to_tune(p_fct(<levels>))`的缩写形式。

```{r}
learner$param_set$values$type = "C-classification"  # needs to be set because of a bug in paradox
learner$param_set$values$cost = to_tune(c(val1 = 0.3, val2 = 0.7))
learner$param_set$values$shrinking = to_tune(p_lgl(depends = cost == "val2"))

print(learner$param_set$search_space())
```

```{r}
rbindlist(generate_design_grid(learner$param_set$search_space(), 3)$transpose(), fill = TRUE)
```

`search_space()`自动从底层ParamSet获取依赖项。因此，如果内核被调优，那么degree就会自动获得对它的依赖，而不需要我们指定。（这里我们重置成本并将其缩减为NULL，以确保生成的输出的清晰性。）

```{r}
learner$param_set$values$cost = NULL
learner$param_set$values$shrinking = NULL
learner$param_set$values$kernel = to_tune(c("polynomial", "radial"))

print(learner$param_set$search_space())
```

```{r}
rbindlist(generate_design_grid(learner$param_set$search_space(), 3)$transpose(), fill = TRUE)
```

甚至可以为单个参数定义整个参数集。对于应该沿着多维搜索的向量超参数，这可能特别有用。但是，这个ParamSet必须有一个`.extra_trafo`，它返回一个包含单个元素的列表，因为它对应于一个正在调优的超参数。假设类的权重超参数应该沿着两个维度进行调整：

```{r}
learner$param_set$values$class.weights = to_tune(
  ps(spam = p_dbl(0.1, 0.9), nonspam = p_dbl(0.1, 0.9),
    .extra_trafo = function(x, param_set) list(c(spam = x$spam, nonspam = x$nonspam))
  ))
head(generate_design_grid(learner$param_set$search_space(), 3)$transpose(), 3)
```


## 嵌套重采样

当需要选择超参数或特征时，评估机器学习模型通常需要额外的重采样层。嵌套重采样将这些模型选择步骤从估计模型性能的过程中分离出来。如果将相同的数据用于模型选择步骤和模型本身的评估，则产生的模型性能估计可能存在严重的偏差。一个原因是模型对测试数据的重复评估可能会将其结构的信息泄露到模型中，从而导致过度乐观的性能估计。请记住，**嵌套重采样是一个统计过程，用于估计在完整数据集上训练的模型的预测性能。嵌套重采样不是一个选择最优超参数的过程**。重采样产生许多超参数配置，**这些超参数配置不应用于构建最终模型**。

![](https://mlr3book.mlr-org.com/images/nested_resampling.png)

上面的图形说明了用于超参数调优的嵌套重采样，在外部循环中使用3倍交叉验证，在内部循环中使用4倍交叉验证。

在外部重采样循环中，我们有三对训练/测试集。对每一个外部训练集进行参数调整，从而执行内部重采样循环。这样，我们就得到了每个外部训练集的一组选定的超参数。然后利用所选的超参数将学习器拟合到每个外部训练集上。随后，我们可以评估学习器在外部测试集上的性能。**外部测试集上的聚合性能是模型的无偏性能估计**。

### 执行

上一节研究了mlr_tasks_pima上简单分类树的优化。我们继续这个例子，并估计模型与嵌套重采样的预测性能。

我们在内部重采样循环中使用4倍交叉验证。AutoTuner执行超参数调优，并在5次计算后停止。通过网格搜索提出了超参数配置。

```{r}
library("mlr3verse")

learner = lrn("classif.rpart")
resampling = rsmp("holdout")
measure = msr("classif.ce")
search_space = ps(cp = p_dbl(lower = 0.001, upper = 0.1))
terminator = trm("evals", n_evals = 5)
tuner = tnr("grid_search", resolution = 10)

at = AutoTuner$new(learner, resampling, measure, terminator, tuner, search_space)
```

外重采样循环采用三倍交叉验证。对每一个外部训练集进行了超参数优化，得到了三种优化的超参数配置。为了执行嵌套重采样，我们将AutoTuner传递给`resample()`函数。我们必须设置`store_models = TRUE`，因为我们需要AutoTuner模型来研究内部调优。

```{r}
task = tsk("pima")
outer_resampling = rsmp("cv", folds = 3)

rr = resample(task, at, outer_resampling, store_models = TRUE)
```


你可以自由组合不同的内部和外部重采样策略。嵌套重采样并不局限于超参数调优。你可以将AutoTuner替换为AutoFSelector，并估计适合于优化特征子集的模型的性能。

### 评估

使用创建的ResampleResult，我们现在可以更仔细地检查执行的重采样迭代。有关ResampleResult对象的详细信息，请参阅重采样一节（上一篇文章）。

我们检查了稳定超参数的内部调优结果。这意味着所选的超参数不应该变化太多。在这个例子中，我们可能会观察到不稳定的模型，因为小的数据集和低的重采样迭代次数可能会引入太多的随机性。通常，我们的目标是为所有外部训练集选择稳定的超参数。

```{r}
extract_inner_tuning_results(rr)
```

接下来，我们要比较外部重采样和内部重采样估计的预测性能。外重采样的预测性能显著降低，表明优化后的超参数模型对数据进行过拟合。

```{r}
rr$score()
```

所有外部重采样迭代的聚合性能本质上是通过网格搜索找到最优超参数的模型的无偏性能。

```{r}
rr$aggregate()
```

请注意，嵌套重采样的计算代价很高。由于这个原因，我们在本例中使用了相对较少的超参数配置和较少的重采样迭代。在实践中，你通常需要增加两者。由于这是计算密集型的，后续你可能想要了解如何并行化。

### 最终模型

我们可以使用AutoTuner来调整我们的学习器的超参数，并在完整的数据集上拟合最终模型。

```{r}
at$train(task)
```

经过训练的模型现在可以用来对新数据进行预测。一个常见的错误是将执行调优的重采样集(在`$tuning_result$classif.ce`)上的估计性能报告为模型的性能。相反，我们报告用嵌套重采样估计的性能作为模型的性能。

## Hyperband调优

除了更传统的调优方法外，围绕mlr3的生态系统还提供了另一个超参数优化过程，即在mlr3hyperband 包中实现的Hyperband。

这里做一个介绍性的类比，想象两个驯马师得到八匹未经训练的马。两名教练都想赢得即将到来的比赛，但他们只有32单位的食物。考虑到每匹马最多可以吃8单位的食物（每匹马的“最大预算”），没有足够的食物给所有的马。**重要的是尽早发现最有前途的马，并给它们足够的食物来改善**。因此，培训师需要制定一个策略，以最好的方式分配食物。第一个驯马师是非常乐观的，他想要探索马的全部能力，因为他不想对马的表现做出判断，除非它已经被完全训练过。所以，他将自己的预算除以他能给一匹马的最大数量（假设8匹，所以32/8=4），然后随机挑选4匹马——他的预算根本不足以训练更多的马。然后，这四匹马被训练到它们的全部能力，而其余的马则被释放。这样，驯马师就有信心从四匹训练过的马中挑选出最好的，但他可能忽略了潜力最大的那匹，因为他只关注了其中的一半。另一位教练则更有创造力，会想出不同的策略。他认为，如果一匹马一开始表现不好，经过进一步的训练，它也不会进步。基于这个假设，他决定给每匹马一单位的食物，并观察它们的发育情况。在吃完最初的食物后，他检查它们的表现，并把训练最慢的那一半踢出训练计划。然后，他增加剩余的食物，进一步训练它们直到食物再次被吃掉，只是再次踢出最差的那一半。他重复这个动作，直到剩下的那匹马吃完了剩下的食物。这意味着只有一匹马接受了完全的训练，但另一方面，他可以开始训练所有八匹马。

比赛当天，所有的马都被放在起跑线上。但是哪位驯马师会拥有获胜的马呢？就是那个想把马训练到最大限度的人？或者另一个人，对他的马的训练进度做出了假设？训练阶段可能是什么样子如图所示。

![](https://mlr3book.mlr-org.com/images/horse_training1.png)

Hyperband在某些方面非常相似，但在其他方面也有不同。在我们的类比中，它不是体现在一个训练员身上，而是更多地体现在付钱给他们的人身上。Hyperband由几个括号组成，每个括号对应一个训练器，我们关心的不是马，而是机器学习算法的超参数配置。预算不是用食物来衡量的，而是用学习器的超参数来衡量的，这个超参数在某种程度上与计算努力有关。一个例子是我们训练神经网络的纪元数，或者在增强过程中迭代的次数。此外，不仅有两个(或训练员)，而是几个，每一个都位于一个独特的位置，在充分探索后期训练阶段和极端选择性之间，相当于早期训练阶段的更高探索。选择侵略性的级别由用户定义的参数η来处理。因此，1/η是在去掉最差配置后剩余配置的分数，但η也是下一阶段预算增加的因素。因为在不同的场景中，每个配置有不同的最大预算，用户还必须将其设置为R参数。Hyperband不需要进一步的参数——所有括号的全部所需预算是间接给出的

$$
(\lfloor \log_{\eta}{R} \rfloor + 1)^2 * R
$$

为了让大家知道对于特定的R和η，布局是怎样的，下表给出了一个快速概览。

| stage | budget |    n |
| ----: | -----: | ---: |
|     1 |      1 |    8 |
|     2 |      2 |    4 |
|     3 |      4 |    2 |
|     4 |      8 |    1 |

| stage | budget |    n |
| ----: | -----: | ---: |
|     1 |      2 |    6 |
|     2 |      4 |    3 |
|     3 |      8 |    1 |

| stage | budget |    n |
| ----: | -----: | ---: |
|     1 |      4 |    4 |
|     2 |      8 |    2 |

| stage | budget |    n |
| ----: | -----: | ---: |
|     1 |      8 |    4 |


> η=2和R=8的hyperband布局，其中n为active配置的数量。

当然，如果在某些情况下过于激进，基于性能标准的提前终止可能是不利的。如果一个学习器在训练阶段对自己的表现进行了大幅度的评估，那么最好的配置可能会被过早地取消，原因很简单，因为与其他学习器相比，他们的改进不够快。换句话说，我们通常不清楚拥有大量的配置n是否比拥有每个配置的高预算B更好，因为它会被早早地丢弃。由此产生的权衡，被称为“n对B/n问题”：为了在基于早期训练表现的选择和后期训练表现的探索之间建立一个平衡，数组元素的值和值之间的值是相等的。因此，有些括号包含更多配置，初始预算较小。在这些情况下，很多人在训练了很短的时间后就被抛弃了，这与我们在马的比喻中选择的驯马师相对应。另一些则使用更少的配置构造，其中丢弃只发生在消耗了大量预算之后。最后一个括号通常不会丢弃任何东西，但也只从很少的配置开始——这相当于教练员在后面阶段的探索。前者对应高n，后者对应高B/n。即使不同的括号被初始化为不同的配置量和不同的初始预算大小，每个括号被分配(大约)相同的预算(数组logη⁡R一半值+1)\∗R。

每个括号开始处的配置由随机的，通常是均匀的抽样初始化。注意，目前所有配置都是从一开始就完全训练过的，所以不会在各个阶段对模型进行在线更新。

要确定评估Hyperband的预算，用户必须显式指定学习器的哪个超参数影响预算，方法是在ParamSet中扩展单个超参数(tags = "budget")，如以下代码片段所示：

```{r}
library("mlr3verse")

# Hyperparameter subset of XGBoost
search_space = ps(
  nrounds = p_int(lower = 1, upper = 16, tags = "budget"),
  booster = p_fct(levels = c("gbtree", "gblinear", "dart"))
)
```

由于mlr3verse的广泛生态系统，学习器不需要一个自然的预算参数。一个典型的例子是决策树。通过使用子采样作为mlr3pipeline的预处理，我们可以解决缺乏预算参数的问题。

```{r}
set.seed(123)

# extend "classif.rpart" with "subsampling" as preprocessing step
ll = po("subsample") %>>% lrn("classif.rpart")

# extend hyperparameters of "classif.rpart" with subsampling fraction as budget
search_space = ps(
  classif.rpart.cp = p_dbl(lower = 0.001, upper = 0.1),
  classif.rpart.minsplit = p_int(lower = 1, upper = 10),
  subsample.frac = p_dbl(lower = 0.1, upper = 1, tags = "budget")
)
```

现在，我们可以像往常一样将具有扩展超参数集的新学习器插入到TuningInstanceSingleCrit中。当然，Hyperband在计算完所有括号后就会终止，因此调优实例中的Terminator充当一个上限，只有在不确定Hyperband在给定设置下需要多长时间完成时，才应该将其设置为一个较低的值。

```{r}
instance = TuningInstanceSingleCrit$new(
  task = tsk("iris"),
  learner = ll,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  terminator = trm("none"), # hyperband terminates itself
  search_space = search_space
)
```


现在，我们初始化mlr3hyperband::mlr_tuners_hyperband类的一个新实例，并开始使用它进行调优。

```{r}
library("mlr3hyperband")
tuner = tnr("hyperband", eta = 3)

# reduce logging output
lgr::get_logger("bbotk")$set_threshold("warn")

tuner$optimize(instance)
```

要接收每个抽样配置的结果，只需运行以下代码片段。

```{r}
as.data.table(instance$archive)[, c(
  "subsample.frac",
  "classif.rpart.cp",
  "classif.rpart.minsplit",
  "classif.ce"
), with = FALSE]
```

你可以通过实例对象访问最佳配置。

```{r}
instance$result

instance$result_learner_param_vals
```


如果你熟悉原始论文，你可能想知道我们是如何使用参数范围从0.1到1.0的Hyperband (Li et al. 2016)。答案是，在预算参数的内部缩放的帮助下。mlr3hyperband自动用它的下界划分预算参数边界，最终预算范围再次从1开始，就像最初的情况一样。如果我们想了解Hyperband创建了什么布局，以及每个设置组中的缩放是如何工作的，我们可以打印一个紧凑的表来查看这些信息。

```{r}
unique(as.data.table(instance$archive)[, .(bracket, bracket_stage, budget_scaled, budget_real, n_configs)])
```

在传统的方法中，Hyperband使用均匀采样在每个括号的开始接收配置样本。但是也可以为每个超参数定义一个自定义Sampler。

```{r}
search_space = ps(
  nrounds = p_int(lower = 1, upper = 16, tags = "budget"),
  eta = p_dbl(lower = 0, upper = 1),
  booster = p_fct(levels = c("gbtree", "gblinear", "dart"))
)

instance = TuningInstanceSingleCrit$new(
  task = tsk("iris"),
  learner = lrn("classif.xgboost"),
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  terminator = trm("none"), # hyperband terminates itself
  search_space = search_space
)

# beta distribution with alpha = 2 and beta = 5
# categorical distribution with custom probabilities
sampler = SamplerJointIndep$new(list(
  Sampler1DRfun$new(search_space$params$eta, function(n) rbeta(n, 2, 5)),
  Sampler1DCateg$new(search_space$params$booster, prob = c(0.2, 0.3, 0.5))
))
```

然后，在实例创建期间必须将定义的采样器作为参数提供。然后，可以进行常规的调优。

```{r}
tuner = tnr("hyperband", eta = 2, sampler = sampler)
set.seed(123)
tuner$optimize(instance)

instance$result
```

此外，我们对原算法进行了扩展，使mlr3hyperband算法也可以用于多目标优化。为此，只需在TuningInstanceMultiCrit中指定更多的度量，并照常运行其余的度量。

```{r}
instance = TuningInstanceMultiCrit$new(
  task = tsk("pima"),
  learner = lrn("classif.xgboost"),
  resampling = rsmp("holdout"),
  measures = msrs(c("classif.tpr", "classif.fpr")),
  terminator = trm("none"), # hyperband terminates itself
  search_space = search_space
)

tuner = tnr("hyperband", eta = 4)
tuner$optimize(instance)
```

现在的结果不是一个单一的最佳配置，而是一个估计的帕累托前沿。关于fpr和tpr性能度量，所有的红点并不受其他参数配置的控制。

```{r}
instance$result

plot(classif.tpr~classif.fpr, instance$archive$data)
points(classif.tpr~classif.fpr, instance$result, col = "red")
```

## 特征选择和过滤

通常，数据集包含大量的特性。提取相关特征子集的技术称为“特征选择”。

特征选择的目标是将模型的稀疏依赖以最合适的方式拟合到可用数据特征的子集上。特征选择可以提高模型的可解释性，加快学习过程，提高学习器的学习性能。有不同的方法来识别相关的特征。文献中强调了两种不同的方法：一种称为过滤，另一种通常称为特征子集选择或包装器方法。

区别是什么？

- 过滤：外部算法计算特征的等级(例如，基于与响应的相关性)。然后，特征被特定的标准子集，例如一个绝对数量或变量数量的百分比。选择的特性将用于适应模型（通过调优选择可选的超参数）。在计算时间方面，这种计算通常比“特征子集选择”更便宜。所有过滤器通过mlr3filers包连接。
- 包装器方法：这里没有对功能进行排名。相反，优化算法选择特征的子集，通过计算重新采样的预测性能来评估集合，然后提出一组新的特征(或终止)。一个简单的例子是顺序向前选择。该方法通常需要大量的模型拟合，计算量很大。此外，严格地说，在估计性能之前，所有这些模型都需要进行调优。这将需要在CV设置中增加一个嵌套级别。在完成所有这些步骤之后，最后一组选定的特性将再次得到满足（通过调优选择可选的超参数）。包装器方法在mlr3fselect包中实现。
- 嵌入方法：许多学习器在内部选择他们认为有助于预测的特征子集。这些子集通常可以被查询，如下例所示：

```{r}
library("mlr3verse")

task = tsk("iris")
learner = lrn("classif.rpart")

# ensure that the learner selects features
stopifnot("selected_features" %in% learner$properties)

# fit a simple classification tree
learner = learner$train(task)

# extract all features used in the classification tree:
learner$selected_features()
```

也有集成过滤器建立在叠加单过滤器方法的思想上。这些还没有实现。

### 过滤器

过滤方法为每个特性分配一个重要值。根据这些值可以对特征进行排名。然后，我们可以选择一个特征子集。[附录](https://mlr3book.mlr-org.com/appendix.html#list-filters)中列出了所有已实现的过滤器方法。

### 计算过滤值

目前，只支持分类和回归任务。

第一步是使用所需的过滤器方法的类创建一个新的R对象。与mlr3中的其他实例类似，这些实例使用关联的快捷函数`flt()`在字典(mlr_filters)中注册。Filter类的每个对象都有一个`.$calculate()`方法，该方法计算过滤值并按降序排列。

```{r}
filter = flt("jmim")

task = tsk("iris")
filter$calculate(task)

as.data.table(filter)
```

一些过滤器支持更改特定的超参数。这类似于使用。`$param_set$values`设置学习器的超参数：

```{r}
filter_cor = flt("correlation")
filter_cor$param_set


# change parameter 'method'
filter_cor$param_set$values = list(method = "spearman")
filter_cor$param_set
```

### 变量重要性过滤器

所有具有“重要性”属性的学习器都具有综合特征选择方法。

对于一些学习器，需要在学习器创建过程中设置所需的过滤方法。例如，分类学习器classif.ranger自带多种集成方法，c.f. `ranger::ranger()`的帮助页面。要使用方法“impurity”，你需要在构造期间设置过滤方法。

```{r}
lrn = lrn("classif.ranger", importance = "impurity")
```

现在你可以对嵌入算法的方法使用FilterImportance过滤器类：

```{r}
task = tsk("iris")
filter = flt("importance", learner = lrn)
filter$calculate(task)
head(as.data.table(filter), 3)
```

### 包装器方法

通过mlr3fselect扩展包支持包装器特性选择。在mlr3fselect的核心是R6类：

- FSelectInstanceSingleCrit、FSelectInstanceMultiCrit：这两个类描述了特性选择问题并存储结果。
- FSelector：这个类是实现特征选择算法的基类。

### FSelectInstance类

下面的小节检查了用于预测患者是否患有糖尿病的Pima数据集上的特征选择。

```{r}
task = tsk("pima")
print(task)
```

我们使用rpart中的分类树。

```{r}
learner = lrn("classif.rpart")
```

接下来，我们需要指定如何评估特征子集的性能。为此，我们需要选择重采样策略和性能度量。

```{r}
hout = rsmp("holdout")
measure = msr("classif.ce")
```

最后，必须为特性选择选择可用的预算。

在这个简短的介绍中，我们指定了20次计算的预算，然后把所有的东西放在一个FSelectInstanceSingleCrit中：

```{r}
evals20 = trm("evals", n_evals = 20)

instance = FSelectInstanceSingleCrit$new(
  task = task,
  learner = learner,
  resampling = hout,
  measure = measure,
  terminator = evals20
)
instance
```

为了开始特征选择，我们仍然需要选择一个通过FSelector类定义的算法。

### FSelector类

以下算法目前在mlr3fselect中实现：

- 随机搜索 FSelectorRandomSearch 
- 穷举搜索 FSelectorExhaustiveSearch
- 顺序搜索 FSelectorSequential
- 递归特征消除 FSelectorRFE
- 设计点 FSelectorDesignPoints

在这个例子中，我们将使用一个简单的随机搜索，并使用`fs()`函数从字典mlr_fselectors中检索它：

```{r}
fselector = fs("random_search")
```

### 触发调优

要开始特性选择，我们只需将FSelectInstanceSingleCrit传递给初始化的FSelector的`$optimize()`方法。算法如下所示：

1. FSelector至少提出一个特征子集，也可以提出多个子集来提高并行性，可以通过设置batch_size来控制。
2. 对于每个特征子集，给定的学习器使用提供的重采样对任务进行拟合。所有的计算都存储在FSelectInstanceSingleCrit的存档中。
3. 如果预算耗尽，终结者会被询问。如果预算未耗尽，则使用第一步重新启动，直到耗尽为止。
4. 确定观察性能最好的特征子集。
5. 将最佳特性子集作为结果存储在实例对象中。可以从实例访问最佳特性子集(`$result_feature_set`)和相应的测量性能(`$result_y`)。

```{r}
# reduce logging output
lgr::get_logger("bbotk")$set_threshold("warn")

fselector$optimize(instance)

instance$result_feature_set

instance$result_y
```

我们可以调查所有已经进行的重采样，因为它们存储在FSelectInstanceSingleCrit的存档中，可以使用`as.data.table()`访问：

```{r}
as.data.table(instance$archive)
```

相关的重采样迭代可以在BenchmarkResult中访问：

```{r}
instance$archive$benchmark_result$data
```

uhash列将重新采样迭代链接到实例`$archive$data()`中已评估的特性子集。例如，可以对所包含的ResampleResults进行不同的评分。

现在，优化后的特征子集可以用来对任务进行子集化，并对所有观测值进行模型拟合。

```{r}
task$select(instance$result_feature_set)
learner$train(task)
```

经过训练的模型现在可以用来对外部数据进行预测。注意，应该避免根据任务中出现的观察结果进行预测。该模型在特征选择过程中已经看到了这些观察结果，因此结果在统计上是有偏差的。因此，由此产生的性能度量将过于乐观。相反，为了获得当前任务的统计无偏性能估计，需要嵌套重采样。

### 自动特征选择

AutoFSelector包装了一个学习器，并为给定任务添加了自动特征选择功能。因为AutoFSelector本身继承自Learner基类，所以它可以像任何其他学习器一样使用。类似于前面的小节，创建了一个新的分类树学习器。这种分类树学习器使用内部重采样(holdout)在给定任务上自动开始特征选择。我们创建了一个允许10次计算的终止符，并使用一个简单的随机搜索作为特征选择算法：

```{r}
learner = lrn("classif.rpart")
terminator = trm("evals", n_evals = 10)
fselector = fs("random_search")

at = AutoFSelector$new(
  learner = learner,
  resampling = rsmp("holdout"),
  measure = msr("classif.ce"),
  terminator = terminator,
  fselector = fselector
)
at
```

我们现在可以像使用其他学习器使用它，调用`$train()`和`$predict()`方法。然而，这一次，我们将它传递给`benchmark()`，以将优化的特性子集与完整的特性集进行比较。这样，AutoFSelector将在外部重采样的各自分割的训练集上进行特征选择的重采样。然后，学习器使用外部重采样的测试集进行预测。这产生了无偏的性能度量，因为测试集中的观察结果在特征选择或拟合各自的学习器时没有被使用。这被称为嵌套重采样。

```{r}
grid = benchmark_grid(
  task = tsk("pima"),
  learner = list(at, lrn("classif.rpart")),
  resampling = rsmp("cv", folds = 3)
)

bmr = benchmark(grid, store_models = TRUE)
bmr$aggregate(msrs(c("classif.ce", "time_train")))
```

请注意，我们不期望任何显著的差异，因为我们只评估了可能的特性子集的一小部分。

```{r}
xfun::session_info()
```

