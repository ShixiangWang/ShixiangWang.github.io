---
title: mlr3（二）基础
author: 王诗翔
date: '2021-09-01'
slug: mlr3-basics
categories:
  - Blog
tags:
  - R
  - mlr3
  - 机器学习
description: 翻译与笔记
keywords: rstats
editor_options:
  chunk_output_type: console
---

<!-- Links -->

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  echo = TRUE, warning = FALSE, message = FALSE,
  fig.width = 9, fig.height = 10, comment = "out"
)
knitr::opts_chunk$set(engine.opts = list(bash = "-l"))
knitr::knit_hooks$set(
  prompt = function(before, options, envir) {
    options(prompt = if (options$engine %in% c('sh','bash')) '$ ' else 'R> ')
})
options(htmltools.dir.version = TRUE)

# If using lightbox for plots, set `fig.show = FALSE`
# Usage: lightbox_img(knitr::fig_chunk("chunk-name", "png"))
lightbox_img <- function(url, alt = "", caption = "", preview = TRUE) {
  if (preview) {
    glue::glue(
      '<a href="{url}" data-featherlight="image">
      <div class="figure">
      <img src="{url}" alt="{alt}">
      <p class="caption">{caption}</p>
      </div>
      </a>
      '
    )
  } else {
    if (alt == "") alt <- "static image of the plot"
    glue::glue('<a href="{url}" data-featherlight="image">{alt}</a>')
  }
}
```

来源：<https://mlr3book.mlr-org.com/basics.html>

本文将教你基本的mlr3知识，以及它的R6类和操作以用于机器学习。典型的机器学习工作流是这样的:

```{r echo = FALSE, fig.cap="机器学习流程 source: https://mlr3book.mlr-org.com/images/ml_abstraction.svg"}
knitr::include_graphics("https://mlr3book.mlr-org.com/images/ml_abstraction.svg")
```

mlr3将数据封装在任务中，并将其分解为互不重叠的训练集和测试集。由于我们感兴趣的模型外推到新的数据，而不仅仅是记忆训练数据，独立的测试数据允许客观地评估模型的泛化。训练数据被提供给一个机器学习算法，在mlr3中我们称之为learner。learner利用训练数据建立输入特征与输出目标值之间关系的模型。然后使用该模型对测试数据进行预测，并将其与参考真值进行比较，以评估模型的质量。mlr3提供了许多不同的度量方法，根据预测值和实际值之间的差异来量化模型的执行情况。通常这是一个数字分数。

将数据分割为训练集和测试集、建立模型并对其进行评估的过程可能会重复多次，每次从原始数据中重新采样不同的训练集和测试集。多重重采样迭代允许我们对特定类型的模型获得更好、更一般化的性能估计，因为它是在不同的条件下测试的，而且由于数据重采样的特定方式，它不太容易产生偏差。

在许多情况下，这个简单的工作流不足以处理真实世界的数据，可能需要规范化（标准化）、缺失值的输入或特征选择。我们将在以后介绍更复杂的工作流程。

本文涵盖以下小主题：

**任务**：

任务用元信息封装数据，比如预测目标列的名称。我们将介绍如何：

- 访问预定义的任务
- 指定一个任务类型
- 创建一个任务
- 使用任务的API工作
- 为任务的行和列分配角色
- 实施任务mutator
- 获取存储在任务中的数据

**学习器**

学习器封装机器学习算法来训练模型并对任务进行预测。它们由R和其他包提供。我们将介绍如何：

- 访问随mlr3而来的分类和回归学习器集合，并检索特定的学习器
- 访问学习器的超参数值集并修改它们

如何修改和扩展学习器涵盖在[补充高级技术](https://mlr3book.mlr-org.com/extending.html#extending-learners)部分。


**训练和预测**

关于训练和预测方法的部分说明了如何使用任务和学习器训练模型并对新数据集进行预测。特别地，我们将介绍如何：

- 正确设置任务和学习器
- 为一项任务设置训练和测试分割（集）
- 在训练集上训练学习器以生成模型
- 生成测试集的预测
- 通过比较预测值和实际值来评估模型的性能

**重采样**

重采样是一种创建训练和测试分割（集）的方法。我们将介绍：

- 访问和选择重采样策略
- 通过应用重采样实例化分割到训练集和测试集
- 执行重采样以获得结果

关于重采样的附加信息可以在[嵌套重采样部分和模型优化](https://mlr3book.mlr-org.com/optimization.html#optimization)一章中找到。

**基准测试**

基准测试用于比较不同模型的性能，例如不同学习器训练的模型，不同任务训练的模型，或不同重采样方法训练的模型。我们介绍如何

- 创建一个基准设计
- 执行设计并汇总结果
- 将基准测试对象转换为重采样对象

**二分类**

二值分类是分类的一种特殊情况，预测的目标变量只有两个可能的值。在这种情况下，还需要考虑其他因素。特别是：

- ROC曲线和预测一个类和另一个类的阈值
- 阈值调整

在详细介绍如何使用mlr3进行机器学习之前，我们先简要介绍一下R6，因为它是R相对较新的一部分。mlr3严重依赖于R6，它提供的所有基本构造都是R6类：

- 任务 task
- 学习器 learner
- 测量 measure
- 重采样 resamplings

## 快速R6入门介绍

R6是R最新的面向对象编程(OO)方言之一。它解决了R中早期OO实现的缺点，比如我们在mlr中使用的S3。如果你以前做过面向对象编程，那么R6应该很熟悉。我们关注的是R6的部分，你需要知道在这里使用mlr3。

- 对象是通过调用`R6::R6Class()`对象的构造函数创建的，特别是初始化方法`$new()`。例如，`foo = foo $new(bar = 1)`创建一个`foo`类的新对象，将构造函数的`bar`参数设置为值`1`。mlr3中的大多数对象都是通过特殊函数（例如`lrn(“regr.rpart”)`）创建的，这些函数也被称为sugar函数。

- 对象具有可变状态，该状态封装在它们的字段中，可以通过dollar操作符访问。我们可以通过`Foo$bar`访问Foo类中的bar值，并通过赋值字段设置其值，例如`Foo$bar = 2`。

- 除了字段之外，对象还公开了一些方法，这些方法允许检查对象的状态、检索信息或执行可能改变对象内部状态的操作。例如，学习者的`$train`方法通过建立和存储一个训练过的模型来改变学习者的内部状态，然后使用该模型对给定的数据进行预测。

- 对象可以有公共和私有的字段和方法。公共字段和方法定义了与对象交互的API。私有方法只有在你想要扩展mlr3时才有用，比如新学习器。

- R6对象是内部环境，因此具有引用语义。例如，`foo2 = foo`并不是在`foo2`中创建`foo`的副本，而是对相同实际对象的另一个引用。设置`foo$bar = 3`也会将`foo2$bar`改为3，反之亦然。

- 要复制对象，使用`$clone()`方法和嵌套对象的`deep = TRUE`参数，例如，`foo2 = foo$clone(deep = TRUE)`。

关于R6的更多细节，请查阅[R6的vignette](https://r6.r-lib.org/)，特别是[介绍](https://r6.r-lib.org/articles/Introduction.html)。

## 任务

任务是包含定义机器学习问题的（通常是表格）数据和附加元数据的对象。例如，元数据是用于监督机器学习问题的目标变量的名称，或数据集的类型（例如空间数据或生存数据）。此信息用于可在任务上执行的特定操作。

### 任务类型

要从`data.frame()`，`data.table()`或`Matrix()`创建任务，首先需要选择正确的任务类型：

- **分类任务**：目标是一个字符串或因子标签，只有几个不同的值。

→ [TaskClassif](https://mlr3.mlr-org.com/reference/TaskClassif.html)

- **回归任务**：目标是一个连续数值向量。

→ [TaskRegr](https://mlr3.mlr-org.com/reference/TaskRegr.html)

- **生存任务**：目标是某一事件的(右审查)时间。更多的审查类型目前正在发展中。

→ [mlr3proba::TaskSurv](https://mlr3proba.mlr-org.com/reference/TaskSurv.html) 在拓展包 [mlr3proba](https://mlr3proba.mlr-org.com/) 中。

- **密度任务**：一个评估密度的非监督任务。

→ [mlr3proba::TaskDens](https://mlr3proba.mlr-org.com/reference/TaskDens.html) 在拓展包 [mlr3proba](https://mlr3proba.mlr-org.com/) 中。


- 聚类任务：一种非监督任务类型；没有目标，目的是在特性空间中识别相似的组。

→ [mlr3cluster::TaskClust](https://mlr3cluster.mlr-org.com/reference/TaskClust.html) 在拓展包 [mlr3cluster](https://mlr3cluster.mlr-org.com/) 中。

- 空间任务：任务中的观察具有时空信息（例如坐标）。

→ [mlr3spatiotempcv::TaskRegrST](https://www.rdocumentation.org/packages/mlr3spatiotempcv/topics/TaskRegrST) 或 [mlr3spatiotempcv::TaskClassifST](https://www.rdocumentation.org/packages/mlr3spatiotempcv/topics/TaskClassifST) 在拓展包 [mlr3spatiotempcv](https://mlr3spatiotempcv.mlr-org.com/) 中。

- 有序回归任务：目标是有序的。

→ TaskOrdinal 在拓展包 [mlr3ordinal](https://github.com/mlr-org/mlr3ordinal) 中。

### 任务创建

作为一个例子，我们将使用包数据集中的mtcars数据集创建一个回归任务，并预测数值目标变量“mpg”（每加仑英里数）。为简洁起见，我们只考虑数据集中的前两个特性。

首先载入数据：

```{r}
data("mtcars", package = "datasets")
data = mtcars[, 1:3]
str(data)
```

接下来，我们创建一个回归任务，即构造一个R6类`TaskRegr`的新实例。通常，这是通过调用构造函数`TaskRegr$new()`来实现的。相反，我们调用转换器`as_task_regr()`来将我们的`data.frame()`作为数据存储到任务中，并提供以下信息：

- `x`：要转换的对象。适用于在DataBackendDataTable类中实现的`data.frame()/data.table()/tibble()`抽象数据后端。DataBackendDataTable允许通过扩展包mlr3db连接到内存不足的存储系统，如SQL服务器。

- `target`：回归问题的目标列的名称。

- `id`(可选)：任务的任意标识符，用于绘图和汇总。如果未提供，将使用`x`的替换名称。

```{r}
library("mlr3")

task_mtcars = as_task_regr(data, target = "mpg", id = "cars")
print(task_mtcars)
```

`print()`方法给出任务的简短总结：它有32个观察值和3列，其中2列是特征。

我们可以对任务数据进行可视化：

```{r}
library("mlr3viz")
autoplot(task_mtcars, type = "pairs")
```

请注意，与单独加载所有扩展包相比，加载mlr3verse包通常更方便。mlr3verse导入大部分mlr3包并重新导出用于常规机器学习和数据科学任务的函数。

### 预定义（内置）任务

mlr3带有一些预定义的机器学习任务。所有任务都存储在名为`mlr_tasks`的R6 `Dictionary`（键值存储）中。打印它将给出关键字（数据集的名称）：

```{r}
mlr_tasks
```

通过将字典转换为`data.table()`对象，我们可以获得更多关于示例任务的信息总结:

```{r}
as.data.table(mlr_tasks)
```

在上面的显示中，列“lgl”(逻辑)、“int”(整数)、“dbl”(双精度)、“chr”(字符)、“fct”(因子)、“ord”(有序因子)和“pxc”(POSIXct时间)显示了具有相应存储类型的数据集中特征的数量。

要从字典中获取任务，可以使用mlr_tasks类中的`$get()`方法，并将返回值赋给一个新对象。由于mlr3将它的大多数对象实例安排在字典中，提取是如此常见的任务，因此有一个快捷方式：函数`tsk()`。在这里，我们从包palmerpenguins中检索palmerpenguins任务：

```{r}
task_penguins = tsk("penguins")
print(task_penguins)
```


注意，像mlr_tasks这样的字典可以由扩展包**填充**。例如，mlr3data提供了更多的示例和玩具任务用于回归和分类，而mlr3proba则提供了额外的生存和密度估计任务。当我们加载mlr3verse包时，这两个包都会被加载，所以我们在这里执行，并再次查看可用的任务：

```{r}
library("mlr3verse")
as.data.table(mlr_tasks)[, 1:4]
```

> 这里还挺有意思的，多个包怎么共用和补充同一个对象的？

要获得关于各自任务的更多信息，可以在`mlr_tasks_[id]`下找到相应的手册页，例如[mlr_tasks_german_credit](https://mlr3.mlr-org.com/reference/mlr_tasks_german_credit.html)。

### 任务API

可以使用任务的公共字段和方法查询所有任务属性和特征。方法还可用于更改存储的数据和任务的行为。

#### 获取数据

存储在任务中的数据可以直接从字段中检索，例如：

```{r}
task_mtcars

task_mtcars$nrow
task_mtcars$ncol
```

通过对象的方法可以获得更多的信息，例如：

```{r}
task_mtcars$data()
```

在mlr3中，每一行(观察)都有一个唯一的标识符，存储为一个整数。这些可以作为参数传递给`$data()`方法以选择特定的行：

```{r}
head(task_mtcars$row_ids)

# retrieve data for rows with ids 1, 5, and 10
task_mtcars$data(rows = c(1, 5, 10))
```

注意，尽管行id通常只是从1到`nrow(data)`的序列，但它们只能保证是唯一的自然数。请记住这一点，特别是当你使用存储在真实数据库管理系统中的数据时。

与行id类似，目标列和特征列也有惟一标识符，即名称。它们的名称可以通过公共槽`$feature_names`和`$target_names`访问。这里，“目标”指的是我们想要预测的变量，“特征”指的是任务的预测变量。

```{r}
task_mtcars$feature_names
task_mtcars$target_names
```

当选择数据的子集时，row_id和列名可以组合：

```{r}
# retrieve data for rows 1, 5, and 10 and only select column "mpg"
task_mtcars$data(rows = c(1, 5, 10), cols = "mpg")
```

要从任务中提取完整的数据，还可以简单地将其转换为`data.table`：

```{r}
summary(as.data.table(task_mtcars))
```

#### 角色（行和列）

可以将不同的角色分配给行和列。这些角色影响任务对不同操作的行为。我们已经在目标和特性列中看到了这一点，它们有不同的用途。

例如，前面构造的mtcars任务有以下列角色：

```{r}
print(task_mtcars$col_roles)
```

列也可以没有角色（被忽略）或有多个角色。要将mtcars的行名作为附加特性添加到数据表中，我们首先将它们作为常规列添加到数据表中，然后使用新列重新创建任务。

```{r}
# with `keep.rownames`, data.table stores the row names in an extra column "rn"
data = as.data.table(datasets::mtcars[, 1:3], keep.rownames = TRUE)
task_mtcars = as_task_regr(data, target = "mpg", id = "cars")

# there is a new feature called "rn"
task_mtcars$feature_names
```

行名现在是一个特性，其值存储在列“rn”中。我们在这里列这一栏仅仅是为了教育目的。**一般来说，使用唯一标识每一行的特性是没有意义的**。此外，字符数据类型将导致许多类型的机器学习算法的问题。

另一方面，标识符可能有助于标记图中的点，例如识别和标记离群点。因此，我们将改变rn列的角色，从特性列表中删除它，并分配新的角色“name”。有两种方法可以做到：

1. 使用任务方法`$set_col_roles()`(推荐)。
2. 只需修改字段`$col_roles`，它是列名向量的命名列表。这个列表中的每个向量对应于一个列角色，该向量中包含的列名被指定为具有该角色。

```{r}
# supported column roles, see ?Task
names(task_mtcars$col_roles)

# assign column "rn" the role "name", remove from other roles
task_mtcars$set_col_roles("rn", roles = "name")

# note that "rn" not listed as feature anymore
task_mtcars$feature_names

# "rn" also does not appear anymore when we access the data
task_mtcars$data(rows = 1:2)

task_mtcars$head(2)
```

更改角色并不会更改底层数据，它只是更新底层数据上的视图。上面的代码中没有复制数据。但是视图被就地更改，即任务对象本身被修改。

与列一样，也可以将不同的角色分配给行。

行可以有两个不同的角色：

1. 角色`use`：通常用于模型拟合的行（尽管它们也可以用作重采样中的测试集）。默认角色。
2. 角色`validation`：不用于训练的行。在任务创建期间，目标列中缺少值的行将自动设置为验证角色。

有几个原因解释为什么区别对待它们：

1. 通常，在外部验证集上验证最终模型以识别可能的过拟合是很好的做法。
2. 有些观察结果可能没有标记，例如在Kaggle比赛中。这些观察结果不能用于训练模型，但可以用于获得预测。

#### 任务调整器

如上所示，修改`$col_roles`或`$row_roles`(通过`set_col_roles()`/`set_row_roles()`或直接通过修改命名列表)会改变数据的视图。附加的便利方法`$filter()`基于行id对当前视图进行子集设置，而`$select()`基于特征名称对视图进行子集设置。

```{r}
task_penguins = tsk("penguins")
task_penguins$select(c("body_mass", "flipper_length")) # keep only these features
task_penguins$filter(1:3) # keep only these rows
task_penguins$head()
```

虽然上面讨论的方法允许将数据子集化，但是`$rbind()`和`$cbind()`方法允许向任务添加额外的行和列。同样，原始数据没有改变。附加的行或列只添加到数据视图中。

```{r}
task_penguins$cbind(data.frame(letters = letters[1:3])) # add column foo
```

#### 可视化任务

mlr3viz包为在mlr3中实现的许多类提供了绘图工具。可用的绘图类型依赖于继承的类，但所有绘图都作为ggplot2对象返回，可以很容易地自定义。

关于分类任务(从TaskClassif继承)，请参阅[`mlr3viz::autoplot`](https://mlr3viz.mlr-org.com/reference/autoplot.TaskClassif.html)的文档查看实现的绘图类型。以下是一些给人留下印象的例子：

```{r}
library("mlr3viz")

# get the pima indians task
task = tsk("pima")

# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))

# default plot: class frequencies
autoplot(task)
```

```{r}
# pairs plot (requires package GGally)
autoplot(task, type = "pairs")
```

```{r}
# duo plot (requires package GGally)
autoplot(task, type = "duo")
```

当然，你也可以对回归任务(从TaskRegr继承)执行同样的操作。

```{r}
library("mlr3viz")

# get the complete mtcars task
task = tsk("mtcars")

# subset task to only use the 3 first features
task$select(head(task$feature_names, 3))

# default plot: boxplot of target variable
autoplot(task)
```


```{r}
# pairs plot (requires package GGally)
autoplot(task, type = "pairs")
```

## 学习器

类学习对象Learner为许多流行的机器学习算法提供了一个统一的接口。它们包括训练和预测任务模型的方法，并提供关于学习者的元信息，如你可以设置的超参数。

每个学习器的基类是Learner，用于回归的是LearnerRegr，用于分类的是LearnerClassif。扩展包继承自学习器基类，例如`mlr3proba::LearnerSurv`或`mlr3cluster::LearnerClust`。与Task相反，通常不需要创建自定义学习器，这是一个[更高级的主题](https://mlr3book.mlr-org.com/extending.html#extending-learners)。

所有的学习器在一个两阶段的过程中工作：

```{r echo = FALSE, fig.cap="学习器 source: https://mlr3book.mlr-org.com/images/learner.svg"}
knitr::include_graphics("https://mlr3book.mlr-org.com/images/learner.svg")
```

- **训练阶段**：训练数据（特征和目标）被传递给学习器的`$train()`函数，该函数训练并存储一个模型，即目标和特征之间的关系。
- **预测阶段**：一个新的数据片段，即推断数据，被传递给学习器的`$predict()`方法。第一步训练的模型用于预测缺失的目标特征，例如分类问题的标签或回归问题的数值结果。

### 预定义的学习器

mlr3包附带了以下最小的分类和回归学习器集合，以避免不必要的依赖：

- [mlr_learners_classif.featureless](https://mlr3.mlr-org.com/reference/mlr_learners_classif.featureless.html)：简单的基线分类学习器(继承自LearnerClassif)。在默认情况下，它会不断预测训练集中出现频率最高的标签。
- [mlr_learners_regr.featureless](https://mlr3.mlr-org.com/reference/mlr_learners_regr.featureless.html)：简单基线回归学习器(从LearnerRegr继承)。在默认情况下，它不断地预测训练集中结果的均值。
- [mlr_learners_classif.rpart](https://mlr3.mlr-org.com/reference/mlr_learners_classif.rpart.html)：rpart包提供的单一的分类树。
- [mlr_learners_regr.rpart](https://mlr3.mlr-org.com/reference/mlr_learners_regr.rpart.html)：rpart包提供的单一的回归树。

这组基线学习器通常不足以进行真实的数据分析。因此，我们挑选了最流行的机器学习方法的一个实现，并将它们连接到mlr3learners包中：

- 线性与逻辑回归
- 惩罚广义线性模型
- k近邻回归与分类
- Kriging
- 线性和二次判别分析
- 朴素贝叶斯
- 支持向量机
- 梯度提升
- 用于回归、分类和生存的随机森林

更多的机器学习方法和替代实现被收集在[mlr3extralearners](https://github.com/mlr-org/mlr3extralearners/)中。

在[这个交互式列表](https://mlr3extralearners.mlr-org.com/articles/learners/list_learners.html)中给出了所有包中已实现的学习者的完整列表，也通过`mlr3extralearners::list_mlr3learners()`给出。

[这里](https://mlr3extralearners.mlr-org.com/articles/learners/learner_status.html)列出了所有学习器的最新构建状态。


要为预定义的学习器之一创建对象，你需要访问`mlr_learners Dictionary`，该Dictionary与mlr_tasks类似，通过扩展包自动填充更多学习器。

```{r}
# load most mlr3 packages to populate the dictionary
library("mlr3verse")
mlr_learners
```

要从字典中获取对象，可以使用`lrn()`或通用的`mlr_learners$get()`方法，例如`lrn("class.rpart")`。

### 学习器API

每个学习器提供以下元信息：

- `feature_types`：学习器能够处理的特征类型。
- `packages`：用这个学习器训练模型并进行预测所需的软件包。
- `properties`：附加属性和功能。例如，如果一个学习器能够处理缺失的特征值，那么他就具有“缺失”属性；如果它计算并允许根据数据提取特征相对重要性，那么他就具有“重要性”属性。在[mlr3的文档](https://mlr3.mlr-org.com/reference/mlr_reflections.html#examples)中有一个完整的列表。
- `predict_types`：可能的预测类型。例如，分类学习器可以预测标签(“响应”)或概率(“概率”)。有关可能的预测类型的完整列表，请参阅[mlr3文档](https://mlr3.mlr-org.com/reference/mlr_reflections.html#examples)。

你可以使用它的id来检索一个特定的学习器：

```{r}
learner = lrn("classif.rpart")
print(learner)
```

`param_set`字段存储了学习者超参数的描述、它们的范围、默认值和当前值：

```{r}
learner$param_set
```

当前超参数值集存储在param_set字段的values字段中。你可以通过为该字段指定一个命名列表来更改当前的超参数值：

```{r}
learner$param_set$values = list(cp = 0.01, xval = 0)
learner

learner$param_set
```

**注意，这个操作只是覆盖了之前设置的所有参数**。如果你只是想添加一个新的超参数，检索当前的参数值集，修改命名列表并将其写回学习器：

```{r}
pv = learner$param_set$values
pv$cp = 0.02
learner$param_set$values = pv
```

这会将cp更新到0.02，并保留先前设置的参数xval。

注意，`lrn()`函数还接受额外的参数，然后用于一次性更新学习器的超参数或设置字段：

```{r}
learner = lrn("classif.rpart", id = "rp", cp = 0.001)
learner$id

learner$param_set$values
```

## 训练、预测和评分

在本节中，我们将解释如何使用任务和学习器来训练模型并预测到新数据集。在使用帝企鹅数据集和rpart学习器的监督分类上证明了这一概念，该学习器构建了一个单一的分类树。

训练学习器意味着将模型拟合到给定的数据集。随后，我们想要预测新的观测结果的标签。这些预测将与参考真值进行比较，以评估模型的预测性能。


### 创建任务和学习器对象

首先，我们加载mlr3verse包。

```{r}
library("mlr3verse")
```

接下来，我们分别从mlr_tasks（使用快捷方式`tsk()`）和mlr_learners（使用快捷方式`lrn()`）中检索任务和学习器：

```{r}
task = tsk("penguins")

learner = lrn("classif.rpart")
```

### 设置任务的训练和测试集

在大部分数据上进行训练是很常见的。在这里，我们使用了所有可用观测值的`80%`，并对剩下的`20%`进行预测。为此，我们创建两个索引向量：

```{r}
train_set = sample(task$nrow, 0.8 * task$nrow)
test_set = setdiff(seq_len(task$nrow), train_set)
```

后面我们将学习mlr3如何基于不同的重采样策略自动创建训练集和测试集。

### 训练学习器

字段`$model`存储在培训步骤中生成的模型。在对学习对象调用`$train()`方法之前，该字段是`NULL`：

```{r}
learner$model
```

接下来，调用学习者的`$train()`方法，使用sonar任务的训练集对分类树进行训练：

```{r}
learner$train(task, row_ids = train_set)
```

这个操作可以就地修改学习器。我们现在可以通过字段`$model`访问存储的模型：

```{r}
print(learner$model)
```

### 预测

模型训练完成后，我们使用剩下的部分数据进行预测。记住，我们最初在train_set和test_set中分割数据。

```{r}
prediction = learner$predict(task, row_ids = test_set)
print(prediction)
```

Learner的`$predict()`方法返回一个Prediction对象。更准确地说，LearnerClassif返回PredictionClassif对象。

预测对象保存测试数据的行id、目标列各自的真实标签和各自的预测。提取此信息的最简单方法是将Prediction对象转换为`data.table()`：

```{r}
head(as.data.table(prediction))
```

对于分类，还可以提取混淆矩阵：

```{r}
prediction$confusion
```

### 修改预测类型

分类学习者默认预测类标签。然而，许多分类器还通过提供后验概率告诉你他们对预测标签的确定程度。要切换到预测这些概率，LearnerClassif的predict_type字段必须在训练前从“response”更改为“probb”：

```{r}
learner$predict_type = "prob"

# re-fit the model
learner$train(task, row_ids = train_set)

# rebuild prediction object
prediction = learner$predict(task, row_ids = test_set)
```

预测对象现在包含所有类标签的概率：

```{r}
# data.table conversion
head(as.data.table(prediction))

# directly access the predicted labels:
head(prediction$response)

# directly access the matrix of probabilities:
head(prediction$prob)
```


与预测概率类似，许多回归学习器通过将预测类型设置为“se”来支持提取标准误差估计。

### 可视化预测

与绘制任务类似，mlr3viz为Prediction对象提供了`autoplot()`方法。所有可用的类型分别在`autoplot.PredictionClassif()`或`autoplot.PredictionRegr()`的手册页中列出。

```{r}
task = tsk("penguins")
learner = lrn("classif.rpart", predict_type = "prob")
learner$train(task)
prediction = learner$predict(task)
autoplot(prediction)
```

### 性能评估

建模的最后一步通常是性能评估。为了评估预测的质量，将预测标签与真实标签进行比较。这个比较是如何计算的由度量定义，度量由Measure对象给出。注意，如果在没有目标列的数据集上进行预测，即没有真正的标签，则无法计算性能。

预定义的可用度量存储在mlr_measures中（使用方便的`msr()`）:

```{r}
mlr_measures
```

我们选择准确性(classif.acc)作为具体的性能度量，并调用Prediction对象的`$score()`方法来量化预测性能。

```{r}
measure = msr("classif.acc")
print(measure)
```

```{r}
prediction$score(measure)
```

## 重采样

重采样策略通常用来评估学习算法的性能。mlr3包含了以下预定义的重采样策略：

- [交叉验证 - cv](https://mlr3.mlr-org.com/reference/mlr_resamplings_cv.html)
- [留一交叉验证 - loo](https://mlr3.mlr-org.com/reference/mlr_resamplings_loo.html)
- [重复交叉验证 - repeated_cv](https://mlr3.mlr-org.com/reference/mlr_resamplings_repeated_cv.html)
- [bootstrapping - bootstrap](https://mlr3.mlr-org.com/reference/mlr_resamplings_bootstrap.html)
- [二次抽样 - subsampling](https://mlr3.mlr-org.com/reference/mlr_resamplings_subsampling.html)
- [holdout - holdout](https://mlr3.mlr-org.com/reference/mlr_resamplings_holdout.html)
- [样本重采样 - insample](https://mlr3.mlr-org.com/reference/mlr_resamplings_insample.html)
- [自定义重采样 - custom](https://mlr3.mlr-org.com/reference/mlr_resamplings_custom.html)

以下部分提供了如何设置和选择重采样策略以及如何随后实例化重采样过程的指导。

以下是重采样过程的图示：

```{r echo = FALSE, fig.cap="机器学习流程 source: https://mlr3book.mlr-org.com/images/ml_abstraction.svg"}
knitr::include_graphics("https://mlr3book.mlr-org.com/images/ml_abstraction.svg")
```

### 设置

在本例中，我们再次使用了penguins任务和rpart包中的一个简单分类树。

```{r}
library("mlr3verse")

task = tsk("penguins")
learner = lrn("classif.rpart")
```

在对数据集执行重采样时，我们首先需要定义应该使用哪种方法。mlr3重采样策略及其参数可以通过查看数据进行查询。mlr_resamplings字典的表输出：

```{r}
as.data.table(mlr_resamplings)
```

用于特殊用例的额外重采样方法将通过扩展包提供，例如用于空间数据的[mlr3spatiotemporal](https://github.com/mlr-org/mlr3spatiotemporal)。

在前面进行的模型拟合相当于“holdout 重采样”，所以让我们首先考虑这个。同样，我们可以通过`$get()`或方便的function `rsmp()`从字典mlr_resamplings中检索元素：

```{r}
resampling = rsmp("holdout")
print(resampling)
```

注意`$is_instantiated`字段被设置为FALSE。这意味着我们还没有在数据集上实际应用该策略。在下一节实例化中对数据集应用该策略。

默认情况下，我们得到`.66/.33`数据的分割。有两种方法可以改变比例：

1. 使用命名列表覆盖`$param_set$values`中的槽：

```{r}
resampling$param_set$values = list(ratio = 0.8)
```

2. 使用时直接指定重采样参数：

```{r}
rsmp("holdout", ratio = 0.8)
```

### 实例化

到目前为止，我们只是设置和选择了重采样策略。

为了实际执行分割并获得训练和测试分割的指标，重采样需要一个Task。通过调用`instantiate()`方法，我们将数据的索引分解为用于训练集和测试集的索引。这些结果索引存储在Resampling对象中。为了更好地说明以下操作，我们切换到一个3折交叉验证：

```{r}
resampling = rsmp("cv", folds = 3)
resampling$instantiate(task)
resampling$iters

str(resampling$train_set(1))
str(resampling$test_set(1))
```

请注意，如果你想以公平的方式比较多个学习器，则必须对每个学习器使用相同的实例化重采样。下一节基准测试将讨论一种大大简化多个学习器之间比较的方法。

### 执行

对于一个任务，一个学习者和一个重采样对象，我们可以调用`resample()`，它根据给定的重采样策略重复地将学习器应用于手头的任务。这又创建了一个ResampleResult对象。我们告诉`resample()`通过将store_models选项设置为true来保留拟合的模型，然后开始计算：

```{r}
task = tsk("penguins")
learner = lrn("classif.rpart", maxdepth = 3, predict_type = "prob")
resampling = rsmp("cv", folds = 3)

rr = resample(task, learner, resampling, store_models = TRUE)
print(rr)
```

rr存储返回的ResampleResult提供了各种getter方法来访问存储的信息：

- 计算所有重采样迭代的平均性能：

```{r}
rr$aggregate(msr("classif.ce"))
```

- 提取单个重采样迭代的性能：

```{r}
rr$score(msr("classif.ce"))
```

- 检查警告或错误：

```{r}
rr$warnings
rr$errors
```

提取并检查重采样分割：

```{r}
rr$resampling

rr$resampling$iters
str(rr$resampling$test_set(1))
str(rr$resampling$train_set(1))
```

- 检索特定迭代的学习器并检查它：

```{r}
lrn = rr$learners[[1]]
lrn$model
```

- 提取预测：

```{r}
rr$prediction() # all predictions merged into a single Prediction object
rr$predictions()[[1]] # prediction of first resampling iteration
```

- 过滤器只保留指定的迭代：

```{r}
rr$filter(c(1, 3))
print(rr)
```

### 自定义重采样

有时需要使用自定义分割进行重采样，例如重现研究报告中的结果。可以使用“custom”模板创建手动重采样实例。

```{r}
resampling = rsmp("custom")
resampling$instantiate(task,
  train = list(c(1:10, 51:60, 101:110)),
  test = list(c(11:20, 61:70, 111:120))
)
resampling$iters

resampling$train_set(1)
resampling$test_set(1)
```

### 使用预定义组进行重采样

与定义列角色“group”（表示特定的观察结果应该总是在测试集或训练集中一起出现）相反，我们还可以提供一个因子变量来预定义所有分区（还在进行中）。

这意味着该变量的每个因素级别单独组成测试集。因此，此方法不允许设置“fold”参数，因为折叠的数量是由因子级别的数量决定的。

这种预定义的方法在mlr2中称为“阻塞”。它不应该与mlr3spatiotempcv中的术语“块”混淆，后者指的是利用平方/矩形分割的一类重采样方法。

### 可视化重采样结果

mlr3viz提供了一个`autoplot()`方法。为了展示一些图，我们创建了一个具有两个特征的二元分类任务，使用10倍交叉验证执行重采样并可视化结果：

```{r}
task = tsk("pima")
task$select(c("glucose", "mass"))
learner = lrn("classif.rpart", predict_type = "prob")
rr = resample(task, learner, rsmp("cv"), store_models = TRUE)

# boxplot of AUC values across the 10 folds
autoplot(rr, measure = msr("classif.auc"))

# ROC curve, averaged over 10 folds
autoplot(rr, type = "roc")

# learner predictions for first fold
rr$filter(1)
autoplot(rr, type = "prediction")
```

[autoplot.ResampleResult()](https://mlr3viz.mlr-org.com/reference/autoplot.ResampleResult.html)的手册页列出了所有可用的绘图类型。

### 可视化重采样分区

Mlr3spatiotempcv提供`autoplot()`方法来可视化时空数据集的重采样分区。更多信息，请参阅[函数参考](https://mlr3spatiotempcv.mlr-org.com/reference)和vignette[“时空可视化”](https://mlr3spatiotempcv.mlr-org.com/articles/spatiotemp-viz.html)。

![](https://mlr3book.mlr-org.com/02-basics-resampling_files/figure-html/02-basics-resampling-018-1.svg)


## 基准测试

比较不同学习器在多个任务和/或不同重采样方案上的表现是一个常见的任务。在机器学习领域，这种操作通常被称为“基准测试”。mlr3包提供了方便的`benchmark()`函数。

### 设计创建

在mlr3中，我们要求你提供基准实验的“设计”。这样的设计本质上是你想要执行的设置表。它由任务、学习者和重采样三方面的唯一组合组成。

我们使用`benchmark_grid()`函数来创建一个详尽的设计并正确地实例化重采样，这样对于每个任务，所有的学习器都在相同的训练/测试分割上执行。我们设置学习器预测概率，并告诉他们预测训练集的观察值(通过设置predict_sets为c(“train”，“test”))。此外，我们使用`tsks()`、`lrns()`和`rsmps()`来检索Task、Learner和Resampling的列表，其方式与`tsk()`、`lrn()`和`rsmp()`相同。

```{r}
library("mlr3verse")

design = benchmark_grid(
  tasks = tsks(c("spam", "german_credit", "sonar")),
  learners = lrns(c("classif.ranger", "classif.rpart", "classif.featureless"),
    predict_type = "prob", predict_sets = c("train", "test")),
  resamplings = rsmps("cv", folds = 3)
)
print(design)
```

创建的设计可以传递给`benchmark()`以开始计算。也可以手动创建自定义设计。然而，如果你使用`data.table()`创建一个自定义任务，**如果你在创建设计之前没有手动实例化重采样，那么设计的每一行的train/test分割将是不同的**。查看`benchmark_grid()`的[帮助页面](https://mlr3.mlr-org.com/reference/benchmark_grid.html)以获得一个示例。

### 结果的执行和汇总

基准设计完成后，可以直接调用`benchmark()`：

```{r}
# execute the benchmark
bmr = benchmark(design)
```

注意，我们没有手动实例化重采样实例。`benchmark_grid()`会为我们处理它：在构建穷举网格期间，每个重采样策略都会为每个任务实例化一次。

基准测试完成后，我们可以使用`$aggregate()`聚合性能结果。我们创建了两个度量来计算训练集和预测集的AUC：

```{r}
measures = list(
  msr("classif.auc", predict_sets = "train", id = "auc_train"),
  msr("classif.auc", id = "auc_test")
)

tab = bmr$aggregate(measures)
print(tab)
```

我们可以进一步汇总这些结果。例如，我们可能有兴趣知道哪个学习器在同时完成所有任务时表现最好。简单地将性能与平均值相加通常在统计上并不合理。相反，我们按任务分组计算每个学习器的等级统计量。然后将计算得到的按学习器分组的秩用data.table进行汇总。由于需要最大化AUC，我们将这些值乘以−1，使最好的学习者的排名为1。

```{r}
library("data.table")
# group by levels of task_id, return columns:
# - learner_id
# - rank of col '-auc_train' (per level of learner_id)
# - rank of col '-auc_test' (per level of learner_id)
ranks = tab[, .(learner_id, rank_train = rank(-auc_train), rank_test = rank(-auc_test)), by = task_id]
print(ranks)
```

```{r}
# group by levels of learner_id, return columns:
# - mean rank of col 'rank_train' (per level of learner_id)
# - mean rank of col 'rank_test' (per level of learner_id)
ranks = ranks[, .(mrank_train = mean(rank_train), mrank_test = mean(rank_test)), by = learner_id]

# print the final table, ordered by mean rank of AUC test
ranks[order(mrank_test)]
```

### 可视化基准测试结果

与绘制任务、预测或重新取样结果类似，mlr3viz还提供了用于基准测试结果的`autoplot()`方法。

```{r}
autoplot(bmr) + ggplot2::theme(axis.text.x = ggplot2::element_text(angle = 45, hjust = 1))
```

我们也可以绘制ROC曲线。为此，我们首先需要过滤BenchmarkResult，使其只包含一个Task：

```{r}
bmr_small = bmr$clone()$filter(task_id = "german_credit")
autoplot(bmr_small, type = "roc")
```

### 提取结果

一个BenchmarkResult对象本质上是多个ResampleResult对象的集合。由于这些数据存储在聚合的`data.table()`的列中，我们可以很容易地提取它们：

```{r}
tab = bmr$aggregate(measures)
rr = tab[task_id == "german_credit" & learner_id == "classif.ranger"]$resample_result[[1]]
print(rr)
```

我们现在可以使用前一节中所示的方法之一来研究这个重采样，甚至是单个重采样迭代：

```{r}
measure = msr("classif.auc")
rr$aggregate(measure)

# get the iteration with worst AUC
perf = rr$score(measure)
i = which.min(perf$classif.auc)

# get the corresponding learner and train set
print(rr$learners[[i]])

head(rr$resampling$train_set(i))
```

### 转换和合并

可以使用转换器`as_benchmark_result()`将ResampleResult转换为BenchmarkResult。另外，两个BenchmarkResults可以合并到一个更大的结果对象中。

```{r}
task = tsk("iris")
resampling = rsmp("holdout")$instantiate(task)

rr1 = resample(task, lrn("classif.rpart"), resampling)
rr2 = resample(task, lrn("classif.featureless"), resampling)

# Cast both ResampleResults to BenchmarkResults
bmr1 = as_benchmark_result(rr1)
bmr2 = as_benchmark_result(rr2)

# Merge 2nd BMR into the first BMR
bmr1$combine(bmr2)

bmr1
```


## 二分类

目标变量只包含两个类的分类问题称为“二分类”。对于这样的二分类目标变量，你可以在任务创建期间在分类任务对象中指定正类。如果在构造过程中没有显式设置，则阳性类默认为目标变量的第一个水平。

```{r}
# during construction
data("Sonar", package = "mlbench")
task = as_task_classif(Sonar, target = "Class", positive = "R")

# switch positive class to level 'M'
task$positive = "M"
```

### ROC和阈值

ROC分析是机器学习的一个子领域，研究对二元预测系统的评价。我们前面已经看到，可以通过访问`$confusion`字段来检索Prediction的混淆矩阵：

```{r}
learner = lrn("classif.rpart", predict_type = "prob")
pred = learner$train(task)$predict(task)
C = pred$confusion
print(C)
```


混淆矩阵包含正确和不正确的类分配的计数，按类标签分组。列显示真实的(观察到的)标签，行显示预测的标签。正数总是在混淆矩阵的第一行或第一行。因此，C11中的元素是我们的模型预测阳性类并正确的次数。类似地，C22中的元素是我们的模型预测负类的次数，并且是正确的。对角线上的元素被称为真阳性(TP)和真阴性(TN)。元素C12是我们错误预测阳性标签的次数，被称为假阳性(FP)。元素C21被称为假阴性(FN)。

我们现在可以将混乱矩阵的行和列规范化，从而得出一些有用的指标。

![](https://mlr3book.mlr-org.com/images/confusion_matrix.png)

很难同时实现高TPR和低FPR，所以我们使用它们来构建ROC曲线。我们通过分类器的TPR和FPR值来描述分类器，并在坐标系中绘制它们。最好的分类器位于左上角。最差的分类器位于对角线。对角线上的分类器产生随机标签(具有不同的比例)。如果每个阳性的x将被随机分为25%的“阳性”，我们得到的TPR为0.25。如果我们将每个负x随机分配给“正”，我们得到的FPR为0.25。在实践中，我们永远不应该得到对角线以下的分类器，因为将预测的标签倒置将导致对角线上的反射。

评分分类器是产生分数或概率的模型，而不是离散标签。为了从mlr3中的学习者获得概率，你必须为ref("LearnerClassif")设置`predict_type = "prob"`。分类器是否能预测概率在其`$predict_types`字段中给出。阈值灵活地将测量的概率转换为标签。如果f^(x)>τ else预测0，则预测1(正类)通常情况下，可以使用τ=0.5将概率转换为标签，但对于不平衡或成本敏感的情况，另一个阈值可能更合适。阈值设置之后，可以使用标签上定义的任何度量。

```{r}
library("mlr3viz")

# TPR vs FPR / Sensitivity vs (1 - Specificity)
autoplot(pred, type = "roc")

# Precision vs Recall
autoplot(pred, type = "prc")
```

### 阈值调整

能够预测出正向分类概率的学习者器常使用简单的规则来确定预测的分类标签：如果概率超过阈值t=0.5，则选择正向分类标签，否则选择负向分类标签。如果模型没有很好地校准或类标签严重不平衡，选择一个不同的阈值可以帮助提高预测性能。

在这里，我们将阈值更改为t=0.2，提高了真实阳性率(TPR)。注意，有了新的阈值，更多来自正类别的观察将被正确地归类为正的标签，但与此同时，真实正阴性率(TNR)下降。根据应用的不同，这可能是一种需要的权衡。

```{r}
measures = msrs(c("classif.tpr", "classif.tnr"))
pred$confusion

pred$score(measures)

pred$set_threshold(0.2)
pred$confusion
```

阈值还可以用mlr3pipelines包进行调优，例如使用[PipeOpTuneThreshold](https://mlr3pipelines.mlr-org.com/reference/mlr_pipeops_tunethreshold.html)。



