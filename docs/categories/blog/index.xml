<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on ShixiangWang
王诗翔</title>
    <link>/categories/blog/</link>
    <description>Recent content in Blog on ShixiangWang
王诗翔</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Wed, 01 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="/categories/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>mlr3（三）模型优化</title>
      <link>/blog/mlr3-model-optimization/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-model-optimization/</guid>
      <description>来源：https://mlr3book.mlr-org.com/optimization.html
模型优化
机器学习算法为其超参数设置了默认值。不管怎样，用户需要更改这些超参数，以在给定的数据集上实现最佳性能。不建议手动选择超参数值，因为这种方法很少能获得最佳性能。为了证实所选超参数（=调优）的有效性，建议进行数据驱动的优化。为了优化机器学习算法，必须指定（1）搜索空间，（2）优化算法(又称调优方法)，（3）评估方法，即重采样策略，（4）性能度量。
总而言之，关于调优的小节介绍：
 进行经验超参数选择 选择优化算法 简洁地指定搜索空间 触发调优 自动调优  本小节还需要包mlr3tuning，这是一个支持超参数调优的扩展包。
特征选择
本章的第二部分介绍特征选择，也称为变量选择。特征选择是寻找数据相关特征子集的过程。执行选择的一些原因：
 增强模型的可解释性 加速模型拟合 通过降低数据中的噪声来提高学习性能  在本文中，我们主要集中在最后一个方面。有不同的方法来识别相关的特征。在特征选择的分章中，我们强调了三种方法：
 运用过滤算法根据分数独立地选择特征 根据变量重要性过滤选择特征 包装器方法迭代地选择特性以优化性能度量  注意，过滤器不需要学习器。变量重要性过滤器需要一个学习器，该学习器在训练时可以计算特征的重要性值。获得的重要值可用于数据子集，然后可用于训练学习器。包装器方法可以用于任何学习器，但需要对学习器进行多次训练。
嵌套重采样
为了更好地估计泛化性能并避免数据泄漏，外部（性能）和内部（调优/特征选择）重采样过程都是必要的。本章将讨论以下特点：
 嵌套重采样中的内重采样和外重采样策略 嵌套重采样的执行 执行重采样迭代的评估  本小节将提供如何实现嵌套重采样的说明，包括mlr3中的内重采样和外重采样。
超参数调优 超参数是机器学习模型的二阶参数，虽然在模型估计过程中往往没有明确优化，但会对模型的结果和预测性能产生重要影响。通常，超参数在训练模型之前是固定的。但是，由于模型的输出可能对超参数的规范很敏感，因此通常建议对哪些超参数设置可以产生更好的模型性能做出明智的决定。在许多情况下，超参数设置可能是预先选择的，但在将模型拟合到训练数据上之前，尝试不同的设置可能是有利的。这个过程通常被称为模型“调优”。
超参数调优是通过mlr3tuning扩展包支持的。下面是这个过程的说明：
mlr3tuning的核心是R6类：
TuningInstanceSingleCrit，TuningInstanceMultiCrit：这两个类描述调优问题并存储结果。
Tuner：这个类是调优算法实现的基类。
TuningInstance* 类 下面的小节审查了皮马印度糖尿病数据集上的简单分类树的优化。
library(&amp;quot;mlr3verse&amp;quot;) task = tsk(&amp;quot;pima&amp;quot;) print(task) ## &amp;lt;TaskClassif:pima&amp;gt; (768 x 9) ## * Target: diabetes ## * Properties: twoclass ## * Features (8): ## - dbl (8): age, glucose, insulin, mass, pedigree, pregnant, pressure, ## triceps 我们使用rpart中的分类树，并选择我们想要调优的超参数的子集。这通常被称为“调优空间”。</description>
    </item>
    
    <item>
      <title>mlr3（二）基础</title>
      <link>/blog/mlr3-basics/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-basics/</guid>
      <description>来源：https://mlr3book.mlr-org.com/basics.html
本文将教你基本的mlr3知识，以及它的R6类和操作以用于机器学习。典型的机器学习工作流是这样的:
 Figure 1: 机器学习流程 source: https://mlr3book.mlr-org.com/images/ml_abstraction.svg  mlr3将数据封装在任务中，并将其分解为互不重叠的训练集和测试集。由于我们感兴趣的模型外推到新的数据，而不仅仅是记忆训练数据，独立的测试数据允许客观地评估模型的泛化。训练数据被提供给一个机器学习算法，在mlr3中我们称之为learner。learner利用训练数据建立输入特征与输出目标值之间关系的模型。然后使用该模型对测试数据进行预测，并将其与参考真值进行比较，以评估模型的质量。mlr3提供了许多不同的度量方法，根据预测值和实际值之间的差异来量化模型的执行情况。通常这是一个数字分数。
将数据分割为训练集和测试集、建立模型并对其进行评估的过程可能会重复多次，每次从原始数据中重新采样不同的训练集和测试集。多重重采样迭代允许我们对特定类型的模型获得更好、更一般化的性能估计，因为它是在不同的条件下测试的，而且由于数据重采样的特定方式，它不太容易产生偏差。
在许多情况下，这个简单的工作流不足以处理真实世界的数据，可能需要规范化（标准化）、缺失值的输入或特征选择。我们将在以后介绍更复杂的工作流程。
本文涵盖以下小主题：
任务：
任务用元信息封装数据，比如预测目标列的名称。我们将介绍如何：
 访问预定义的任务 指定一个任务类型 创建一个任务 使用任务的API工作 为任务的行和列分配角色 实施任务mutator 获取存储在任务中的数据  学习器
学习器封装机器学习算法来训练模型并对任务进行预测。它们由R和其他包提供。我们将介绍如何：
 访问随mlr3而来的分类和回归学习器集合，并检索特定的学习器 访问学习器的超参数值集并修改它们  如何修改和扩展学习器涵盖在补充高级技术部分。
训练和预测
关于训练和预测方法的部分说明了如何使用任务和学习器训练模型并对新数据集进行预测。特别地，我们将介绍如何：
 正确设置任务和学习器 为一项任务设置训练和测试分割（集） 在训练集上训练学习器以生成模型 生成测试集的预测 通过比较预测值和实际值来评估模型的性能  重采样
重采样是一种创建训练和测试分割（集）的方法。我们将介绍：
 访问和选择重采样策略 通过应用重采样实例化分割到训练集和测试集 执行重采样以获得结果  关于重采样的附加信息可以在嵌套重采样部分和模型优化一章中找到。
基准测试
基准测试用于比较不同模型的性能，例如不同学习器训练的模型，不同任务训练的模型，或不同重采样方法训练的模型。我们介绍如何
 创建一个基准设计 执行设计并汇总结果 将基准测试对象转换为重采样对象  二分类
二值分类是分类的一种特殊情况，预测的目标变量只有两个可能的值。在这种情况下，还需要考虑其他因素。特别是：
 ROC曲线和预测一个类和另一个类的阈值 阈值调整  在详细介绍如何使用mlr3进行机器学习之前，我们先简要介绍一下R6，因为它是R相对较新的一部分。mlr3严重依赖于R6，它提供的所有基本构造都是R6类：
 任务 task 学习器 learner 测量 measure 重采样 resamplings  快速R6入门介绍 R6是R最新的面向对象编程(OO)方言之一。它解决了R中早期OO实现的缺点，比如我们在mlr中使用的S3。如果你以前做过面向对象编程，那么R6应该很熟悉。我们关注的是R6的部分，你需要知道在这里使用mlr3。</description>
    </item>
    
    <item>
      <title>R小技巧：分组应用和排序去重的应用与比较</title>
      <link>/blog/r-tricks-remove-duplicates-after-ordering/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/r-tricks-remove-duplicates-after-ordering/</guid>
      <description>问题与方案 假设我们有这样一个数据集：
df &amp;lt;- data.frame( c1 = c(&amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), c2 = c(1, 3, 2, 1, 4, 2) ) df out c1 c2 out 1 a 1 out 2 a 3 out 3 a 2 out 4 b 1 out 5 b 4 out 6 c 2 如果我们想保留每个c1分类和分类下的最大值，你会怎么操作？
思考一分钟。
如果使用惯了tidyverse套装，我们脑子里容易冒出来的是这样的解法：使用分组应用。
library(dplyr) df |&amp;gt; group_by(c1) |&amp;gt; summarize(c2 = max(c2, na.rm = TRUE)) out # A tibble: 3 × 2 out c1 c2 out &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; out 1 a 3 out 2 b 4 out 3 c 2 在数据不是特别大的时候，使用这种策略没有任何问题。但如果分组有成千上万，分组的时间代价就很高了。有没有其他的方式可以解决该问题呢？</description>
    </item>
    
    <item>
      <title>forestmodel给多水平变量添加整体p值</title>
      <link>/blog/forestmode-set-overall-pva-for-variable-with-multiple-levels/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/forestmode-set-overall-pva-for-variable-with-multiple-levels/</guid>
      <description>前段时间收到来信：
1Hi Shixiang 2 3I am writing to you about the forestmodel package in R. 4 5Thank you so much for the wonderful package that you created. 6 7I was wondering if there is a way to display the wald test p-value which is important for variables that have more than two levels. I tried to work around the code but did not find a way out. 8 9Best 10Aniket 我不是作者，搞错了人，问我干啥呢～自个提问嘛</description>
    </item>
    
    <item>
      <title>mlr3（一）快速入门</title>
      <link>/blog/mlr3-quickstart/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-quickstart/</guid>
      <description>来源：https://mlr3book.mlr-org.com/quickstart.html
安装包：
install.packages(&amp;quot;mlr3&amp;quot;) 作为一个30秒的介绍性示例，我们将在虹膜数据集的前120行训练决策树模型，并对最后30行进行预测，测量训练模型的准确性。
library(&amp;quot;mlr3&amp;quot;) task = tsk(&amp;quot;iris&amp;quot;) learner = lrn(&amp;quot;classif.rpart&amp;quot;) # 为任务的一个子集（前120行）训练这个学习器的模型 learner$train(task, row_ids = 1:120) # 决策树模型 learner$model ## n= 120 ## ## node), split, n, loss, yval, (yprob) ## * denotes terminal node ## ## 1) root 120 70 setosa (0.41666667 0.41666667 0.16666667) ## 2) Petal.Length&amp;lt; 2.45 50 0 setosa (1.00000000 0.00000000 0.00000000) * ## 3) Petal.Length&amp;gt;=2.45 70 20 versicolor (0.00000000 0.71428571 0.28571429) ## 6) Petal.</description>
    </item>
    
    <item>
      <title>PR曲线与AUC</title>
      <link>/blog/pr-curve-and-auc-value/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/pr-curve-and-auc-value/</guid>
      <description>这里直接使用ROCR包提供的数据作为示例：
library(ROCR) data(ROCR.simple) pred &amp;lt;- prediction(ROCR.simple$predictions, ROCR.simple$labels) perf &amp;lt;- performance(pred,&amp;quot;tpr&amp;quot;,&amp;quot;fpr&amp;quot;) plot(perf) ## precision/recall curve (x-axis: recall, y-axis: precision) perf1 &amp;lt;- performance(pred, &amp;quot;prec&amp;quot;, &amp;quot;rec&amp;quot;) plot(perf1, xlim = c(0, 1), ylim = c(0, 1)) 使用 PRROC 包获取PR AUC值并且绘图：
pr &amp;lt;- PRROC::pr.curve(ROCR.simple$predictions, weights.class0 = ROCR.simple$labels, curve = TRUE) pr ## ## Precision-recall curve ## ## Area under curve (Integral): ## 0.7815038 ## ## Area under curve (Davis &amp;amp; Goadrich): ## 0.7814246 ## ## Curve for scores from 0.</description>
    </item>
    
    <item>
      <title>《R语言数据科学导论》笔记</title>
      <link>/blog/note-for-r-data-science-intro/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/note-for-r-data-science-intro/</guid>
      <description>原始资料来源：https://github.com/leovan/data-science-introduction-with-r
特征工程 特征工程是将原始数据转换成特征的过程。更通俗地说，特征工程就是人工设计模型的输入变量 x的过程。
主要分为：
 数据预处理 特征提取和选择 特征变换和编码 特征监控  数据预处理 对赃数据进行清洗，包括括缺失，噪声，不一致等等一系列问题数据。
剔除处理：
 样本去重。同一个ID出现多次重复记录。 特征去重。例如月收入和年收入，它们都是用于表征收入特征，关系只差常数倍。 常量特征剔除。即常量或方差近似为0的特征。caret包中的nearZeroVar()可以帮助我们识别该类特征。  缺失值处理：
 探索缺失值：mice包的md.pattern()，VIM包的aggr()/marginplot()。 处理：  删除法，可以直接使用na.omit()。 插补法，如果该特征对最终的预测结果影响较小，则我们可以直接删除该特征；相反如果该特征对预测结果影响较大，直接删除会对模型造成较大的影 响，此时我们需要利用其它的方法对该特征的缺失值进行填补。其中最简单的方式是利用均值，中位数或众数等统计量对其进行简单插补。这种插补方法是建立在完全随机缺失的前提假设下，同时会造成变量方差变小。    异常值是指样本中存在的同样本整体差异较大的数据。
分为2类：
采样是一种常见的预处理技术。
 随机采样。每个样本单位被抽中的概率相等，样本的每个单位完全独立，彼此间无一定的关联性和排斥性。 分层采样。将抽样单位按某种特征或某种规则划分为不同的层，然后从不同的层中独立、随机地抽取样本。从而保证样本的结构与总体的结构比较相近，从而提高估计的精度。可以利用sampling::strata()。 欠采样和过采样。我们经常会碰到不同分类的样本比例相差较大的问题，这种问题会对我们构建模型造成很大的影响，因此从数据角度出发，我们可以利用欠采样或过采样处理这种现象。可以利用ROSE::ovun.sample()。  特征变换和编码 无量纲化 通过归一化，我们可以消除不同量纲下的数据对最终结果的影响。
1normalize &amp;lt;- function(x) { 2 # 计算极值 3 x_min &amp;lt;- min(x) 4 x_max &amp;lt;- max(x) 5 # 归一化 6 x_n &amp;lt;- (x - x_min) / 7 (x_max - x_min) 8 # 将极值作为结果的属性 9 attr(x_n, 10 &amp;#39;min&amp;#39;) &amp;lt;- x_min 11 attr(x_n, 12 &amp;#39;max&amp;#39;) &amp;lt;- x_max 13 # 返回归一化后结果 14 x_n 15} 标准化。</description>
    </item>
    
    <item>
      <title>解决由于网络问题导致的stringi安装失败问题</title>
      <link>/blog/install-stringi-when-bad-acess-to-gh/</link>
      <pubDate>Thu, 26 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/install-stringi-when-bad-acess-to-gh/</guid>
      <description>这是一个我每次重装R，或者在新的系统上使用R进行包安装，都会遇到的问题。
stringi是tidyverse的一个核心包，基本上必装。但由于gayhub经常访问有问题，这个包安装时所需要的依赖文件会下载不了。 解决的办法是手动下载，然后进行安装：
1wget https://github.com/gagolews/stringi/archive/master.zip -O stringi.zip 2# 如果上面github的链接无法下载，尝试： 3# wget https://download.fastgit.org/gagolews/stringi/archive/master.zip -O stringi.zip 4unzip stringi.zip 5sed -i &amp;#39;/\/icu..\/data/d&amp;#39; stringi-master/.Rbuildignore 6R CMD build stringi-master 7R CMD INSTALL stringi*.tar.gz 参考：https://stackoverflow.com/questions/31942322/how-to-install-stringi-from-local-file-absolutely-no-internet-access#</description>
    </item>
    
    <item>
      <title>CentOS/Redhat R包使用最新的gcc编译</title>
      <link>/blog/use-new-gcc-on-centos-for-r/</link>
      <pubDate>Wed, 25 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/use-new-gcc-on-centos-for-r/</guid>
      <description>R包在Linux下编译不通过，原因是gcc版本太低怎么办？
一些有C++代码的R包可能会用到一些新的C++特性，需要C++11或者C++14。这个问题通常在CentOS/红帽系统上出现，因为系统稳定的要求，这个系列的系统它的C++版本很低。 但请读者前往注意了别自己编译新版本的gcc，然后替换掉系统的。这种操作我试过几次，系统基本上就崩掉了。
正确的解决方式是安装独立的gcc，通过环境变量引用和使用它。
在Root用户下操作：
1yum install centos-release-scl 2yum install devtoolset-9 然后在你使用R的用户下操作：
1# If you use your non-root account to install packages,  2# change /root to /home/your_id in the following command 3mkdir -p /root/.R 4vi /root/.R/Makevars 将下面的内容写入打开的文件，然后保存：
1CXX11=/opt/rh/devtoolset-9/root/usr/bin/g++ -std=c++11 -fPIC 2CXX14=/opt/rh/devtoolset-9/root/usr/bin/g++ -std=c++14 -fPIC </description>
    </item>
    
    <item>
      <title>使用modules包来组织R的函数集合</title>
      <link>/blog/use-modules-to-organize-r-functions/</link>
      <pubDate>Tue, 24 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/use-modules-to-organize-r-functions/</guid>
      <description>接触过Python的朋友肯定对模块很熟悉，R的代码组织方式以包为主。但基于文件的模块形式也是可以实现的，modules 包提供了这种支持。
安装和使用 直接从CRAN下载即可：
1install.packages(&amp;#34;modules&amp;#34;) 使用了解2个函数的使用就可以了。
一是import()，用于替换library()加载包。
1&amp;gt; library(modules) 2&amp;gt; gp = import(&amp;#39;ggplot2&amp;#39;) 3Masking (modules:ggplot2): 4 `Position` from: base 5&amp;gt; args(gp$ggplot) 6function (data = NULL, mapping = aes(), ..., environment = parent.frame()) 7NULL 8&amp;gt; args(ggplot) 9function (data = NULL, mapping = aes(), ..., environment = parent.frame()) 10NULL 这样我们可以直接使用这个函数，也可以通过gp这个对象去访问可用的函数。
如果不想要在全局直接访问包内的函数，在导入时设定attach=FALSE。
1&amp;gt; dp &amp;lt;- import(dplyr, attach = FALSE) 2Masking (modules:dplyr): 3 `intersect` from: base 4 `setdiff` from: base 5 `setequal` from: base 6 `union` from: base 7&amp;gt; select 8错误: 找不到对象&amp;#39;select&amp;#39; 9&amp;gt; dp$select 10function (.</description>
    </item>
    
  </channel>
</rss>
