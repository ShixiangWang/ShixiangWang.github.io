<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on ShixiangWang
(王诗翔)</title>
    <link>/categories/blog/</link>
    <description>Recent content in Blog on ShixiangWang
(王诗翔)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 20 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="/categories/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>R使用Jupyter Notebook那些事</title>
      <link>/blog/r-jupyter-notebook/</link>
      <pubDate>Thu, 20 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/r-jupyter-notebook/</guid>
      <description>在操作的一台服务器的R没有X11支持，Jupyter一运行代码就报错Kernel挂掉。而RStudio Server可以直接点击切换图形后端为Cairo。 Jupyter 怎么搞呢？
首先尝试了Stack Overflow的一个办法，在 ~/.Rprofile 中加入代码：
setHook(packageEvent(&amp;#34;grDevices&amp;#34;, &amp;#34;onLoad&amp;#34;), function(...) grDevices::X11.options(type = &amp;#34;cairo&amp;#34;)) options(device = &amp;#34;x11&amp;#34;) 最后还是在IRkernel的官方仓库问题区看到解决的办法：
 https://github.com/IRkernel/IRkernel/issues/388
 加入下面的语句就可以了。
## Set default &amp;#39;type&amp;#39; for png() calls - useful when X11 device is not available! ## NOTE: Needs &amp;#39;cairo&amp;#39; capability options(bitmapType=&amp;#39;cairo&amp;#39;) 完成后重启下Jupyter，然后等待一会，再试一试。
另外，由于Jupyter无法像R一样拖动绘图窗口实时修改图形大小，如果要改动的话需要 提前用下面的语句设置：
options(repr.plot.width = 4, repr.plot.height = 3) 我们可以写一个简化函数：
setplot = function(w=5, h=4, d = c(&amp;#34;svg&amp;#34;, &amp;#34;png&amp;#34;)) { options(repr.plot.width = w, repr.plot.height = h) options(jupyter.plot_mimetypes = paste0(&amp;#34;image/&amp;#34;, switch( match.</description>
    </item>
    
    <item>
      <title>R(Studio)中指定外部软件路径</title>
      <link>/blog/r-studio-specify-path/</link>
      <pubDate>Wed, 19 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/r-studio-specify-path/</guid>
      <description>在安装R kernel时报错：
&amp;gt; IRkernel::installspec() Error in IRkernel::installspec() : jupyter-client has to be installed but “jupyter kernelspec --version” exited with code 127. In addition: Warning message: In system2(&amp;#34;jupyter&amp;#34;, c(&amp;#34;kernelspec&amp;#34;, &amp;#34;--version&amp;#34;), FALSE, FALSE) : error in running command 这种情况是R识别不了外部的$PATH，我们可以通过~/.Rprofile进行修改配置。
在RStudio中运行file.edit(&amp;quot;~/.Rprofile&amp;quot;)或者手动打开，添加如下内容：
old_path = Sys.getenv(&amp;#34;PATH&amp;#34;) Sys.setenv(PATH = paste(old_path, &amp;#34;~/miniconda3/bin/&amp;#34;, sep = &amp;#34;:&amp;#34;)) 北外镜像近期使用经验整体还是比较稳定的，不妨添加：
options(BioC_mirror=&amp;#34;https://mirrors.bfsu.edu.cn/bioconductor&amp;#34;) options(&amp;#34;repos&amp;#34; = c(CRAN=&amp;#34;https://mirrors.bfsu.edu.cn/CRAN/&amp;#34;)) ~/.condarc中可以添加：
channels: - defaults show_channel_urls: true default_channels: - https://mirrors.bfsu.edu.cn/anaconda/pkgs/main - https://mirrors.bfsu.edu.cn/anaconda/pkgs/r - https://mirrors.bfsu.edu.cn/anaconda/pkgs/msys2 custom_channels: conda-forge: https://mirrors.bfsu.edu.cn/anaconda/cloud msys2: https://mirrors.</description>
    </item>
    
    <item>
      <title>dials自定义grid示例</title>
      <link>/blog/dials-grid/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/dials-grid/</guid>
      <description>  library(dials) library(dplyr) param_quant = function (label, range = c(10L, 1000L), type = &amp;quot;integer&amp;quot;, trans = NULL) { stopifnot(length(label) == 1L) names(label) = label new_quant_param(type = type, range = range, inclusive = c(TRUE, TRUE), trans = trans, label = label, finalize = NULL) } param_class = function (label, values) { stopifnot(length(label) == 1L) names(label) = label new_qual_param(type = &amp;quot;character&amp;quot;, values = values, label = label, finalize = NULL) } abc = grid_max_entropy(param_quant(&amp;quot;scale&amp;quot;), param_quant(&amp;quot;abc&amp;quot;, range = c(0, 1), trans = scales::log10_trans()), param_class(&amp;quot;gender&amp;quot;, c(&amp;quot;F&amp;quot;, &amp;quot;M&amp;quot;)), size = 100, original = FALSE) plot(abc$scale, abc$abc) </description>
    </item>
    
    <item>
      <title>通过tidymodels使用XGBOOST</title>
      <link>/blog/using-xgboost-with-tidymodels/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/using-xgboost-with-tidymodels/</guid>
      <description>原文：https://www.r-bloggers.com/2020/05/using-xgboost-with-tidymodels/
 XGBoost是一个最初用C++编写的机器学习库，通过XGBoost R包中移植到R。在过去的几年里，XGBoost在Kaggle竞赛中的有效性让它大受欢迎。在Tychobra, XGBoost是我们的首选机器学习库。
 在2016年和2017年，Kaggle被两种方法所主导:梯度升压机和深度学习。具体来说，梯度增强用于结构化数据可用的问题，而深度学习用于图像分类等感知问题。前者的实践者几乎总是使用优秀的XGBoost库。
 Max Kuhn和Rstudio的其他人最近将他们的注意力从caret转向了 tidymodels （caret的继承者）。“tidymodels”是一个R包的集合，它们一起工作来简化和加强模型训练和优化。随着最近发布的tidymodels.org，我们觉得是时候给tidymodels R包一个机会了。
概览 这篇文章中我们使用tidymodels包训练和优化XGBoost模型。我们使用的AmesHousing数据集，其中包含来自艾奥瓦州艾姆斯的住房数据。我们的模型将预测房屋销售价格。
加载包：
# data library(AmesHousing) # data cleaning library(janitor) # data prep library(dplyr) # tidymodels library(rsample) library(recipes) library(parsnip) library(tune) library(dials) library(workflows) library(yardstick) # speed up computation with parrallel processing (optional) library(doParallel) all_cores &amp;lt;- parallel::detectCores(logical = FALSE) registerDoParallel(cores = all_cores) 加载数据：
# set the random seed so we can reproduce any simulated results. set.seed(1234) # load the housing data and clean names ames_data &amp;lt;- make_ames() %&amp;gt;% janitor::clean_names()  Step 0：探索性数据分析 在这一点上，我们通常会对数据做一些简单的图表和总结，以获得对数据的高层次理解。为了简单起见，我们将从这篇文章中删除EDA过程，但是，在实际分析中，理解业务问题和执行有效的EDA通常是分析中最耗时和最关键的方面。</description>
    </item>
    
    <item>
      <title>Flux Overview：建立一个简单的预测</title>
      <link>/blog/flux-overview/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/flux-overview/</guid>
      <description>julia&amp;gt; using Flux julia&amp;gt; actual(x) = 4x + 2 actual (generic function with 1 method) 提供训练和测试集 julia&amp;gt; x_train, x_test = hcat(0:5...), hcat(6:10...) ([0 1 … 4 5], [6 7 … 9 10]) julia&amp;gt; y_train, y_test = actual.(x_train), actual.(x_test) ([2 6 … 18 22], [26 30 … 38 42]) 通常，你的训练和测试数据来自真实世界的观察，但这个函数将模拟真实世界的观察。
构建一个模型预测 julia&amp;gt; model = Dense(1, 1) Dense(1, 1) # 2 parameters julia&amp;gt; model.weight 1×1 Matrix{Float32}: -1.0924082 julia&amp;gt; model.bias 1-element Vector{Float32}: 0.0 在底层，一个全连接层是一个含有weight和bias的结构体。weight代表权重矩阵，bias代表偏置向量。 我们可以使用其他方式思考一个模型。在Flux中，模型是概念上的预测函数：</description>
    </item>
    
    <item>
      <title>如何用Julia语言创建软件包</title>
      <link>/blog/julia-packaging/</link>
      <pubDate>Mon, 27 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/julia-packaging/</guid>
      <description>源：https://jaantollander.com/post/how-to-create-software-packages-with-julia-language/
 介绍 本文将教你如何用Julia编程语言创建一个开源的软件包，并使用基于git的工作流开发软件包。例如，你将了解如何自动化单元测试和文档部署，以及发布包的新版本。此外，我们创建了Julia播放列表的逐步视频教程，以指导你通过这个过程。
安装Julia 首先，我们将从julialang网站的下载页面安装Julia编程语言。在Linux中，我们可以将存档解压缩到所需的位置。我们将使用~/software/目录。
~/.bashrc添加配置如下：
export PATH=&amp;#34;$PATH:$HOME/software/julia-1.5.3-linux-x86_64/julia-1.5.3/bin&amp;#34; 上面的版本根据你自己的实际情况进行修改。
Julia REPL  How to use Julia REPL for Developing Packages
 我们可以通过在命令行输入Julia来打开Julia REPL。Julia REPL有四种不同的模式：
 Julia模式julia&amp;gt;用于测试Julia代码。 包管理模式pkg&amp;gt;用于执行包管理命令。可以使用]进行激活。 帮助模式help?&amp;gt;用于打印帮助和文档。我们可以使用?进行激活。 Shell模式shell&amp;gt;用于执行shell命令。我们可以使用分号;进行激活。  我们可以使用回车符从其他模式退回到Julia模式。
包结构 我们的包结构将遵循使用Julia语言创建软件包的官方示例。我们可以在Example.jl中找到示例库。我们可以克隆示例库并对其进行研究。以点开头的目录可能被操作系统隐藏了。我们可以从文件系统设置中显示隐藏的文件。Julia包结构如下所示：
Example/ ├─ .git/ ├─ .github/ │ └─ workflows/ │ ├─ TagBot.yml │ └─ ci.yml ├─ docs/ │ ├─ src/ │ │ └─ index.md │ ├─ Project.toml │ └─ make.jl ├─ src/ │ └─ Example.jl ├─ test/ │ └─ runtests.</description>
    </item>
    
    <item>
      <title>ggplot结合点图与箱线图的问题与解决</title>
      <link>/blog/ggplot-overlay-points-on-boxplot-qa/</link>
      <pubDate>Wed, 08 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/ggplot-overlay-points-on-boxplot-qa/</guid>
      <description>最近在使用ggplot2对箱线图叠加点图是发现奇怪的现象，只要我改变点的形状，绘图就出问题了。
下面我通过一个简单的示例展示这个问题。
我们先生成一组简单的数据，并绘制一个正常的叠加图：
library(ggplot2) library(dplyr) head(mtcars) ## mpg cyl disp hp drat wt qsec vs am gear carb ## Mazda RX4 21.0 6 160 110 3.90 2.620 16.46 0 1 4 4 ## Mazda RX4 Wag 21.0 6 160 110 3.90 2.875 17.02 0 1 4 4 ## Datsun 710 22.8 4 108 93 3.85 2.320 18.61 1 1 4 1 ## Hornet 4 Drive 21.4 6 258 110 3.</description>
    </item>
    
    <item>
      <title>Complexheatmap合并figure legends以利用空间</title>
      <link>/blog/merge-complexheatmap-figure-legends/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/merge-complexheatmap-figure-legends/</guid>
      <description>最近在绘制热图的时候遇到这样一个问题：
library(ComplexHeatmap) set.seed(1) m = matrix(sample(c(&amp;quot;&amp;quot;, &amp;quot;AMP&amp;quot;, &amp;quot;DEL&amp;quot;), 100, prob = c(0.8, 0.1, 0.1), replace = TRUE), nrow = 10) rownames(m) = paste0(&amp;quot;A&amp;quot;, 1:10) colnames(m) = paste0(&amp;quot;B&amp;quot;, 1:10) oncoPrint(m, top_annotation = HeatmapAnnotation(cbar = anno_oncoprint_barplot(), g = c(&amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;))) 我们可以看到Alterations和g两组图例是按行排列的，这样需要整个图更多的宽度，如果按列排列个人感觉效果更好。 翻遍了complexHeatmap的文档和相关QA，没有搜索到相关的内容。比较接近的是设置legends_param列表，它可以操作单个图例 的排列，比如分类特别多，可以指定为几行几列这种。但无法排布多个legends的布局。
最终还是把问题抛给了开发者顾神（https://github.com/jokergoo/ComplexHeatmap/issues/850）。
下面是作者提供的简单解决办法：
ht = oncoPrint(m, top_annotation = HeatmapAnnotation(cbar = anno_oncoprint_barplot(), g = c(&amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;A&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;B&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;C&amp;quot;, &amp;quot;D&amp;quot;))) draw(ht, merge_legends = TRUE) 感谢感谢！</description>
    </item>
    
    <item>
      <title>深度学习笔记摘录</title>
      <link>/blog/deep-learning-notes/</link>
      <pubDate>Thu, 02 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/deep-learning-notes/</guid>
      <description>https://discoverml.github.io/simplified-deeplearning/
 神经网络中的非线性导致它的大部分代价函数变得非凸，对于非凸的损失函数，梯度下降算法不能保证收敛到全局最优，因此神经网络模型中的参数初始化是非常重要的，通常会将所有的权重初始化为一个较小的随机数，并且将偏置初始化为0或者较小的正值。
大多数现代神经网络使用极大似然原理，也就是说模型的损失函数和训练数据和模型分布间的交叉熵等价。
由于神经网络的特殊结构，导致神经网络必须注意的是损失函数的梯度必须有足够大的预测性，这样才能很好的指导算法的学习。很多输出单元都会包含一个指数函数，当变量取绝对值非常大的负值时函数会变得饱和（函数变得很“平”），函数梯度变得很小，而负的对数似然能够抵消输出单元中的指数效果。
对于实现最大似然估计的交叉熵损失函数通常需要使用正则化技术来避免过拟合的情况。
对于隐藏单元，logistic sigmoid函数只有在输入接近0的时候它们的梯度才比较大，因此不鼓励将它们作为前馈网络中的隐藏层，对于上文提到的输出层，对数似然损失函数抵消了sigmoid的饱和性，因此可以用在基于梯度学习的输出单元中。
双曲正切激活函数通常比sigmoid函数表现要好，它和sigmoid激活函数关系密切。
神经网络的架构（architecture）指网络的整体架构：神经网络需要多少单元以及单元之间的连接方式。大多数神经网络被组织成层的单元组，然后将这些层布置成链式结构，其中每一层是前一层的函数。在这个链式结构中，主要考虑的是网络的深度和每一层的宽度。通常来说更深的网络对每一层能够使用更少的单元数以及参数，并且泛化效果更好，但是它也更能难以训练。
万能近似定理（universal approximation theorem）表明一个前馈神经网络如果具有线性输出层和至少一层具有任何一种 “挤压”性质的激活函数（如logistic sigmoid激活函数）的隐藏层，只要给与网络足够数量的隐藏单元，它可以以任意精度来近似任何从一个有限维空间到另一有限维空间的Borel可测函数，前馈网络的导数也可以任意精度来近似函数的导数。万能近似定理说明了存在达到任意精度的这么一个神经网络，但是没有指出这个网络有多大。
在很多情况下，使用更深的模型能够减少表示期望函数所需的单元数量，并且可以减少泛化误差。增加网络的深度往往能够得到比增加宽度更加好的泛化能力。（宽度是指隐藏层的维度）
过拟合是无法彻底避免的，我们所能做的只是“缓解”以减少其风险。
L2参数正则化（也称为岭回归、Tikhonov正则）通常被称为权重衰减（weight decay)，是通过向目标函数添加一个正则项使权重更加接近原点。
将L2正则化的参数惩罚项Ω(θ)由权重衰减项修改为各个参数的绝对值之和，即得到L1正则化
将目标函数作二次泰勒展开近似
相比L2正则化，L1正则化会产生更稀疏的解。正则化策略可以被解释为最大后验（MAP）贝叶斯推断。L2 正则化相当于权重是高斯先验的MAP贝叶斯推断L1 正则化相当于权重是Laplace先验的MAP贝叶斯推。
作为约束的范数惩罚。较大的α将得到一个较小的约束区域，而较小的α将得到一个较大的约束区域。（重投影的显示约束对优化过程增加了一定的稳定性。例如当学习率较高时，很可能进入正反馈，即大的权重诱导大的梯度，使权重获得较大的更新。如果持续更新增加权重大小，则会使θ迅速增大而远离原点发生溢出。）
让机器学习模型泛化得更好的最好办法是使用更多的数据进行训练，因此需要在有限的数据中创建假数据并添加到训练集中。数据集增强在对象识别领域是特别有效的方法。
 数据集的各种变换，如对图像的平移、旋转和缩放。 在输入层注入噪声，也可以看作数据集增强的一种方法（如去噪自编码器）。通过将随机噪声添加到输入再进行训练能够大大改善神经网络的健壮性。  噪声鲁棒性。
 将噪声加入到输入。在一般情况下,注入噪声远比简单地收缩参数强大,特别是噪声被添加到隐藏单元时会更加强大（如Dropout）。对于某些模型而言，向输入添加方差极小的噪声等价于对权重施加范数惩罚。 将噪声加入到权重。这项技术主要用于循环神经网络。这可以被解释为关于权重的贝叶斯推断的随机实现。贝叶斯学习过程将权重视为不确定的,并且可以通过概率分布表示这种不确定性，向权重添加噪声是反映这种不确定性的一种实用的随机方法。（这种正则化鼓励参数进入权重小扰动对输出相对影响较小的参数空间区域。换句话说，它推动模型进入对权重小的变化相对不敏感的区域，找到的点不只是极小点，而且是由平坦区域所包围的极小点） 将噪声加入到输出。即显式地对标签上的噪声进行建模。正则化具有k个输出的softmax函数的模型。softmax函数值永远在0-1区间内而达不到0或1，标签平滑的优势是能够防止模型追求确切概率而不影响模型学习正确分类。  多任务学习（参数共享）：从深度学习的观点看，底层的先验知识为：能解释数据变化的因素中，某些因素是跨多个任务共享的。
如果我们只要返回使验证集误差最低的参数，就可以获得验证集误差更低的模型。这种策略被称为提前终止（early stopping）。由于它的有效性和简单性，这可能是深度学习中最常用的正则化形式。（提前终止相当于L2正则化，提前终止为何具有正则化效果？其真正机制可理解为将优化过程的参数空间限制在初始参数值θ0的小邻域内。提前终止比L2正则化更具有优势，提前终止能自动确定正则化的正确量，而权重衰减需要进行多个不同超参数的训练实验。）
稀疏表示也是卷积神经网络经常用到的正则化方法。L1正则化会诱导稀疏的参数，使得许多参数为0；而稀疏表示是惩罚神经网络的激活单元，稀疏化激活单元。换言之，稀疏表示是使得每个神经元的输入单元变得稀疏，很多输入是0。
Bagging(bootstrap aggregating)是通过结合几个模型降低泛化误差的技术。主要想法是分别训练几个不同的模型，然后让所有模型表决测试样例的输出。这是机器学习中常规策略的一个例子,被称为模型平均(model averaging)。采用这种策略的技术被称为集成方法。
Bagging是一种允许重复多次使用同一种模型、训练算法和目标函数的方法。具体来说,Bagging涉及构造k个不同的数据集。每个数据集从原始数据集中重复采样构成，和原始数据集具有相同数量的样例。模型平均是一个减少泛化误差的非常强大可靠的方法。集成平方误差的期望随集成规模的增大而线性减少。
其他集成方法，如Boosting，通过向集成逐步添加神经网络，可以构建比单个模型容量更高的集成模型。
Dropout可以被认为是集成大量深层神经网络的实用Bagging方法。但是Bagging方法涉及训练多个模型，并且在每个测试样本上评估多个模型。当每个模型都是一个大型神经网络时，Bagging方法会耗费很多的时间和内存。而Dropout则提供了一种廉价的Bagging集成近似，能够训练和评估指数级数量的神经网络。
区别：Bagging所有模型都是独立的。Dropout所有模型共享参数，其中每个模型继承父神经网络参数的不同子集。参数共享使得在有限内存下表示指数级数量的模型变得可能。
Dropout优缺点：
 计算方便 适用广 相比其他正则化方法（如权重衰减、过滤器约束和稀疏激活）更有效 不适合宽度太窄的网络 不适合训练数据太小（如小于5000）的网络。训练数据太小时，Dropout没有其他方法表现好。 不适合非常大的数据集。数据集大的时候正则化效果有限（大数据集本身的泛化误差就很小），使用Dropout的代价可能超过正则化的好处。  有时候我们的真正损失函数，比如 0-1 分类误差并无法被有效的优化，此时我们会使用代理损失函数（surrogate loss function）来作为原来目标的替代，而且会带来好处。比如，正确分类类别的负对数似然通常用作 0-1 损失的替代，。负对数似然允许模型估计给定样本的类别的条件概率，能够输出期望最小分类误差所对应的类型。有些情况下，代理损失函数可以比原损失函数学到更多的东西，比如对数似然代替 0-1 分类误差函数时，当训练集上的误差达到0之后，测试集上的误差还可以持续下降，也就是说此时模型可以继续学习以拉开不同类别直接的距离以提高分类的鲁棒性。也就是说，代理损失函数从训练数据中学到了更多的东西。
使用整个训练集的优化方法被称为批量(batch) 或确定性（deterministic）梯度算法，他们会在每次更新参数时计算所有样本。通常，“批量梯度下降”指使用全部训练集，而“批量”单独出现时，指一组样本。每次只使用部分样本的方法被称为随机（stochastic）或者在线（online）算法。在线通常是指从连续产生的数据流（stream）中提取样本，而不是从一个固定大小的样本中遍历多次采样的情形。大多数深度学习算法介于两者之间，使用一个以上但不是全部的训练样本，传统上称这种方法为小批量（minibatch）或者小批量随机（minibatch stochastic）方法，现在统称为随机（stochastic）方法。
在凸优化问题中，优化问题可以简化为寻找一个局部极小值点，因为任何的局部极小值就是全局最小值。虽然有些凸函数底部是一个很大的平坦区域，并非单一的极值点，但是应用过程中实际上该区域中每一个极小值点都是一个可以接受的点。所以说，对于凸优化问题来说，找到任何形式的临界点，就是找到了一个不错的可行解。而对于非凸函数问题，比如神经网络问题，可能会存在很多的局部极小值点。</description>
    </item>
    
    <item>
      <title>torch入门：使用预训练模型预测图像分类</title>
      <link>/blog/learn-torch-predict-image-with-pretrained-model/</link>
      <pubDate>Wed, 01 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/learn-torch-predict-image-with-pretrained-model/</guid>
      <description>代码来源图书 deep-learning-with-pytorch。
from torchvision import models import torch dir(models) resnet = models.resnet101(pretrained=True) from torchvision import transforms preprocess = transforms.Compose([ transforms.Resize(256), transforms.CenterCrop(224), transforms.ToTensor(), transforms.Normalize( mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225] )]) from PIL import Image img = Image.open(&amp;#34;../data/p1ch2/bobby.jpg&amp;#34;) img_t = preprocess(img) batch_t = torch.unsqueeze(img_t, 0) resnet.eval() out = resnet(batch_t) out with open(&amp;#39;../data/p1ch2/imagenet_classes.txt&amp;#39;) as f: labels = [line.strip() for line in f.readlines()] _, index = torch.max(out, 1) percentage = torch.nn.functional.softmax(out, dim=1)[0] * 100 # 转换为概率 labels[index[0]], percentage[index[0]].</description>
    </item>
    
  </channel>
</rss>
