<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Blog on ShixiangWang
王诗翔</title>
    <link>/categories/blog/</link>
    <description>Recent content in Blog on ShixiangWang
王诗翔</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="/categories/blog/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>读《指北》：多重假设检验记录与思考</title>
      <link>/blog/multiple-stats-testing-and-thinking/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/multiple-stats-testing-and-thinking/</guid>
      <description>本文有记录和思考2个方面，记录是根据《现代科研指北》的统计推断的一部分内容进行记录和学习，思考是在记录和学习的过程中添加一些自己的理解和思索。
首先谈谈为什么是这样的形式，而不是直接转载。对于个人而言，学习的本质是为了掌握知识，而不是记录知识。本文的主题是统计分析特别是组学统计分析中常用却甚少思考的一个基本点：多重比较与假设检验。我不知道有多少人像我一样，在有几年的数据处理经验之后，对这种比较基础的理论还一知半解。 现在，我们可以轻而易举的使用R的p.adj()对p值进行校正，甚至使用 Bioconductor的一些专门的包（如qvalue）进行处理。但我们真的了解它吗？你能简单地说出p.adj()中提供的方法原理和区别吗？如果你的目标是数据分析师，完成工作任务，仅仅作为赚钱养家的技能。ok，没必要深入学习，会调包调函数完全足够了。但如果我们有更高的追求，比如数据科学家， 无论是工业界还是学术界，那么我们必须对概念和问题产生自己的见解。
下面是《指北》中的一些内容。
多重比较的场景 科研里最常用的比较是两独立样本均值比较的t检验与评价单因素多水平影响的方差分析。t检验可以看作方差分析的特例，使用统计量t来比较而方差分析通常是用分类变量所解释的变异比上分类变量以外的变异去进行F检验。换句话讲，如果分类变量可以解释大部分响应变量的变异，我们就说这种分类变量对响应变量的解释有意义。
但是仅仅知道是否受影响是不够的，我们知道的仅仅是存在一种分类方法可以解释响应的全部变化，其内部也是均匀的，但不同分类水平间的差异我们并不知道，这就需要多重比较了。例如，当我们对两组数据做置信度0.05的t检验，我们遇到假阳性的概率为5%。但如果面对多组数据例如3组，进行两两比较的话就有\(3\choose2\)也就是3组对比，那么我们遇到假阳性的概率就为\(1-(1-0.05)^3\)，也就是14.3%，远高于0.05的置信度。组越多，两两对比就越多，整体上假阳性的概率就越来越大，到最后就是两组数据去对比，无论如何你都会检验出差异。
 值得思考的一个点是：这里一般提出的比较是多组，如A、B、C这3个组比较同一个指标的差异。而在组学分析中的比较是固定的A、B这2个组不同的指标的比较。它们能看作一样的事情吗？
  本质上是一样的，关键在对比的数量。我们可以把比较拆开为独立的1对1的比较。那么比较一次假设出现错误的概率是0.05，那么比对的数量越多，整体上的分析结果中出现一次错误的概率会越大于0.05。
 此外就方向而样，虽然我们都不承认零假设（要不然还做什么实验），但当我们默认设定为双尾检验时，假阳性就被默认发生在两个方向上了，这样的多重比较必然导致在其中一个方向上的错误率被夸大了。就影响大小而言，如果我们每次重复都选择效应最强的那一组，重复越多，预设的偏态就越重，换言之，我们的零假设因为重复实验的选择偏好而发生了改变。
 多重比较 那么多重比较如何应对这个问题呢？有两种思路，一种思路是我依旧采取两两对比，进行t检验，但p值的选取方法要修改，例如Bonferroni方法中就把p的阈值调整为进行多重比较的次数乘以计算得到的p值。如果我们关心的因素为2，那么计算得到的p值都要乘2来跟0.05或0.01的边界置信度进行比较；另一种思路则是修改两两比较所用的统计量，给出一个更保守的分布，那么得到p值就会更大。不论怎样，我们这样做都是为了降低假阳性，但同时功效不可避免的降低了。（有得必有失）
多重比较的方法类型包括单步法与逐步法。 单步法只考虑对零假设的影响而不考虑其他影响而逐步法则会考虑其他假设检验对单一检验的影响，例如可以先按不同分组均值差异从大到小排序，先对比第一个，有差异对比下一个，当出现无差异时停止对比；或者从下到大排序，有差异时停止对比，之后均认为有差异。此时还要注意一种特殊情况，因为F检验是从方差角度来考虑影响显著性与否，所以可能存在F检验显著但组间均值差异均不显著的情况，此时要考虑均值间线性组合的新均值的差异性（？？？）。不过，大多数情况我们只用考虑不同组间两两差异比较即可。
具体而言，单步法等方差多重比较最常见的是Tukey’s HSD方法，这是一个两两比较的方法，基于 studentized range 分布计算出q统计量，然后基于这个统计量进行两两间差异的假设检验。该方法适用于分组间等方差等数目的场景，如果分组内数目不同，需要用 Tukey-Kranmer 方法。该方法适用于两两比较，在分组数目相同时统计功效等同于从大到小排序的逐步法。
此外，还有些多重比较的方法在特定学科里也很常见。从总体控制错误率的角度，如果是两两比较应该选 Tukey’s HSD方法；如果侧重组间差异线性组合的均值用 Scheffe test；如果对比数指定了，功效按 Gabriel、GT2、DST、 Bonferroni顺序来选；如果是各分组都跟控制组比，应该选Dunnett法；如果各分组方差不相等，用GH，C，T3等方法。此外，如果打算保证每个比较中的置信水平，应该选 Tukey、 Scheffe、Dunnett法。
 远比想象中要复杂。
  多重检验 与多重比较类似的一个统计推断问题是多重检验问题。多重检验指的是同时进行多次假设检验的场景，其实多重比较可以看作多重检验在方差分析里的一个特例。
举例而言，我对两组样品（暴露组跟对照组）中每一个样品测定了10000个指标，每组有10个样品，那么如果我想知道差异有多大就需要对比10000次，具体说就是10000次双样本t检验。那么如果我对t检验的置信水平设置在95%，也就是5%假阳性，做完这10000次检验，我会期望看到500个假阳性，而这500个有显著差异的指标其实对分组不敏感也可以随机生成。假如真实测到了600个有显著差异的指标，那么如何区分其中哪些是对分组敏感？哪些又仅仅只是随机的呢？随机的会不会只有500个整呢？这个场景在组学技术与传感器技术采集高通量高维数据的今天变得越来越普遍。
这个问题在做经典科研实验时往往会忽略，深层次的原因是经典的科研实验往往是理论或经验主导需要进行检验的假说（注：经典实验比较的数目量也上不去）。例如，我测定血液中白血球的数目就可以知道你是不是处于炎症中，其背后是医学知识的支撑。然而，在组学或其他高通量实验中，研究实际是数据导向的，也就是不管有用没用反正我测了一堆指标，然后就去对比差异，然后就是上面的问题了，我们可能分不清楚哪些是真的相关，哪些又是随机出现的。
对于单次比较，当我们看到显著差异的p值脑子里想的是零假设为真时发生的概率，当我们置信水平设定在0.95而p值低于对应的阈值，那么我们应该拒绝零假设。但对比次数多了从概率上就会出现已经被拒绝的假设实际是错误的而你不知道是哪一个。整体错误率控制的思路就是我不管单次比较了，我只对你这所有的对比次数的总错误率进行控制。还是上面的例子，对于10000次假设检验我只能接受1个错误，整体犯错概率为0.0001，那么对于单次比较，其假阳性也得设定在这个水平上去进行假设检验，结果整体上错误率是控制住了，但对于单次比较就显得十分严格了。下面用一个仿真实验来说明：
# 随机数的10000次比较 set.seed(42) pvalue &amp;lt;- NULL for (i in 1:10000){ a &amp;lt;- rnorm(10) b &amp;lt;- rnorm(10) c &amp;lt;- t.test(a,b) pvalue[i] &amp;lt;- c$p.value } # 看下p值分布 hist(pvalue) # 小于0.</description>
    </item>
    
    <item>
      <title>使用GenomicRanges操作区间数据</title>
      <link>/blog/operate-range-data-with-genomicranges/</link>
      <pubDate>Mon, 01 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/operate-range-data-with-genomicranges/</guid>
      <description>资料来源：Bioinformatics Data Skills
 准备 涉及的包：
 GenomicRanges - 表示和处理基因组区间 GenomicFeatures - 表示和处理基因组元件（基因、外显子等） Biostrings/BSgenome - 操作基因组序列 rtracklayer - 读入常见生物学数据文件（BED、GTF/GFF和WIG等）   从IRanges开始 基本用法 IRange是区间的基本数据构造：
library(IRanges) rng = IRanges(start = 1, end = 15) rng ## IRanges object with 1 range and 0 metadata columns: ## start end width ## &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; ## [1] 1 15 15 构造出来的对象区间起始和终止都是闭合的，另外与R索引一致，都是从1开始。
 构造向量 向量是最常见的了：
x = IRanges(start=c(4, 7, 2, 20), end=c(13, 7, 5, 23)) x ## IRanges object with 4 ranges and 0 metadata columns: ## start end width ## &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; &amp;lt;integer&amp;gt; ## [1] 4 13 10 ## [2] 7 7 1 ## [3] 2 5 4 ## [4] 20 23 4 给区间命名：</description>
    </item>
    
    <item>
      <title>机器学习分类性能常用一些指标</title>
      <link>/blog/measures-for-classification-in-ml/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/measures-for-classification-in-ml/</guid>
      <description>这篇文章的目的主要是记录一些分类器相关的度量指标。 从混淆矩阵中衍生出来的指标特别多，而我们中文与英文可能又存在多种对应 关系，这造成了记忆和理解上的困难。
 来源：https://zhuanlan.zhihu.com/p/111274912
 灵敏度与特异性 灵敏度 灵敏度（sensitivity），又称真阳性率，即实际有病，并且按照该诊断试验的标准被正确地判为有病的百分比。它反映了诊断试验发现病人的能力。
该研究中，根据手术病理结果有100例乳腺癌患者，但胸部扪诊只检测出其中80例患者。这说明该诊断试验只能发现80%的病人。
特异性 特异度（specificity），又称真阴性率，即实际没病，同时被诊断试验正确地判为无病的百分比。它反映了诊断试验确定非病人的能力。
例如有900例不是乳腺癌患者，但胸部扪诊只识别了其中的800例。特异性为89%。
比较 如果一项诊断试验的灵敏度比较低，那么会出现很多假阴性的患者。这会延误患者的就诊，影响病程发展和愈后，甚至导致患者过早死亡。
如果一项诊断试验的特异度比较低，那么会出现很多假阳性的患者。这样会浪费医疗资源、造成患者无端的恐慌和焦虑。
这两个指标主要可以通过ROC曲线同时查看。
 本节参考：https://www.mediecogroup.com/zhuanlan/lessons/229/  精度与召回率 首先需要说明的是这两者类似于ROC曲线，可以通过PR曲线同时进行观测。
精度 精度，precision。预测所关注的事件的结果中，预测正确的概率（共预测了 20 次，8 次正确，12 次错误）。
与Accuracy的区别：Accuracy不管正负类，算全部预测正确占总数的比率。而精度关注 预测正确的正类数目占全部正类数目的比率。
召回率/查全率 recall。对所有所关注的类型（一般就是正类），将其预测出的概率（共 10 个癌症患者，预测出 8 个）。
 本节参考：https://www.jianshu.com/p/dcf4deddff9f  </description>
    </item>
    
    <item>
      <title>此mutate非彼mutate</title>
      <link>/blog/this-mutate-is-not-that-mutate/</link>
      <pubDate>Fri, 29 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/this-mutate-is-not-that-mutate/</guid>
      <description>程序出乎意料，怎么办？
今天在星球圈里收到提问：
我对ddply()这个函数是不熟悉的，只知道hadley一个过时的包plyr里有一系列这样的函数。 所以我首先想到的是这位朋友用错了。不过我马上就排除了，这种问题是非常容易发现和处理的。
因此还是得动手实际检验一下这个问题在我的电脑上是否可以重复。
我们首先把数据导入进来：
library(scales) library(tidyverse) library(plyr) ts &amp;lt;- openxlsx::read.xlsx(&amp;quot;~/Downloads/示例数据.xlsx&amp;quot;) head(ts) ## Name variable value ## 1 SLCO1B1 TCGA-44-2666 3.52916020 ## 2 GCGR TCGA-44-2666 0.08499940 ## 3 HTR3A TCGA-44-2666 0.05029628 ## 4 CA9 TCGA-44-2666 0.19814361 ## 5 TNFSF11 TCGA-44-2666 0.28202803 ## 6 FGB TCGA-44-2666 4.56223499 按照两种不同的方法生成结果：
out1 = ts %&amp;gt;% ddply(., .(variable), transform, rescale = rescale(value)) %&amp;gt;% arrange(variable, Name) head(out1) ## Name variable value rescale ## 1 ADRB2 TCGA-05-4390 2.</description>
    </item>
    
    <item>
      <title>ezcox v1.0.2 更新</title>
      <link>/blog/ezcox-v1-2-update/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/ezcox-v1-2-update/</guid>
      <description>针对@lijing-lin在GitHub的ezcox仓库提出的Fast way to add interaction terms?问题， 这两天闲暇时废了些脑细胞进行解决。同时也fix之前记录的一个遗留问题。
remotes::install_github(&amp;quot;ShixiangWang/ezcox&amp;quot;) 交互项支持 之前为了解决用户数据列名不符合的R命名规则，在源代码例自动对不合法名字进行了反撇号标记。 这会导致R的公式没法进行解析，例如sex:age会被判断为一个列名，R的公式没法解析它，因为 找不到数据中对应的sex:age列，所以会报错。
library(survival) library(ezcox) lung$ph.ecog &amp;lt;- factor(lung$ph.ecog) ezcox(lung, covariates = c(&amp;quot;age&amp;quot;), controls = &amp;quot;sex:ph.ecog&amp;quot;) ## # A tibble: 5 × 12 ## Variable is_control contrast_level ref_level n_contrast n_ref beta HR ## &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;chr&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;lgl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; ## 1 age FALSE age NA NA NA 0.00844 1.01 ## 2 age TRUE sex:ph.ecog0 NA NA NA -0.890 0.</description>
    </item>
    
    <item>
      <title>R6编程</title>
      <link>/blog/r6-programming/</link>
      <pubDate>Fri, 22 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/r6-programming/</guid>
      <description>原文来源：https://r6.r-lib.org/articles/Introduction.html
 R6包为R提供了封装的面向对象编程的实现（有时也被称为经典的面向对象编程）。它类似于R的引用类，但它更高效，不依赖于S4类和方法包。
与R中的许多对象不同，R6类的实例(对象)具有引用语义。R6类还支持：
 公共和私有方法 active bindings 跨包工作的继承(超类)  基础 下面是如何创建一个简单的R6类。public参数是一个项目列表，可以是函数和字段(非函数)。函数将被用作方法。
library(R6) Person &amp;lt;- R6Class( &amp;quot;Person&amp;quot;, public = list( name = NULL, hair = NULL, initialize = function(name = NA, hair = nA) { self$name &amp;lt;- name self$hair &amp;lt;- hair self$greet() }, set_hair = function(val) { self$hair &amp;lt;- val }, greet = function() { cat(paste0(&amp;quot;Hello, my name is &amp;quot;, self$name, &amp;quot;.\n&amp;quot;)) } ) ) 使用$new()进行初始化：
ann &amp;lt;- Person$new(&amp;quot;Ann&amp;quot;, &amp;quot;black&amp;quot;) ## Hello, my name is Ann.</description>
    </item>
    
    <item>
      <title>跳过R包check系统使用无法显式载入DESCRIPTION的外部包</title>
      <link>/blog/skip-r-check-system/</link>
      <pubDate>Wed, 20 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/skip-r-check-system/</guid>
      <description>.attach_this &amp;lt;- function() { if (!&amp;#34;ggpubr&amp;#34; %in% (.packages())) { tryCatch(eval(parse(text = &amp;#34;library(ggpubr)&amp;#34;)), error = function(e) { eval(parse(text = &amp;#39;remotes::install_github(&amp;#34;ggpubr&amp;#34;)&amp;#39;)) eval(parse(text = &amp;#34;library(ggpubr)&amp;#34;)) }) } } `%:::%` &amp;lt;- function(pkg, fun, inherits = TRUE) { get(fun, envir = asNamespace(pkg), inherits = inherits ) } .attach_this() ggboxp &amp;lt;- &amp;#34;ggpubr&amp;#34;%:::%&amp;#34;ggboxplot&amp;#34; args(ggboxp) </description>
    </item>
    
    <item>
      <title>rstatix使用fisher检验处理比例关系</title>
      <link>/blog/rstatix-fisher-test/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/rstatix-fisher-test/</guid>
      <description>Fisher检验R默认就可以做，但是只支持一次检验，为了更好地处理数据，这篇文章通过rstatix包的相关功能来 学习一些新知识。
library(rstatix)  本文的相关代码文档可以运行?rstatix::fisher_test()查看。
 比较2个比例值 生成数据：
xtab &amp;lt;- as.table(rbind(c(490, 10), c(400, 100))) dimnames(xtab) &amp;lt;- list( group = c(&amp;quot;grp1&amp;quot;, &amp;quot;grp2&amp;quot;), smoker = c(&amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;) ) xtab ## smoker ## group yes no ## grp1 490 10 ## grp2 400 100 进行比较：
fisher_test(xtab) ## # A tibble: 1 × 3 ## n p p.signif ## * &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; ## 1 1000 8.77e-22 **** # 给出更多的比较信息 fisher_test(xtab, detailed = TRUE) ## # A tibble: 1 × 8 ## n estimate p conf.</description>
    </item>
    
    <item>
      <title>解决igraph使用optimap_函数报错：GLPK is not available, Unimplemented function call</title>
      <link>/blog/fix-igprah-glpk-error/</link>
      <pubDate>Sat, 02 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/fix-igprah-glpk-error/</guid>
      <description>在使用igraph的测试用例时，发生GLPK相关的报错：
&amp;gt; g &amp;lt;- make_graph(&amp;#34;Zachary&amp;#34;) &amp;gt; oc &amp;lt;- cluster_optimal(g) Error in cluster_optimal(g) : At optimal_modularity.c:85 : GLPK is not available, Unimplemented function call GitHub的帖子#273对该问题进行了一些 积极的讨论，不过主要集中在MacOS系统上。而我要解决的是CentOS上的问题。
不过原理相通，加上cluster_optimal函数文档的描述，大体知道了CRAN不允许igraph团队 内置该库，所以从1.2.1版本后就移除了，因此需要安装包之前在相关系统上安装好该库， 这样该包安装的时候就能够编译相应的函数。否则，相应的函数使用就会报错。
一种解决的思路就是安装之前的版本，我尝试了下，发现一些编译报错。可能是旧代码存在一些 bug吧，所以只能用最新版本。
这样需要先用root权限安装库：
yum install glpk glpk-devel 然后再安装：
install.packages(&amp;#34;igraph&amp;#34;) 安装时间会比较长。
如果仔细观察的话，会发现g++的命令中会指定加入-lglpk选项用于加入相关的库进行编译。
g++ -m64 -std=gnu++11 -shared -L/usr/lib64/R/lib -Wl,-z,relro -o igraph.so AMD/Source/amd.o AMD/Source/amd_1.o AMD/Source/amd_2.o AMD/Source/amd_aat.o AMD/Source/amd_control.o AMD/Source/amd_defaults.o AMD/Source/amd_dump.o AMD/Source/amd_global.o AMD/Source/amd_info.o AMD/Source/amd_order.o AMD/Source/amd_post_tree.o AMD/Source/amd_postorder.o AMD/Source/amd_preprocess.o AMD/Source/amd_valid.o AMD/Source/amdbar.o CHOLMOD/Check/cholmod_check.o CHOLMOD/Check/cholmod_read.o CHOLMOD/Check/cholmod_write.o CHOLMOD/Cholesky/cholmod_amd.o CHOLMOD/Cholesky/cholmod_analyze.o CHOLMOD/Cholesky/cholmod_colamd.o CHOLMOD/Cholesky/cholmod_etree.o CHOLMOD/Cholesky/cholmod_factorize.o CHOLMOD/Cholesky/cholmod_postorder.</description>
    </item>
    
    <item>
      <title>「转载」可重复性危机</title>
      <link>/blog/reproducibility-issue/</link>
      <pubDate>Wed, 29 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/reproducibility-issue/</guid>
      <description>原文来自《现代科研指北》第3.3节。
 可重复性危机是当前科研领域里最大的问题，如果结论不可被重复验证，那么科学性就无从谈起。这里我们先讨论科研里通用假设检验的问题，然后讨论下规律性，最后介绍应对这个危机的可重复性研究与开放科学趋势。
3.3.1 零假设显著性检验（NHST） 零假设显著性检验（NHST）则是可重复性危机的核心。NHST 更常见的形式是 p 值，也就是在零假设成立的条件下某事件发生的概率。打个比方，我们从一个混合了黑白两种颜色小球的口袋里有放回的取一个小球三次，结果都是白球。这里我们设定零假设为黑球白球各一半，那么发生三次白球的概率为12.5%，这个不算极端。但是，如果有放回取了十次，结果还是都是白球，这情况发生概率大概为千分之一，这就比较极端了。在此基础上，我们有理由认为零假设不成立，而此时就需要一个阈值来帮助我们判断是否成立，目前学术界会认为5%或0.05的概率可以作为显著性与否的阈值。科研中我们会去计算零假设下出现当前实验结果的概率，也就是p值，如果低于阈值就可以认为是极端事件就拒绝零假设而高于阈值则认为零假设下可能发生。
当然，我们现在科研用的p值还会考虑零假设之外的备择假设，如果拒绝了零假设就转而接受备择假设。不过一旦引入备择假设就需要讨论错误，这里我们把决策出的结果分为阴性与阳性，而事实分为真假。零假设为真但接受了备择假设的情况，这就是假阳性或者第一类错误；零假设为假但没拒绝零假设就是假阴性或者第二类错误。这里我们可以看到第一类错误与前面设定的决策阈值密切相关，如果设定在5%或者0.05，那么我们就有5%的可能性做出了错误判断。第二类错误则与统计功效也就是真阴性的概率有关，通常会设定在80%，如果功效过低，例如10%，那么犯第二类错误的概率就很高。举例来说，我脚43码的但我不知道，这时去买鞋别人问我脚尺码我说44码的其实是错了，但不影响脚能穿进去，此时尺码的区别功效就不足。但如果我穿久了就会发现确实是大了，此时相当于我通过多次实验或采样提高了统计功效，但可能这个差别虽然明显但也不影响穿。通常NHST关心第一类错误，但设计实验会考虑第二类错误，通过提高样本量来提高统计功效。
p 值有多流行呢？根据 Jeff Leek 的估计，如果把 p 值当成一篇文献，那么其被引次数已经超过 300 万次了，当之无愧的史上被引次数之王，甩第二名一个数量级。原因其实很简单，p 值已经渗透到几乎所有学科的研究中了，特别是实验学科。可想而知，如果产生 p 值的 NHST 出了问题其影响力有多大。下面谈下 NHST 具体的问题：
如果一个假设对另一个假设来说很稀少，NHST 会在很低的条件概率下拒绝掉，然后那些稀少的事情在 NHST 里就成了无法被检验的事情。这个例子最早是 Cohen 提出用来说明人们在使用 NHST 时的问题。零假设是某人是中国人，备择假设是非中国人。我们知道张三是人大代表的概率大概是百万分之二，这是个事实。不过这个事实在零假设里很难发生，备择假设里也无法发生。零假设我们拒绝了某人是中国人，那么根据 NHST，他不是中国人。但问题是人大代表一定要是中国人，此时就会出现事实跟NHST矛盾的情况。在此类问题里，NHST 永远无法认定稀有事件，也就是功效永远不足，并会给出错误答案。
这个问题本质上是多数人在使用 p 值时搞混了条件概率，拿上面人大代表的例子来说，我们的假设 H0 在面对张三这个数据 D 时给出了拒绝 p(H0|D)=0p(H0|D)=0，这个决定是构建在假设 H0 成立时出现 D 的概率太低（即 p(D|H0)p(D|H0)）之上，也就是说 NHST 下，我们默认下面的概率是成立的：
p(D|H0)=p(H0|D)p(D|H0)=p(H0|D)如果你修过任何基础的统计学课程都会知道这两个概率之间差了一个贝叶斯公式。通过使用贝叶斯定理，在新数据出现后原有概率是要被更新而不是直接拒绝掉的。p 值给的是前者，要想知道随机生成的概率，需要知道零假设为真的概率。通俗点说就是 NHST 属于革命派，不认可就打倒你；贝叶斯属于改良派，用新的证据更新原有理论。这个问题的本质就是把假设下的事实与事实下的假设搞混导致的，这是 NHST 的一个致命问题，然而致命问题可不止这一个。
过去的一百年，测量方法的精度是在不断提高的，而精度其实又会影响研究结果，很不幸，也是通过 NHST 来进行的。其实 NHST 在实验物理学里用的还是好好的，例如我去检测一个物理量，只有数据出现在其理论预测下数值四五个标准差以外才会对理论产生实质作用。此时，测量精度越高，由于测量误差导致的对原有理论的冲击就会越少，因为物理学的预测性要比化学生物等学科要好不少且此时 NHST 检测的原有理论是比较真实的。但在其他学科，特别是心理学跟医学的控制实验里，在实验开始前你几乎就可以确定零假设是不成立的，要不然你也没必要分组，此时你去搞 NHST ，几乎一定可以找到差异，此时测量精度如果不断上升，那么你会识别到一系列差异，但这些差异的效果是无法体现在p值里的，p值可能非常小，但效应却属于明显但很微弱，这样的结果也许可以发表，但对实际问题的解决几乎没有贡献。更极端的情况是如果你加大了样本量来提高统计功效，你总是能发现差异的，也就是你的零假设里原有学科理论为真也是会被方法学进步给推翻的。总结下就是 Meehl 在60年代就提出的悖论：方法学的进步与增大样本数对于相对硬（理论根基深厚）的学科证伪是正面的，但对相对软（理论比较模糊）的学科则是弱化。方法学悖论的根基其实是应用学科与基础学科的矛盾，基础学科用 NHST 检验观察事实中的理论，但应用学科用 NHST 来检验的是实验设计预测下的事实，此时实验设计的那个假设与 NHST 的零假设并不对应，而 NHST 先天弱化零假设的问题就凸显了。</description>
    </item>
    
  </channel>
</rss>
