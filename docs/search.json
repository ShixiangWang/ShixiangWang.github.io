[
  {
    "objectID": "posts/2023-04-08-yiyi-with-book-by-y/index.html",
    "href": "posts/2023-04-08-yiyi-with-book-by-y/index.html",
    "title": "晒晒娃和Y叔R书的合照",
    "section": "",
    "text": "买了一本Y叔最新出的新书，出版社的张编辑又送了一本，这里晒一下崽崽和图书的照片。\n\n\n摄影自我媳妇"
  },
  {
    "objectID": "posts/2023-05-12-start-a-new-research-direction/index.html",
    "href": "posts/2023-05-12-start-a-new-research-direction/index.html",
    "title": "Start a new research direction",
    "section": "",
    "text": "Copied from a slide (Liulab?).\n\n\nIs the new direction is important?\n\nI can explain its importance to laymen\nThere are basic science, translational and industry interests\nI am willing to devote the next 5-10 years working on it\n\nDo we have any advantage working on this?\nWhat can we actually do (expertise)?"
  },
  {
    "objectID": "posts/2023-05-02-random/index.html",
    "href": "posts/2023-05-02-random/index.html",
    "title": "随想",
    "section": "",
    "text": "越长大，突然明白这个世界都是在玩一场资源分配的游戏。\n卷不是目的，只是无能为力。\n超脱者永远是少数。\n所谓，求仙不得仙，只能老实做人。"
  },
  {
    "objectID": "posts/2023-06-14-use-just/index.html",
    "href": "posts/2023-06-14-use-just/index.html",
    "title": "使用 Just 重复构建",
    "section": "",
    "text": "Just（https://just.systems/）是一个命令行运行容器，它只是简单的运行你输入的命令，以方便重复构建。\n它没有 Make 那么复杂，这真是我喜欢它的原因。很久之前我很想学习 Make/Makefile，但一直未能成行。Just 让我意识到，我可能根本不需要学习 Make，也能开始很好地学会使用构建。\n我把 Just 的文档看完后发现，其实核心要点就在 README 的图里，而复杂的特征需求往后再说，可能一直都用不上。\n\n\n来源：https://github.com/casey/just"
  },
  {
    "objectID": "posts/2023-05-31-scrna-seq_online-00/index.html",
    "href": "posts/2023-05-31-scrna-seq_online-00/index.html",
    "title": "scRNA-seq_online 00：包准备",
    "section": "",
    "text": "参考资料：https://hbctraining.github.io/scRNA-seq_online/"
  },
  {
    "objectID": "posts/2023-05-31-scrna-seq_online-00/index.html#安装包",
    "href": "posts/2023-05-31-scrna-seq_online-00/index.html#安装包",
    "title": "scRNA-seq_online 00：包准备",
    "section": "安装包",
    "text": "安装包\n安装 CRAN 包：\ninstall.packages(\"BiocManager\")\nBiocManager::install(c(\"tidyverse\", \"Matrix\", \"RCurl\", \"scales\", \"cowplot\", \"Seurat\", \"metap\"))\n安装 Bioc 包：\n# options(BioC_mirror=\"https://mirrors.tuna.tsinghua.edu.cn/bioconductor\")\nBiocManager::install(c(\"AnnotationHub\", \"ensembldb\", \"multtest\", \"glmGamPoi\"))"
  },
  {
    "objectID": "posts/2023-05-31-scrna-seq_online-00/index.html#测试包的安装",
    "href": "posts/2023-05-31-scrna-seq_online-00/index.html#测试包的安装",
    "title": "scRNA-seq_online 00：包准备",
    "section": "测试包的安装",
    "text": "测试包的安装\n\nlibrary(Seurat)\n## Attaching SeuratObject\nlibrary(tidyverse)\n## ── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n## ✔ dplyr     1.1.2     ✔ readr     2.1.4\n## ✔ forcats   1.0.0     ✔ stringr   1.5.0\n## ✔ ggplot2   3.4.2     ✔ tibble    3.2.1\n## ✔ lubridate 1.9.2     ✔ tidyr     1.3.0\n## ✔ purrr     1.0.1\n## ── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n## ✖ dplyr::filter() masks stats::filter()\n## ✖ dplyr::lag()    masks stats::lag()\n## ℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\nlibrary(Matrix)\n## \n## Attaching package: 'Matrix'\n## \n## The following objects are masked from 'package:tidyr':\n## \n##     expand, pack, unpack\nlibrary(RCurl)\n## \n## Attaching package: 'RCurl'\n## \n## The following object is masked from 'package:tidyr':\n## \n##     complete\nlibrary(scales)\n## \n## Attaching package: 'scales'\n## \n## The following object is masked from 'package:purrr':\n## \n##     discard\n## \n## The following object is masked from 'package:readr':\n## \n##     col_factor\nlibrary(cowplot)\n## \n## Attaching package: 'cowplot'\n## \n## The following object is masked from 'package:lubridate':\n## \n##     stamp\nlibrary(AnnotationHub)\n## Loading required package: BiocGenerics\n## \n## Attaching package: 'BiocGenerics'\n## \n## The following objects are masked from 'package:lubridate':\n## \n##     intersect, setdiff, union\n## \n## The following objects are masked from 'package:dplyr':\n## \n##     combine, intersect, setdiff, union\n## \n## The following objects are masked from 'package:stats':\n## \n##     IQR, mad, sd, var, xtabs\n## \n## The following objects are masked from 'package:base':\n## \n##     anyDuplicated, aperm, append, as.data.frame, basename, cbind,\n##     colnames, dirname, do.call, duplicated, eval, evalq, Filter, Find,\n##     get, grep, grepl, intersect, is.unsorted, lapply, Map, mapply,\n##     match, mget, order, paste, pmax, pmax.int, pmin, pmin.int,\n##     Position, rank, rbind, Reduce, rownames, sapply, setdiff, sort,\n##     table, tapply, union, unique, unsplit, which.max, which.min\n## \n## Loading required package: BiocFileCache\n## Loading required package: dbplyr\n## \n## Attaching package: 'dbplyr'\n## \n## The following objects are masked from 'package:dplyr':\n## \n##     ident, sql\nlibrary(ensembldb)\n## Loading required package: GenomicRanges\n## Loading required package: stats4\n## Loading required package: S4Vectors\n## \n## Attaching package: 'S4Vectors'\n## \n## The following objects are masked from 'package:Matrix':\n## \n##     expand, unname\n## \n## The following objects are masked from 'package:lubridate':\n## \n##     second, second&lt;-\n## \n## The following objects are masked from 'package:dplyr':\n## \n##     first, rename\n## \n## The following object is masked from 'package:tidyr':\n## \n##     expand\n## \n## The following objects are masked from 'package:base':\n## \n##     expand.grid, I, unname\n## \n## Loading required package: IRanges\n## \n## Attaching package: 'IRanges'\n## \n## The following object is masked from 'package:lubridate':\n## \n##     %within%\n## \n## The following objects are masked from 'package:dplyr':\n## \n##     collapse, desc, slice\n## \n## The following object is masked from 'package:purrr':\n## \n##     reduce\n## \n## Loading required package: GenomeInfoDb\n## Loading required package: GenomicFeatures\n## Loading required package: AnnotationDbi\n## Loading required package: Biobase\n## Welcome to Bioconductor\n## \n##     Vignettes contain introductory material; view with\n##     'browseVignettes()'. To cite Bioconductor, see\n##     'citation(\"Biobase\")', and for packages 'citation(\"pkgname\")'.\n## \n## \n## Attaching package: 'Biobase'\n## \n## The following object is masked from 'package:AnnotationHub':\n## \n##     cache\n## \n## \n## Attaching package: 'AnnotationDbi'\n## \n## The following object is masked from 'package:dplyr':\n## \n##     select\n## \n## Loading required package: AnnotationFilter\n## \n## Attaching package: 'ensembldb'\n## \n## The following object is masked from 'package:dplyr':\n## \n##     filter\n## \n## The following object is masked from 'package:stats':\n## \n##     filter"
  },
  {
    "objectID": "posts/2023-05-31-scrna-seq_online-00/index.html#查看会话信息",
    "href": "posts/2023-05-31-scrna-seq_online-00/index.html#查看会话信息",
    "title": "scRNA-seq_online 00：包准备",
    "section": "查看会话信息",
    "text": "查看会话信息\n\nsessionInfo()\n\nR version 4.2.2 (2022-10-31)\nPlatform: x86_64-apple-darwin17.0 (64-bit)\nRunning under: macOS Big Sur ... 10.16\n\nMatrix products: default\nBLAS:   /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRblas.0.dylib\nLAPACK: /Library/Frameworks/R.framework/Versions/4.2/Resources/lib/libRlapack.dylib\n\nlocale:\n[1] zh_CN.UTF-8/zh_CN.UTF-8/zh_CN.UTF-8/C/zh_CN.UTF-8/zh_CN.UTF-8\n\nattached base packages:\n[1] stats4    stats     graphics  grDevices utils     datasets  methods  \n[8] base     \n\nother attached packages:\n [1] ensembldb_2.22.0        AnnotationFilter_1.22.0 GenomicFeatures_1.50.4 \n [4] AnnotationDbi_1.60.2    Biobase_2.58.0          GenomicRanges_1.50.2   \n [7] GenomeInfoDb_1.34.9     IRanges_2.32.0          S4Vectors_0.36.2       \n[10] AnnotationHub_3.6.0     BiocFileCache_2.6.1     dbplyr_2.3.2           \n[13] BiocGenerics_0.44.0     cowplot_1.1.1           scales_1.2.1           \n[16] RCurl_1.98-1.12         Matrix_1.5-4.1          lubridate_1.9.2        \n[19] forcats_1.0.0           stringr_1.5.0           dplyr_1.1.2            \n[22] purrr_1.0.1             readr_2.1.4             tidyr_1.3.0            \n[25] tibble_3.2.1            ggplot2_3.4.2           tidyverse_2.0.0        \n[28] SeuratObject_4.1.3      Seurat_4.3.0           \n\nloaded via a namespace (and not attached):\n  [1] utf8_1.2.3                    spatstat.explore_3.2-1       \n  [3] reticulate_1.28               tidyselect_1.2.0             \n  [5] RSQLite_2.3.1                 htmlwidgets_1.6.2            \n  [7] grid_4.2.2                    BiocParallel_1.32.6          \n  [9] Rtsne_0.16                    munsell_0.5.0                \n [11] codetools_0.2-19              ica_1.0-3                    \n [13] future_1.32.0                 miniUI_0.1.1.1               \n [15] withr_2.5.0                   spatstat.random_3.1-5        \n [17] colorspace_2.1-0              progressr_0.13.0             \n [19] filelock_1.0.2                knitr_1.43                   \n [21] rstudioapi_0.14               ROCR_1.0-11                  \n [23] tensor_1.5                    listenv_0.9.0                \n [25] MatrixGenerics_1.10.0         GenomeInfoDbData_1.2.9       \n [27] polyclip_1.10-4               bit64_4.0.5                  \n [29] parallelly_1.36.0             vctrs_0.6.2                  \n [31] generics_0.1.3                xfun_0.39                    \n [33] timechange_0.2.0              R6_2.5.1                     \n [35] bitops_1.0-7                  spatstat.utils_3.0-3         \n [37] cachem_1.0.8                  DelayedArray_0.24.0          \n [39] promises_1.2.0.1              BiocIO_1.8.0                 \n [41] gtable_0.3.3                  globals_0.16.2               \n [43] goftest_1.2-3                 rlang_1.1.1                  \n [45] splines_4.2.2                 rtracklayer_1.58.0           \n [47] lazyeval_0.2.2                spatstat.geom_3.2-1          \n [49] BiocManager_1.30.20           yaml_2.3.7                   \n [51] reshape2_1.4.4                abind_1.4-5                  \n [53] httpuv_1.6.11                 tools_4.2.2                  \n [55] ellipsis_0.3.2                RColorBrewer_1.1-3           \n [57] ggridges_0.5.4                Rcpp_1.0.10                  \n [59] plyr_1.8.8                    progress_1.2.2               \n [61] zlibbioc_1.44.0               prettyunits_1.1.1            \n [63] deldir_1.0-9                  pbapply_1.7-0                \n [65] zoo_1.8-12                    SummarizedExperiment_1.28.0  \n [67] ggrepel_0.9.3                 cluster_2.1.4                \n [69] magrittr_2.0.3                data.table_1.14.8            \n [71] scattermore_1.1               lmtest_0.9-40                \n [73] RANN_2.6.1                    ProtGenerics_1.30.0          \n [75] fitdistrplus_1.1-11           matrixStats_0.63.0           \n [77] hms_1.1.3                     patchwork_1.1.2              \n [79] mime_0.12                     evaluate_0.21                \n [81] xtable_1.8-4                  XML_3.99-0.14                \n [83] gridExtra_2.3                 compiler_4.2.2               \n [85] biomaRt_2.54.1                KernSmooth_2.23-21           \n [87] crayon_1.5.2                  htmltools_0.5.5              \n [89] later_1.3.1                   tzdb_0.4.0                   \n [91] DBI_1.1.3                     MASS_7.3-60                  \n [93] rappdirs_0.3.3                cli_3.6.1                    \n [95] parallel_4.2.2                igraph_1.4.3                 \n [97] pkgconfig_2.0.3               GenomicAlignments_1.34.1     \n [99] sp_1.6-0                      plotly_4.10.1                \n[101] spatstat.sparse_3.0-1         xml2_1.3.4                   \n[103] XVector_0.38.0                digest_0.6.31                \n[105] sctransform_0.3.5             RcppAnnoy_0.0.20             \n[107] spatstat.data_3.0-1           Biostrings_2.66.0            \n[109] rmarkdown_2.21                leiden_0.4.3                 \n[111] uwot_0.1.14                   restfulr_0.0.15              \n[113] curl_5.0.0                    shiny_1.7.4                  \n[115] Rsamtools_2.14.0              rjson_0.2.21                 \n[117] lifecycle_1.0.3               nlme_3.1-162                 \n[119] jsonlite_1.8.4                viridisLite_0.4.2            \n[121] fansi_1.0.4                   pillar_1.9.0                 \n[123] lattice_0.21-8                KEGGREST_1.38.0              \n[125] fastmap_1.1.1                 httr_1.4.6                   \n[127] survival_3.5-5                interactiveDisplayBase_1.36.0\n[129] glue_1.6.2                    png_0.1-8                    \n[131] BiocVersion_3.16.0            bit_4.0.5                    \n[133] stringi_1.7.12                blob_1.2.4                   \n[135] memoise_2.0.1                 irlba_2.3.5.1                \n[137] future.apply_1.11.0"
  },
  {
    "objectID": "posts/2023-05-31-scrna-seq_online-00/index.html#阅读",
    "href": "posts/2023-05-31-scrna-seq_online-00/index.html#阅读",
    "title": "scRNA-seq_online 00：包准备",
    "section": "阅读",
    "text": "阅读\n接下来就可以阅读以下两份非常好的材料了解单细胞的预备知识。\n\nIntroduction to single-cell RNA-seq\nGeneration of count matrix"
  },
  {
    "objectID": "posts/2023-05-23-nextflow-singularity-no-space-left/index.html",
    "href": "posts/2023-05-23-nextflow-singularity-no-space-left/index.html",
    "title": "nextflow 运行 singularity no space left",
    "section": "",
    "text": "运行 nextflow 时报错没有空间：\nError executing process &gt; 'NFCORE_CIRCDNA:CIRCDNA:CNVKIT_BATCH (N87-TR)'\n\nCaused by:\n  Process `NFCORE_CIRCDNA:CIRCDNA:CNVKIT_BATCH (N87-TR)` terminated with an error exit status (255)\n\nCommand executed:\n\n  cnvkit.py \\\n      batch \\\n      N87-TR.bam \\\n       \\\n      --reference GRCh38_cnvkit_filtered_ref.cnn \\\n      --processes 4 \\\n      --method wgs\n\n  cat &lt;&lt;-END_VERSIONS &gt; versions.yml\n  \"NFCORE_CIRCDNA:CIRCDNA:CNVKIT_BATCH\":\n      cnvkit: $(cnvkit.py version | sed -e \"s/cnvkit v//g\")\n  END_VERSIONS\n\nCommand exit status:\n  255\n\nCommand output:\n  (empty)\n\nCommand error:\n  INFO:    Converting SIF file to temporary sandbox...\n  FATAL:   while extracting /data3/wsx/nf-core-circdna-dev/workflow/../singularity-images/depot.galaxyproject.org-singularity-cnvkit-0.9.9--pyhdfd78af_0.img: root filesystem extraction failed: extract command failed: WARNING: passwd file doesn't exist in container, not updating\n  WARNING: group file doesn't exist in container, not updating\n  WARNING: Skipping mount /etc/hosts [binds]: /etc/hosts doesn't exist in container\n  WARNING: Skipping mount /etc/localtime [binds]: /etc/localtime doesn't exist in container\n  WARNING: Skipping mount proc [kernel]: /proc doesn't exist in container\n  WARNING: Skipping mount /data3/wsx/miniconda3/var/singularity/mnt/session/tmp [tmp]: /tmp doesn't exist in container\n  WARNING: Skipping mount /data3/wsx/miniconda3/var/singularity/mnt/session/var/tmp [tmp]: /var/tmp doesn't exist in container\n  WARNING: Skipping mount /data3/wsx/miniconda3/var/singularity/mnt/session/etc/resolv.conf [files]: /etc/resolv.conf doesn't exist in container\n\n  Write on output file failed because No space left on device\n\n  FATAL ERROR:writer: failed to write file /image/root/.singularity.d/startscript\n  Parallel unsquashfs: Using 48 processors\n  29783 inodes (35465 blocks) to write\n\n  : exit status 1\n\nWork dir:\n  /data3/wsx/nxf_wgs/work/e9/902f1684d95d41a61ae28ef3e529b3\n\nTip: when you have fixed the problem you can continue the execution adding the option `-resume` to the run command line\n我查了下 /tmp 缺失很少或没有了，尝试删除我自己产生的临时目录再次运行还是报错。原因是 singularity 镜像在 /tmp 目录下解压空间不够导致的。\n实际上我在 ~/.bashrc 下是设置过临时目录和singularity的缓存的：\nexport TMPDIR=$HOME/TEMPDIR\nexport TEMP=$HOME/TEMPDIR\nexport TMP=$HOME/TEMPDIR\n\nexport NXF_SINGULARITY_CACHEDIR=$HOME/NXF_singularity\nexport SINGULARITY_TMPDIR=$HOME/singularity-env\nexport SINGULARITY_CACHEDIR=$HOME/singularity-env\n这就相当纳闷了。在 Github 发现一个帖子，讨论说这个问题是 nextflow 没有正常地读取和设置 singularity 的临时目录磁盘挂载。\n想一想，确实是这个问题。为了确定，我在报错的 work 目录下查看和调试了 .command.run 文件，当设置挂载后确实是可以正常工作的。\n于是按照下面进行了 nextflow.config 的配置：\nsingularity {\nenabled = true\nautoMounts = true\nrunOptions = '-B $SINGULARITY_TMPDIR:/tmp -B $SINGULARITY_TMPDIR:/scratch'\n//Used to allow Singularity to access bashrc variables\nenvWhitelist = ['SINGULARITY_TMPDIR']\n}\n还是不行，后面对比时猛然发现在 nextflow.config 中 autoMounts 的写法是 singularity.autoMounts = true。 所以我添加了前缀：\nsingularity.autoMounts = true\nsingularity.runOptions = '-B $SINGULARITY_TMPDIR:/tmp'\nsingularity.envWhitelist = ['SINGULARITY_TMPDIR']\n这样就没有问题了。"
  },
  {
    "objectID": "posts/welcome/index.html",
    "href": "posts/welcome/index.html",
    "title": "Welcome To My Blog",
    "section": "",
    "text": "This is the first post in a Quarto blog. Welcome!"
  },
  {
    "objectID": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html",
    "href": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html",
    "title": "ChatGPT 帮助我理解 Rust 的所有权",
    "section": "",
    "text": "这篇文章以我和 ChatGPT 的问答进行。"
  },
  {
    "objectID": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#怎么理解rust的所有权",
    "href": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#怎么理解rust的所有权",
    "title": "ChatGPT 帮助我理解 Rust 的所有权",
    "section": "怎么理解rust的所有权？",
    "text": "怎么理解rust的所有权？\nRust的所有权是其独特的内存管理系统，用于动态内存分配和释放。它基于以下原则：\n\n每个值在任何时刻只能有一个所有者。\n所有权只能转移，不能共享。\n默认情况下，所有权的转移是按值而不是按引用进行的。\n\n这种所有权系统有助于避免内存泄漏、空引用和数据竞争等常见的错误。在Rust中，通过为每个值分配一个所有者来跟踪内存中的数据是如何使用的，每一个所有者离开作用域时，它拥有的值都会被销毁。因此，Rust所有权系统能够自动管理内存，而且无需额外的垃圾回收机制。这一特性让Rust成为一个高效、安全和可靠的编程语言。需要注意的是，所有权机制对于Rust的初学者来说是一个相对复杂的概念，需要一定的理解和实践才能更好地应用它并编写出高质量的Rust代码。"
  },
  {
    "objectID": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#怎么理解-所有权的主要目的就是为了管理堆数据",
    "href": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#怎么理解-所有权的主要目的就是为了管理堆数据",
    "title": "ChatGPT 帮助我理解 Rust 的所有权",
    "section": "怎么理解 所有权的主要目的就是为了管理堆数据？",
    "text": "怎么理解 所有权的主要目的就是为了管理堆数据？\nRust中的所有权确实是用于管理堆数据的，因为堆数据是在运行时动态分配的，并且在内存中存在一定的问题，如内存泄漏、数据竞争等。因此需要一种机制来管理堆数据并解决这些问题。所有权机制可以确保在动态分配内存的情况下，内存得到正确的释放，每个heap上的数据有且仅有一个所有者对其进行管理，从而避免了数据竞争和其他常见的错误。\n此外，Rust还使用采取堆管理的方式为其他类型的数据分配内存。例如，当一个Vector或String类型增长时，它们必须重新分配和复制所有的数据，同时保证新的数据具有唯一的所有者。这使得Rust的动态内存分配和释放机制非常高效、可靠和安全，在许多应用程序场景中可以提供非常好的性能。"
  },
  {
    "objectID": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#为什么所有权不是管理栈数据的呢",
    "href": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#为什么所有权不是管理栈数据的呢",
    "title": "ChatGPT 帮助我理解 Rust 的所有权",
    "section": "为什么所有权不是管理栈数据的呢？",
    "text": "为什么所有权不是管理栈数据的呢？\n所有权的设计之所以没有涉及栈，是因为栈上的数据是随着当前作用域结束而自动释放的。栈上的数据的分配和释放是编译时完成的，编译器可以自己进行管理，从而不需要特别的内存管理机制。当在栈上分配数据时，其生命周期的结束是在编译器处理的代码块退出前的最后一个语句执行后就会自动发生。此时编译器会自动释放它们的空间，没有必要使用所有权。因此，所有权机制主要应用于需要在运行时动态分配内存的场景，例如堆上存储的大型数据结构、字符串、闭包等。相比于栈上的数据，堆上的数据需要更加灵活和高级的处理方式，所以所有权体系的设计针对的是动态内存的管理，而不是栈上的处理。"
  },
  {
    "objectID": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#所有权造成的操作障碍",
    "href": "posts/2023-03-29-chatgpt-help-me-understand-rust-ownership/index.html#所有权造成的操作障碍",
    "title": "ChatGPT 帮助我理解 Rust 的所有权",
    "section": "所有权造成的操作障碍",
    "text": "所有权造成的操作障碍\n由于所有权的问题，Rust 变得安全有效，但对于开发者也造成了一些理解和操作问题。 例如，同一个堆数据（栈数据不会受到影响，因为它们在编译时已经被决定了，堆数据在运行时是可变的，所以才会有内存问题）不能指向两个不同的变量，当新的变量出现时，所有权被转移，之前的变量就无效无法使用了。\nfn main() {\n    let s1 = String::from(\"hello\");\n    let s2 = s1;\n\n    println!(\"{}, world!\", s1);\n}\n\n为了生成两个拷贝，需要用到克隆。\nfn main() {\n    let s1 = String::from(\"hello\");\n    let s2 = s1.clone();\n\n    println!(\"s1 = {}, s2 = {}\", s1, s2);\n}\n这个 Rust 的 trait 设计也有关系（我理解就是实际的实现）\n\nRust 有一个叫做 Copy trait 的特殊注解，可以用在类似整型这样的存储在栈上的类型上。如果一个类型实现了 Copy trait，那么一个旧的变量在将其赋值给其他变量后仍然可用。\nRust 不允许自身或其任何部分实现了 Drop trait 的类型使用 Copy trait。如果我们对其值离开作用域时需要特殊处理的类型使用 Copy 注解，将会出现一个编译时错误。\n那么哪些类型实现了 Copy trait 呢？你可以查看给定类型的文档来确认，不过作为一个通用的规则，任何一组简单标量值的组合都可以实现 Copy，任何不需要分配内存或某种形式资源的类型都可以实现 Copy 。如下是一些 Copy 的类型：\n所有整数类型，比如 u32。 布尔类型，bool，它的值是 true 和 false。 所有浮点数类型，比如 f64。 字符类型，char。 元组，当且仅当其包含的类型也都实现 Copy 的时候。比如，(i32, i32) 实现了 Copy，但 (i32, String) 就没有。\n\n变量的所有权总是遵循相同的模式：将值赋给另一个变量时移动它。当持有堆中数据值的变量离开作用域时，其值将通过 drop 被清理掉，除非数据被移动为另一个变量所有。\n\n参考：\n\nhttps://kaisery.github.io/trpl-zh-cn/ch04-01-what-is-ownership.html"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html",
    "title": "Single-cell sequencing protocols",
    "section": "",
    "text": "From https://www.sc-best-practices.org/introduction/scrna_seq.html\nTypes:"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#基于微流控装置",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#基于微流控装置",
    "title": "Single-cell sequencing protocols",
    "section": "基于微流控装置",
    "text": "基于微流控装置\n基于微流控芯片的单细胞策略可以将细胞固定在水凝胶液滴内部，实现将其分隔到单细胞反应室中。最广泛使用的协议有inDrop [Klein等人，2015]、Drop-seq [Macosko等人，2015]和商业可用的10x Genomics Chromium [Zheng等人，2017]，能够每秒生成数千个这样的液滴。这种大规模并行的过程以相对较低的成本生成非常多的液滴。虽然这三个协议在细节上有所不同，但始终设计了包含携带PCR处理程序、细胞条形码和4-8个碱基对长的唯一分子标识符（UMI）和poly-T尾巴的专门微珠来封装细胞的纳升级液滴，以便同时捕获微珠和细胞。封装过程是使用具有on-bead引物的专门微珠进行的，这些引物包含一个PCR处理程序、一个细胞条形码和一个4-8 bp长的唯一分子标识符（UMI）和一个poly-T尾巴。在裂解后，细胞的mRNA立即被释放，并被附加在微珠上的带条形码的寡核苷酸捕获。接下来，收集液滴并将其打破以释放连接到微粒（STAMPs）上的单个细胞转录组。然后进行PCR和反转录以捕获和扩增转录物。最后进行标签切割，其中转录本被随机切割并附加测序适配器。该过程产生了用于测序的测序文库，如上所述。在基于微流控芯片的协议中，细胞的约10%的转录本会被检测到[Islam等人，2014]。值得注意的是，这种低测序量已足以稳健地识别细胞类型。\n所有三种基于微流控芯片的方法都会产生特定的偏差。所使用的微珠材料在协议之间存在差异。Drop-seq使用脆性树脂制成的微珠，因此微珠被以泊松分布封装，而InDrop和10X Genomics微珠是可变形的，导致微珠的占用率超过80%[Zhang等人，2019]。此外，Drop-Seq中使用表面固定引物可能会影响捕获效率。InDrop使用光解引物释放，而10X genomics则溶解微珠。这种差异也影响了反转录过程的位置。在Drop-seq中，反转录发生在微珠从液滴中释放后，而在InDrop和10X genomics协议中，反转录发生在液滴内部[Zhang等人，2019]。\n2019年张等人的比较发现，就微珠质量而言，10X Genomics比inDrop和Drop-seq表现更好，因为前两个系统中的细胞条形码存在明显的不匹配。此外，从有效条形码中产生的读数比例对于10X Genomics是75%，而对于InDrop和Drop-seq仅分别为25%和30%。\n在敏感性方面，10X Genomics也表现出类似的优势。他们的比较显示，平均而言，10X Genomics捕获了来自3000个基因的约17000份转录本，而Drop-seq只有来自2500个基因的约8000份转录本，InDrop则只有来自1250个基因的约2700份转录本。技术噪音最小的是10X Genomics，其次是Drop-seq和InDrop[Zhang等人，2019]。\n实际生成的数据展示了大量的协议偏差。10X Genomics更倾向于捕获和扩增长度较短的基因和GC含量较高的基因，而相比之下，Drop-seq更倾向于GC含量较低的基因。尽管10X Genomics在各个方面的表现都超过了其他协议，但它每个细胞的成本也是其他协议的两倍左右。此外，除了微珠以外，Drop-seq是开源的，协议可以更容易地进行适应性调整。InDrop完全是开放源代码的，甚至可以在实验室中制造和修改微珠。因此，InDrop是三种协议中最灵活的一种。\n\n优点：\n\n可以以成本效益的方式对大量细胞进行测序，以识别组织的总体组成并表征罕见的细胞类型。\n可以加入唯一分子标识符（UMIs）。\n\n限制：\n\n与其他方法相比，转录本检测率较低。\n只能捕获3’端而非全长转录本，因为细胞条形码和PCR处理程序仅添加到转录本的末端。"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#基于板",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#基于板",
    "title": "Single-cell sequencing protocols",
    "section": "基于板",
    "text": "基于板\n基于板的协议通常将细胞物理地分离到微孔板中。第一步涉及通过荧光激活细胞分选（FACS）等方法对细胞进行分选，其中根据特定的细胞表面标记对细胞进行排序；或通过微型移液进行。然后将所选细胞放入含有细胞裂解缓冲液的单个孔中，随后进行反转录。这样可以在单次实验中分析数百个细胞，并每个细胞捕获5000至10000个基因。基于板的测序协议包括但不限于SMART-seq2、MARS-seq、QUARTZ-seq和SRCB-seq。总的来说，这些协议在其多重复合能力方面存在差异。例如，MARS-seq允许三个条形码级别，即分子、细胞和板级标签，以实现强大的多重复合功能。相反，SMART-seq2不允许早期多重复合，从而限制了细胞数目。Mereu等人在2020年进行的系统比较显示，与SMART-seq2、MARS-seq或SRCB-seq相比，QUARTZ-seq2能够捕获更多的基因[Mereu等人，2020]，这意味着QUARTZ-seq2能够很好地捕获细胞类型特异性标记基因，从而实现可靠的细胞类型注释。\n\n优点：\n\n每个细胞可以恢复许多基因，从而进行深入的表征。\n可能在库制备之前收集信息，例如通过FACS排序将细胞大小和任何使用的标记的强度与孔座标关联起来。\n允许完整的转录本恢复。\n\n限制：\n\n基于板的实验规模受到其单个处理单元较低的吞吐量的限制。\n断裂步骤会消除链特异性信息[Hrdlickova等人，2017]。\n根据协议不同，基于板的协议可能是人力密集型的，需要许多必需的移液步骤，导致潜在的技术噪声和批次效应。"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#fluidigm-c1",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#fluidigm-c1",
    "title": "Single-cell sequencing protocols",
    "section": "Fluidigm C1",
    "text": "Fluidigm C1\n商业的Fluidigm C1系统是一种微流控芯片，可以自动将细胞加载和分离到小反应室中。 CEL-seq2和SMART-seq（版本1）协议在其工作流程中使用Fluidigm C1芯片，允许RNA提取和文库制备步骤同时进行，从而减少所需的手动劳动。但是，Fluidigm C1需要相对均匀的细胞混合物，因为细胞基于其大小会到达微流控芯片上的不同位置，可能会引入潜在的空间偏差。由于扩增步骤是在单个孔中进行的，因此可以实现全长测序，有效地减少了许多其他单细胞RNA测序协议的3’偏差。该协议通常也更昂贵，因此主要用于特定细胞群的广泛检查。\n\n优点：\n\n允许全长转录本覆盖。\n可以恢复剪接变异和T/B细胞受体多样性。\n\n限制：\n\n仅允许对最多800个细胞进行测序[Fluidigm，2022]。\n每个细胞的成本比其他协议更高。"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#纳米孔单细胞转录组测序",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#纳米孔单细胞转录组测序",
    "title": "Single-cell sequencing protocols",
    "section": "纳米孔单细胞转录组测序",
    "text": "纳米孔单细胞转录组测序\n长读单细胞测序方法很少使用UMI [Singh等人，2019]或未执行UMI校正[Gupta等人，2018]，因此将新的UMI读取分配给新的UMI。由于长读测序器的较高测序误差率，这会导致严重问题[Lebrigand等人，2020]。Lebigrand等人引入了ScNaUmi-seq（带有UMI的单细胞Nanopore测序），它将Nanopore测序与细胞条形码和UMI分配相结合。通过比较在Nanopore读取中发现的细胞条形码序列和从同一区域或基因恢复的 Illumina读取中发现的序列，利用Illumina数据指导条形码分配[Lebrigand等人，2020]。然而，这实际上需要两个单细胞库。scCOLOR-seq使用在整个条形码长度上互补的核苷酸对计算识别无误差的条形码。然后使用这些条形码作为指南来纠正其余的错误条形码[Philpott等人，2021]。修改过的UMI-tools定向网络方法可以纠正UMI序列重复。\n\n优点：\n\n恢复剪接和序列异质性信息\n\n缺点：\n\nNanopore试剂昂贵。\n细胞条形码恢复错误率高。\n根据协议不同，条形码分配使用Illumina数据进行指导，需要两个测序试验。 只有约10%的提取细胞被捕获，使该协议不适用于罕见细胞类型或低输入。\n使用的阵列仅捕获特定的细胞大小，可能会引入偏差。"
  },
  {
    "objectID": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#总结",
    "href": "posts/2023-05-12-single-cell-sequencing-protocols/index.html#总结",
    "title": "Single-cell sequencing protocols",
    "section": "总结",
    "text": "总结\n总的来说，我们强烈建议湿实验室和干实验室的科学家根据研究目的选择测序协议。是希望对特定细胞类型人群进行深入表征吗？在这种情况下，其中一种基于板的方法可能更适合。相反，基于液滴的测定会更好地捕获异质性混合物，从而允许更广泛的细胞表征。此外，如果预算是一个限制因素，则应选择更具成本效益和稳健性的协议。在分析数据时，请注意测序试验特异性偏差。为了全面比较所有单细胞测序协议，我们建议参考Mereu等人的“Benchmarking single-cell RNA-sequencing protocols for cell atlas projects”论文[Mereu等人，2020]。"
  },
  {
    "objectID": "posts/2023-06-01-likelihood/index.html",
    "href": "posts/2023-06-01-likelihood/index.html",
    "title": "概率与似然——摘要",
    "section": "",
    "text": "概率(probability)和似然(Likelihood)是两个经常被混淆使用的概念。\n概率质量函数（PMF）是用于描述离散随机变量的概率分布的函数。对于给定的随机变量取值，概率质量函数给出了该取值发生的概率。概率质量函数的输入是随机变量的取值，输出是对应取值的概率。\n似然函数（Likelihood Function）是用于估计模型参数的函数。对于给定的模型参数值，似然函数衡量了观测数据出现该参数值的可能性。似然函数的输入是模型参数的取值，输出是在给定参数下观测数据出现的可能性。\n概率质量函数和似然函数的区别在于它们关注的对象不同。概率质量函数是给定参数值时，计算随机变量的取值的概率；而似然函数是给定观测数据时，评估参数值的可能性。因此，似然函数通常用于参数估计，而概率质量函数用于描述随机变量的分布。\n简而言之，当我们有一个固定参数集的模型并且我们对可能生成的数据类型感兴趣时，通常会考虑概率。相反，当我们已经观察到数据并且我们想要检查某些模型参数的可能性时，就会使用似然。\n概率质量函数（PMF）：参数已知，观察数据。\n似然函数(Likelihood Function)：数据已知，评估参数。\n\n来源：\n\n一文了解最大似然估计(Maximum Likelihood Estimation)"
  },
  {
    "objectID": "posts/2023-05-29-tccia/index.html",
    "href": "posts/2023-05-29-tccia/index.html",
    "title": "TCCIA：第一个连接CircRNA和免疫治疗的数据库",
    "section": "",
    "text": "CircRNA是一种形成闭环结构的RNA类型，已被证明在调节基因表达方面发挥重要作用。 然而，CircRNA在免疫治疗中的作用和标志物潜能仍未被充分研究。我们很高兴地向大家介绍TCCIA（The Cancer CircRNA Immunome Atlas），它是一个广泛且用户友好的数据库，用于研究接受针对CTLA4，PD-1或PDL-1等靶点的免疫治疗的18个临床队列中的circRNA表达和分析。这一创新资源提供了cohorts和molecule级别上circRNAs、临床表型和免疫特征/浸润的系统比较。该数据库包括3700多个癌症样本，来自5种不同类型的癌症患者，这些患者单独或与化疗、靶向治疗以及其他免疫治疗药物联合使用免疫检查点抑制剂（ICI）进行治疗。\nTCCIA代表了研究circRNA及其作为预测免疫治疗响应生物标志物的潜力以及它们在癌症中的广泛功能的独特机会。无论你是研究circRNA的研究人员还是对改善新治疗策略以提高患者预后感兴趣的临床医生，TCCIA都提供了有价值的信息，可以深入了解circRNA、免疫系统和癌症之间复杂的相互作用。\n\nTCCIA 分为多个不同的页面，它以仓库页面的数据查阅和筛选为起点，允许用户从多个不同的层面和角度探索CircRNA在免疫治疗中的价值。\n\nTCCIA 是一次成功的线上科研协作，来自国内外各地的研究者贡献自己的数据和知识、资源与技术。我们旨在提供一个有用且好用的CircRNA在线研究平台，希望CircRNA领域的研究者能从中获益。目前，TCCIA正式进入开放测试阶段，它可以通过 http://biotrainee.vip:18888/TCCIA/ 和 https://shiny.hiplot.cn/TCCIA 进行在线访问。我们欢迎大家进行试用并提供宝贵的反馈意见，任何使用不便或者新功能特性的提议请发送到王诗翔（shixiang1994wang@gmail.com）或周建国（jianguo.zhou@zmu.edu.cn），我们团队将尽力回复和解决，我们期待大家的参与，一起为该领域的进步添砖加瓦。\n\n下面是一些功能的预览图："
  },
  {
    "objectID": "posts/2023-06-12-prepare-for-validation/index.html",
    "href": "posts/2023-06-12-prepare-for-validation/index.html",
    "title": "准备好应对验证",
    "section": "",
    "text": "个人感觉有效地验证的必要的，但过度的验证是次要的。但作为一个生信从业者，当文章投出去之后，总会遇到认为全世界的数据（包括原始数据）都供你可用的，任意挥霍的评审人。我并不认为这是真正的专家，因为它把一个次要的问题当作major concern，由此来否决你整个方法研究的科学性。\n事实是，文章总能在由高到低的期刊列表的评审过程中发出去。真正付出的代价是研究者的时间。 这也是预印本为什么正在走向科学发表主流的根本原因，人们越来越没有耐心了，专业化让人们产生越来越大的隔阂，但评审在大部分情况下并没有快捷有效地提升文章的真正质量。实际上，大部分的审稿人可能并不具备评估某一篇文章的能力，邀请审稿大多数只是一种资历。\n我比较痛恨当前科学研究赢者通吃的规则。eLife 等期刊的新理念或许是一个好的方向。更让我思考和困惑的是，如何不在所谓大树的阴凉下，有且做好独立创新，并能够追求内心倾向、自由探索的学术。\n可能当前阶段，我的想法过于理想和幼稚。但如果我不想和尝试做做，我的人生也总归不会交到别人的手上。"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Write programs that do one thing and do it well.",
    "section": "",
    "text": "2023-07-13\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJul 13, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-07-12\n\n\n\n\n\n\n\njournal\n\n\nmachine-learning\n\n\n\n\n\n\n\n\n\n\n\nJul 12, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nscrna 核心工具\n\n\n\n\n\n\n\nnote\n\n\nscRNA-seq\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-07-10\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nmight & right\n\n\n\n\n\n\n\nnote\n\n\n\n\n\n\n\n\n\n\n\nJul 10, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-07-06\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n生物医学能离开生物信息学吗？\n\n\n\n\n\n\n\nthought\n\n\n\n\n\n\n\n\n\n\n\nJul 6, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n博客 links\n\n\n\n\n\n\n\nnote\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-07-02\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJul 2, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-06-28\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJun 28, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-06-27\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJun 27, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n2023-06-26\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nlmtest 似然比检验Likelihood Ratio Test 比较两个线性模型\n\n\n\n\n\n\n\nstats\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nJun 26, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n使用 Just 重复构建\n\n\n\n\n\n\n\nLinux\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n应该写写日记\n\n\n\n\n\n\n\njournal\n\n\n\n\n\n\n\n\n\n\n\nJun 14, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n准备好应对验证\n\n\n\n\n\n\n\nbioinformatics\n\n\nthought\n\n\n\n\n\n\n\n\n\n\n\nJun 12, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n概率与似然——摘要\n\n\n\n\n\n\n\nstats\n\n\n\n\n\n\n\n\n\n\n\nJun 1, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nscRNA-seq_online 00：包准备\n\n\n\n\n\n\n\nbioinformatics\n\n\nscRNA-seq\n\n\n\n\n\n\n\n\n\n\n\nMay 31, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nTCCIA：第一个连接CircRNA和免疫治疗的数据库\n\n\n\n\n\n\n\nbioinformatics\n\n\nshiny\n\n\n\n\n\n\n\n\n\n\n\nMay 29, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nnextflow 运行 singularity no space left\n\n\n\n\n\n\n\ndebug\n\n\n\n\n\n\n\n\n\n\n\nMay 23, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nStart a new research direction\n\n\n\n\n\n\n\nacademic\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nSingle-cell sequencing protocols\n\n\n\n\n\n\n\nbioinformatics\n\n\nnote\n\n\n\n\n\n\n\n\n\n\n\nMay 12, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n晒晒娃和Y叔R书的合照\n\n\n\n\n\n\n\npersonal\n\n\nR\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\n随想\n\n\n\n\n\n\n\npersonal\n\n\n\n\n\n\n\n\n\n\n\nApr 8, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nChatGPT 帮助我理解 Rust 的所有权\n\n\n\n\n\n\n\nRust\n\n\nAI\n\n\n\n\n\n\n\n\n\n\n\nMar 29, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\n  \n\n\n\n\nWelcome To My Blog\n\n\n\n\n\n\n\nnews\n\n\n\n\n\n\n\n\n\n\n\nMar 28, 2023\n\n\nShixiang Wang\n\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "resource.html",
    "href": "resource.html",
    "title": "Resource",
    "section": "",
    "text": "一些比较有用的 R 包都列入了 r-universe，无论是否发布在 CRAN。这里也进行了一些罗列。\n\n\n\n\nloon - 不再维护\n\n\n\n\n\nsync-deploy\nR Search Extension"
  },
  {
    "objectID": "resource.html#软件",
    "href": "resource.html#软件",
    "title": "Resource",
    "section": "",
    "text": "一些比较有用的 R 包都列入了 r-universe，无论是否发布在 CRAN。这里也进行了一些罗列。\n\n\n\n\nloon - 不再维护\n\n\n\n\n\nsync-deploy\nR Search Extension"
  },
  {
    "objectID": "resource.html#图书教程",
    "href": "resource.html#图书教程",
    "title": "Resource",
    "section": "图书/教程 📖",
    "text": "图书/教程 📖\n\n交互的Python：数据分析入门 - 阅读地址\n极客R：数据分析之道\n\nhttps://github.com/ShixiangWang/geek-r-tutorial\n\nCookbook for R 中文版- 阅读地址\n\nhttps://github.com/openbiox/Cookbook-for-R-Chinese\n\n生信爱好者周刊"
  },
  {
    "objectID": "posts/2023-06-14-write-journal/index.html",
    "href": "posts/2023-06-14-write-journal/index.html",
    "title": "应该写写日记",
    "section": "",
    "text": "吴军在《阅读与写作讲义》中写道工作日记、读书心得以及对特殊经历的记录值得人写下来。\n我很认同这个看法。回望过去一到两年的时间，写东西的次数少了以后，我竟常常难以思考出来过去一段时间做了什么，是浪费了时间还是利用了时间都搞不清楚。\n这让我联想到博士后期间做的工作，我不禁反思：是否是平常太过随意，导致工作和论文写作不严谨，所以论文评审才常常收到负面意见？心态可以放松，思想应当解放，但平时无论是工作或是生活中都要严谨，这样可能才能做好真正的科学研究工作。做人首先还是要对自己负责，毕竟生命只有一次啊！\n很多东西真的不重要，很多东西真的很重要。"
  },
  {
    "objectID": "posts/2023-06-26-lmtest-lrt/index.html",
    "href": "posts/2023-06-26-lmtest-lrt/index.html",
    "title": "lmtest 似然比检验Likelihood Ratio Test 比较两个线性模型",
    "section": "",
    "text": "library(lmtest)\n\nLoading required package: zoo\n\n\n\nAttaching package: 'zoo'\n\n\nThe following objects are masked from 'package:base':\n\n    as.Date, as.Date.numeric\n\n## with data from Greene (1993):\n## load data and compute lags\ndata(\"USDistLag\")\nusdl &lt;- na.contiguous(cbind(USDistLag, lag(USDistLag, k = -1)))\ncolnames(usdl) &lt;- c(\"con\", \"gnp\", \"con1\", \"gnp1\")\n\nfm1 &lt;- lm(con ~ gnp + gnp1, data = usdl)\nfm2 &lt;- lm(con ~ gnp + con1 + gnp1, data = usdl)\n\n## various equivalent specifications of the LR test\n## 下面4种操作方法是等价的\nlrtest(fm2, fm1)\n\nLikelihood ratio test\n\nModel 1: con ~ gnp + con1 + gnp1\nModel 2: con ~ gnp + gnp1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   5 -56.069                         \n2   4 -65.871 -1 19.605  9.524e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(fm2, 2) # Remove variable with idx 2\n\nLikelihood ratio test\n\nModel 1: con ~ gnp + con1 + gnp1\nModel 2: con ~ gnp + gnp1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   5 -56.069                         \n2   4 -65.871 -1 19.605  9.524e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(fm2, \"con1\") # Remove variable cond 1\n\nLikelihood ratio test\n\nModel 1: con ~ gnp + con1 + gnp1\nModel 2: con ~ gnp + gnp1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   5 -56.069                         \n2   4 -65.871 -1 19.605  9.524e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\nlrtest(fm2, . ~ . - con1)  # Remove con1 by formula\n\nLikelihood ratio test\n\nModel 1: con ~ gnp + con1 + gnp1\nModel 2: con ~ gnp + gnp1\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)    \n1   5 -56.069                         \n2   4 -65.871 -1 19.605  9.524e-06 ***\n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n\nSurvival 模型交互项：\n\nlibrary(survival)\n\nfit2 = coxph(Surv(time, status) ~ age + sex*factor(ph.ecog), data = lung)\nlmtest::lrtest(fit2, . ~ . - sex:factor(ph.ecog))\n\nLikelihood ratio test\n\nModel 1: Surv(time, status) ~ age + sex * factor(ph.ecog)\nModel 2: Surv(time, status) ~ age + sex + factor(ph.ecog)\n  #Df  LogLik Df  Chisq Pr(&gt;Chisq)\n1   7 -728.93                     \n2   5 -729.05 -2 0.2263      0.893\n\nsummary(fit2)\n\nCall:\ncoxph(formula = Surv(time, status) ~ age + sex * factor(ph.ecog), \n    data = lung)\n\n  n= 227, number of events= 164 \n   (1 observation deleted due to missingness)\n\n                          coef exp(coef)  se(coef)      z Pr(&gt;|z|)  \nage                   0.009667  1.009714  0.009601  1.007   0.3140  \nsex                  -0.641345  0.526583  0.385890 -1.662   0.0965 .\nfactor(ph.ecog)1      0.335017  1.397964  0.609291  0.550   0.5824  \nfactor(ph.ecog)2      0.618092  1.855384  0.686960  0.900   0.3683  \nfactor(ph.ecog)3      1.941570  6.969687  1.033409  1.879   0.0603 .\nsex:factor(ph.ecog)1  0.063350  1.065400  0.451918  0.140   0.8885  \nsex:factor(ph.ecog)2  0.221865  1.248403  0.507016  0.438   0.6617  \nsex:factor(ph.ecog)3        NA        NA  0.000000     NA       NA  \n---\nSignif. codes:  0 '***' 0.001 '**' 0.01 '*' 0.05 '.' 0.1 ' ' 1\n\n                     exp(coef) exp(-coef) lower .95 upper .95\nage                     1.0097     0.9904    0.9909     1.029\nsex                     0.5266     1.8990    0.2472     1.122\nfactor(ph.ecog)1        1.3980     0.7153    0.4235     4.615\nfactor(ph.ecog)2        1.8554     0.5390    0.4827     7.131\nfactor(ph.ecog)3        6.9697     0.1435    0.9195    52.827\nsex:factor(ph.ecog)1    1.0654     0.9386    0.4394     2.583\nsex:factor(ph.ecog)2    1.2484     0.8010    0.4621     3.372\nsex:factor(ph.ecog)3        NA         NA        NA        NA\n\nConcordance= 0.636  (se = 0.025 )\nLikelihood ratio test= 31.09  on 7 df,   p=6e-05\nWald test            = 30.72  on 7 df,   p=7e-05\nScore (logrank) test = 33.92  on 7 df,   p=2e-05\n\n\n除了用 likelihood ratio test，还可以使用 anova() 去对比。\n但如果数据不一致时，上述模型无法见效。这时，应把不同的对比作为变量构建模型，然后可以采用 aov() 进行方差分析，看变量是否显著以评估是否有组间差异。"
  },
  {
    "objectID": "posts/2023-06-26-journal/index.html",
    "href": "posts/2023-06-26-journal/index.html",
    "title": "2023-06-26",
    "section": "",
    "text": "疫情之后抗感冒能力确实变得更加糟糕了，上一次二阳（本以为是重感冒）十多天之后在端午之前终于感觉到差不多好了，端午去了趟深圳回家又感觉不好了，特别是前天晚上睡觉时突然感觉喉咙很痒，频繁咳嗽，把自己咳起来去喝水。\n工作后老是感觉时间少，做什么都不够用似的，而且身体在变形和走下坡路。所以，成年人需要合理地管理自己的时间：身体、工作、生活、家人（陪伴）、休闲娱乐。其实，人生存在很强的悖论，要保持理性追求职业上升的同时，又要把关自身的感性的体态面貌健康/快乐渴望，很难做到，真的很难做到。\n我总是在想起我自己常想的一句话：我们是看着别人在过自己的人生。这也是非常矛盾的，合理的把握至关重要。在平衡这方面，我们国家的哲学理论实在是一言蔽之——阴阳！"
  },
  {
    "objectID": "posts/2023-06-27-journal/index.html",
    "href": "posts/2023-06-27-journal/index.html",
    "title": "2023-06-27",
    "section": "",
    "text": "今天记录在《经济学讲义》中看到的一句话：\n\n你拥有你的生命，但是你的生命是怎么度过的，你的职业是怎样选择的，很大程度上是由社会上其他人决定的。"
  },
  {
    "objectID": "posts/2023-06-28-journal/index.html",
    "href": "posts/2023-06-28-journal/index.html",
    "title": "2023-06-28",
    "section": "",
    "text": "坚持学习，坚持同一种内容的学习。\n工作、生活越来越让时间碎片化，我常常在回家后忘记想要做的工作和学习内容，在上班的空闲时间也常忘记家里要处理的杂事，比如购置一些缺少的生活用品。可见，这种碎片化非常影响记忆，自然就影响日常的学习进度了。\n为了抵抗这种情况，就要自律，不论各种事情，只要定下了近期的学习目标，在一两天内必须要有跟进。如果放到一周后再来做，可能要做什么都要回想半个小时。之前写 Python 基础教程书期间我就有半年因为这种事情而焦虑。\n人最可贵的是思考并付诸于行动，不是吗？"
  },
  {
    "objectID": "posts/2023-07-02-links/index.html",
    "href": "posts/2023-07-02-links/index.html",
    "title": "博客 links",
    "section": "",
    "text": "之前在构建个人域名网站 &lt;shixiangwang.work&gt; 时，把浏览器书签的所有博客链接都进行了整理。\n由于云服务器的时间有限，运维实际成本想了想还是蛮高的，没多久后也没考虑再维护了。 这里把之前整理的链接备份一下，以方便查找复用，如果对一些读者有帮助也是极好的了。\n点击查看链接"
  },
  {
    "objectID": "posts/2023-07-02-journal/index.html",
    "href": "posts/2023-07-02-journal/index.html",
    "title": "2023-07-02",
    "section": "",
    "text": "今天摘录从书中看到的一句话。\n\n我们应该利用自己有限的时间、有限的精力，在自己所能涉及的所有领域、所有活动、所有选项中， 根据边际平衡的规律来分配时间、金钱、精力和其他资源，从而使总效用达到最大。\n\n这概括了生命一生的所有努力。"
  },
  {
    "objectID": "posts/2023-07-06-journal/index.html",
    "href": "posts/2023-07-06-journal/index.html",
    "title": "2023-07-06",
    "section": "",
    "text": "顾神昨天公众号吐槽他的海外优青没有上会，我深表遗憾。\n我根据这几年逐步对学术界的了解和领会，分析可能有以下一些原因：\n\n缺乏大子刊及以上的一作和通讯；\n国内缺乏生物医学各种山头的硬的合作和关系；\n纯生信基础设施的研究工作不被评审人认可，我自己申请国自然基金时就感觉生信工作如果扯不上“分子机制”就被认为不是“自然科学”；\n基金本子没有突出优势，上会之前应该是有多个评审人基于不同的方面评估等级，所以很可能写的本子不对国内的“口味”。\n\n国内的学术条件确实在越来越好，这吸引了越来越多海外优秀的青年回国发展。 但目前国内长期不正常的学术土壤为祸尤烈，希望未来在政府的引导下、有识之士的建设下 朝着良好的方向前进。学术是创新探索，也是资源的分配，希望以后资源能够更主动地分配 到不同领域的各个角落，而不是各大门派山头。"
  },
  {
    "objectID": "posts/2023-07-06-can-biology-live-without-bioinformatics/index.html",
    "href": "posts/2023-07-06-can-biology-live-without-bioinformatics/index.html",
    "title": "生物医学能离开生物信息学吗？",
    "section": "",
    "text": "不能。\n整个生物医学领域，已经由实验科学进入了数据科学的层次，而这一点无法再倒退。 生物信息学者/家（bioinformatian/computational biologist），已经成为了该领域不可或缺的存在。无论是狭义的组学，还是更广义的分子结构计算/图形处理等，生物信息学者已经成为了科学发现/技术创造的中间力量。这也正是为什么从事生物信息学的人能从致谢名单中走到作者列表，走到第一/通讯作者的根本原因。\n如果你是一个纯湿实验的研究者，你还在心里鄙夷这个行业，你就应该反思了，时代的进步不会等待你的落后。"
  },
  {
    "objectID": "posts/2023-07-10-journal/index.html",
    "href": "posts/2023-07-10-journal/index.html",
    "title": "2023-07-10",
    "section": "",
    "text": "今天终于看完了《癌生物学》，具体而言，是「珠江肿瘤」公众号整理的中文版《癌生物学》的内容。\n当年阅读计划单上终于可以划去一项了，稍稍松了一口气。这几年，虽然我读完了不少“闲书”和网文小说，但阅读，特别是 读完的工作领域相关图书几乎是没有的。教科书类字少，但理解、思考却非常费时费力，充满挑战。 这里需要感谢公众号的作者的悉心整理，当然也特别感谢图书的作者和译者。\n\n\n公众号癌生物学汇总帖\n癌生物学PDF.pdf\n\n\n很多内容读的很浅，有些内容也跳读了，但翻完了，心里好像“靴子落地”了。这也给了我自信和时间去关注和完成其他的事情。\n这两年，我在生活和工作中都遇到了心里难以言表的困难，这种困难来自感受，也部分来自物质。切实地融入生活，才发生生活有那么多的琐事，很多事情需要耗费心力，却感受上“憋”的很。我常常会想在心里找个角落躲起来。也有时会在游戏、小说和心灵的孤独中放逐自我。 人不是机器，它不能一直产生正能量。我们都是大大宇宙中小小地球上一个个活着的卑微的人，我们想要诉求伟大，但跌入的是统计的深渊。\n不管怎样，我们的道路，就是要完成一个一个想做的事情，然后继续向前。"
  },
  {
    "objectID": "posts/2023-07-10-might-and-right/index.html",
    "href": "posts/2023-07-10-might-and-right/index.html",
    "title": "might & right",
    "section": "",
    "text": "摘录一句话。\n能力：might\n权利：right\n能力取决于自己能够占有多少，而权利取决于社会上其他人愿意给你多少。\n\n所以，该追求哪种呢？"
  },
  {
    "objectID": "posts/2023-07-10-scrna-recom/index.html",
    "href": "posts/2023-07-10-scrna-recom/index.html",
    "title": "scrna 核心工具",
    "section": "",
    "text": "Repo {scrna-recom} 单细胞综述文章关于单细胞转录组分析的流程、软件、安装等的一些说明。这里我主要是拷贝下其中关于核心工具的整理，防止迷失。\n\n\n\n\n\n\n\n\nPackage\n\n\nTutorial\n\n\n\n\n\n\nRaw Data Processing\n\n\nCell Ranger\n\n\nhttps://support.10xgenomics.com/single-cell-gene-expression/software/pipelines/latest/what-is-cell-ranger\n\n\n\n\nQuality Control\n\n\nDoubletFinder\n\n\nhttps://github.com/chris-mcginnis-ucsf/DoubletFinder\n\n\n\n\nSeurat\n\n\nhttps://satijalab.org/seurat/articles/pbmc3k_tutorial.html\n\n\n\n\nSoupX\n\n\nhttps://rawcdn.githack.com/constantAmateur/SoupX/204b602418df12e9fdb4b68775a8b486c6504fe4/inst/doc/pbmcTutorial.html\n\n\n\n\nNormalization\n\n\nSeurat\n\n\nhttps://satijalab.org/seurat/articles/pbmc3k_tutorial.html#normalizing-the-data-1\n\n\n\n\nIntegration\n\n\nSeurat:CCA,RPCA\n\n\nhttps://satijalab.org/seurat/articles/integration_rpca.html\n\n\n\n\nLiger\n\n\nhttps://github.com/welch-lab/liger\n\n\n\n\nHarmony\n\n\nhttps://github.com/immunogenomics/harmony\n\n\n\n\nDimensional Reduction\n\n\nSeurat:PCA,UMAP\n\n\nhttps://satijalab.org/seurat/articles/pbmc3k_tutorial.html#perform-linear-dimensional-reduction-1\n\n\n\n\nClustering\n\n\nSeurat\n\n\nhttps://satijalab.org/seurat/articles/pbmc3k_tutorial.html#cluster-the-cells-1\n\n\n\n\nCell type annotation\n\n\nSingleR\n\n\nhttps://github.com/dviraran/SingleR\n\n\n\n\nscCATCH\n\n\nhttps://github.com/ZJUFanLab/scCATCH\n\n\n\n\nRegulon analysis\n\n\nSCENIC\n\n\nhttps://pyscenic.readthedocs.io/en/latest/\n\n\n\n\nTrajectory inference\n\n\nMonocle3\n\n\nhttps://cole-trapnell-lab.github.io/monocle3/\n\n\n\n\nscVelo\n\n\nhttps://github.com/theislab/scvelo\n\n\n\n\nCell communication\n\n\nCellChat\n\n\nhttps://github.com/sqjin/CellChat\n\n\n\n\nMetabolic analysis\n\n\nscMetabolism\n\n\nhttps://github.com/wu-yc/scMetabolism\n\n\n\n\nscFEA\n\n\nhttps://github.com/changwn/scFEA\n\n\n\n\n\nWorkflow:"
  },
  {
    "objectID": "posts/2023-07-12-journal/index.html",
    "href": "posts/2023-07-12-journal/index.html",
    "title": "2023-07-12",
    "section": "",
    "text": "在看文献的时候发现一个自监督学习，我看英文有个 supervise，以为这是带标签的学习，了解后发现原来并非如此。这里记录下 ChatGPT 关于自监督学习和监督学习的回答。以后有机会实践深入了解下。\n自监督学习和监督学习是机器学习中两种不同的方法。\n监督学习是一种常见的机器学习方法，其中模型通过使用带有标签的训练数据进行训练。在监督学习中，输入和相应的输出之间存在一个明确的映射关系。训练数据包含了输入样本及其对应的预期输出标签。模型根据这些标签来调整自身的参数，以使预测结果尽可能接近于真实标签。例如，在图像分类任务中，监督学习会使用带有标签的图像来训练模型，使其能够根据输入图像正确地预测其所属的类别。\n自监督学习则是一种无监督学习的形式，其中模型在没有人工标签的情况下进行训练。相反，自监督学习利用输入数据中的某种自动生成的标签或信息来进行训练。这些自动生成的标签可以是输入数据的某种变换、部分信息或其他方式生成的。例如，在自我对比学习中，模型会将输入数据分为两个视图，并鼓励模型将它们视为相似。通过最大化这两个视图之间的相似性度量，模型可以学习到数据的有用表示。自监督学习的目标是通过学习数据中的内在结构或模式来训练模型，而无需人工标签。\n总的来说，监督学习依赖于带有人工标签的训练数据，而自监督学习则通过利用数据中的某种自动生成的标签或信息来进行训练。自监督学习在无法获得大量带有标签的数据时尤为有用，并且已经在多个领域中取得了显著的研究进展。"
  },
  {
    "objectID": "posts/2023-07-13-journal/index.html",
    "href": "posts/2023-07-13-journal/index.html",
    "title": "2023-07-13",
    "section": "",
    "text": "今天还是摘要书中看到的话。\n\n我们面临的，就是两个分离的世界：一个世界是我们真实的世界、看得见摸得着的物理世界。 在这里，一切都按照自然规律有条不紊地进行着。另一个是看不见、摸不着的观念世界。 在那里，人们时刻在形成、比较、交换和修正对未来的预期。\n\n\n每个人生活在世界上，都至少面临四种最基本的约束，那就是： 东西不够、时间有限、相互依赖、需要协调。\n\n——《薛兆丰经济学讲义》"
  }
]