<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>R on ShixiangWang
王诗翔</title>
    <link>/tags/r/</link>
    <description>Recent content in R on ShixiangWang
王诗翔</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Sun, 26 Sep 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/r/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>处理glm.fit: fitted probabilities numerically 0 or 1 occurred</title>
      <link>/blog/process-glm-logistic-warning/</link>
      <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/process-glm-logistic-warning/</guid>
      <description>原文：https://www.statology.org/glm-fit-fitted-probabilities-numerically-0-or-1-occurred/
 在建立逻辑回归模型时遇到这个警告：
Warning message: glm.fit: fitted probabilities numerically 0 or 1 occurred 当拟合逻辑回归模型，且数据框中一个或多个观测值的预测概率与0或1难以区分时，会出现此警告。
值得注意的是，这是一个警告消息，而不是一个错误。即使你收到这个错误，你的逻辑回归模型仍然是合适的，但是可能值得分析原始数据框，看看是否有任何异常值导致此警告消息出现。
本教程将分享如何在实践中处理此警告消息。
重复警告 假设我们将logistic回归模型拟合到R中的以下数据框：
#create data frame df &amp;lt;- data.frame(y = c(0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1), x1 = c(3, 3, 4, 4, 3, 2, 5, 8, 9, 9, 9, 8, 9, 9, 9), x2 = c(8, 7, 7, 6, 5, 6, 5, 2, 2, 3, 4, 3, 7, 4, 4)) #fit logistic regression model model &amp;lt;- glm(y ~ x1 + x2, data=df, family=binomial) #view model summary summary(model) Warning message: glm.</description>
    </item>
    
    <item>
      <title>Rcpp：什么时候使用Rcpp</title>
      <link>/blog/when-use-rcpp/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/when-use-rcpp/</guid>
      <description>来源：https://teuder.github.io/rcpp4everyone_en/010_Rcpp_merit.html
什么时候使用  后面的迭代依赖于前面的迭代的循环操作。 需要访问向量/矩阵的每个元素。 在循环中循环调用函数。 动态更改向量的大小。 需要高级数据结构和算法的操作。  怎么配置 除了Windows需要安装Rtools，其他系统中一般已经装好了。
如果我们要自定义C++的配置，如更改编译器，需要使用到配置文件.R/Makevars。
下面是一个示例：
CC=/opt/local/bin/gcc-mp-4.7 CXX=/opt/local/bin/g++-mp-4.7 CPLUS_INCLUDE_PATH=/opt/local/include:$CPLUS_INCLUDE_PATH LD_LIBRARY_PATH=/opt/local/lib:$LD_LIBRARY_PATH CXXFLAGS= -g0 -O2 -Wall MAKE=make -j4  包括编译器位置、头文件位置、动态库位置、编译参数等。
 安装Rcpp install.packages(&amp;#34;Rcpp&amp;#34;) </description>
    </item>
    
    <item>
      <title>Rcpp：基本用法</title>
      <link>/blog/rcpp-basic-usage/</link>
      <pubDate>Mon, 13 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/rcpp-basic-usage/</guid>
      <description>来源：https://teuder.github.io/rcpp4everyone_en/030_basic_usage.html
使用Rcpp函数只需要3步：
 编写Rcpp源代码。 编译代码。 执行函数。  编写Rcpp代码 下面是一个对向量求和的Rcpp函数：
//sum.cpp #include &amp;lt;Rcpp.h&amp;gt;using namespace Rcpp; // [[Rcpp::export]] double rcpp_sum(NumericVector v){ double sum = 0; for(int i=0; i&amp;lt;v.length(); ++i){ sum += v[i]; } return(sum); } Rcpp函数定义格式 下面是定义一个Rcpp函数的基本格式：
#include&amp;lt;Rcpp.h&amp;gt;using namespace Rcpp; // [[Rcpp::export]] RETURN_TYPE FUNCTION_NAME(ARGUMENT_TYPE ARGUMENT){ //do something  return RETURN_VALUE; }  #include&amp;lt;Rcpp.h&amp;gt;：这个句子允许你使用Rcpp包定义的类和函数。 // [[Rcpp::export]]：这个句子下面定义的函数可以从R中访问。 你需要把这个句子附加到你想从R中使用的每个函数中。 using namespace Rcpp;：这个句子是可选的。但是如果你没有写这个句子， 你必须添加前缀Rcpp::来指定由Rcpp定义的类和函数。(例如：Rcpp::NumericVector) RETURN_TYPE FUNCTION_NAME(ARGUMENT_TYPE ARGUMENT){}：你需要指定函数和参数的数据类型。 return RETURN_VALUE;：如果函数将返回一个值，return语句是强制性的。 然而，如果你的函数没有返回值（即RETURN_TYPE是无效的），返回语句可以省略。  编译代码 函数Rcpp::sourceCpp()将编译你的源代码，并将定义的函数加载到R。
library(Rcpp) sourceCpp(&amp;#39;sum.cpp&amp;#39;) 使用函数 像正常R函数一样调用它就可以了。</description>
    </item>
    
    <item>
      <title>mlr3（三）模型优化</title>
      <link>/blog/mlr3-model-optimization/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-model-optimization/</guid>
      <description>来源：https://mlr3book.mlr-org.com/optimization.html
模型优化
机器学习算法为其超参数设置了默认值。不管怎样，用户需要更改这些超参数，以在给定的数据集上实现最佳性能。不建议手动选择超参数值，因为这种方法很少能获得最佳性能。为了证实所选超参数（=调优）的有效性，建议进行数据驱动的优化。为了优化机器学习算法，必须指定（1）搜索空间，（2）优化算法(又称调优方法)，（3）评估方法，即重采样策略，（4）性能度量。
总而言之，关于调优的小节介绍：
 进行经验超参数选择 选择优化算法 简洁地指定搜索空间 触发调优 自动调优  本小节还需要包mlr3tuning，这是一个支持超参数调优的扩展包。
特征选择
本章的第二部分介绍特征选择，也称为变量选择。特征选择是寻找数据相关特征子集的过程。执行选择的一些原因：
 增强模型的可解释性 加速模型拟合 通过降低数据中的噪声来提高学习性能  在本文中，我们主要集中在最后一个方面。有不同的方法来识别相关的特征。在特征选择的分章中，我们强调了三种方法：
 运用过滤算法根据分数独立地选择特征 根据变量重要性过滤选择特征 包装器方法迭代地选择特性以优化性能度量  注意，过滤器不需要学习器。变量重要性过滤器需要一个学习器，该学习器在训练时可以计算特征的重要性值。获得的重要值可用于数据子集，然后可用于训练学习器。包装器方法可以用于任何学习器，但需要对学习器进行多次训练。
嵌套重采样
为了更好地估计泛化性能并避免数据泄漏，外部（性能）和内部（调优/特征选择）重采样过程都是必要的。本章将讨论以下特点：
 嵌套重采样中的内重采样和外重采样策略 嵌套重采样的执行 执行重采样迭代的评估  本小节将提供如何实现嵌套重采样的说明，包括mlr3中的内重采样和外重采样。
超参数调优 超参数是机器学习模型的二阶参数，虽然在模型估计过程中往往没有明确优化，但会对模型的结果和预测性能产生重要影响。通常，超参数在训练模型之前是固定的。但是，由于模型的输出可能对超参数的规范很敏感，因此通常建议对哪些超参数设置可以产生更好的模型性能做出明智的决定。在许多情况下，超参数设置可能是预先选择的，但在将模型拟合到训练数据上之前，尝试不同的设置可能是有利的。这个过程通常被称为模型“调优”。
超参数调优是通过mlr3tuning扩展包支持的。下面是这个过程的说明：
mlr3tuning的核心是R6类：
TuningInstanceSingleCrit，TuningInstanceMultiCrit：这两个类描述调优问题并存储结果。
Tuner：这个类是调优算法实现的基类。
TuningInstance* 类 下面的小节审查了皮马印度糖尿病数据集上的简单分类树的优化。
library(&amp;quot;mlr3verse&amp;quot;) task = tsk(&amp;quot;pima&amp;quot;) print(task) ## &amp;lt;TaskClassif:pima&amp;gt; (768 x 9) ## * Target: diabetes ## * Properties: twoclass ## * Features (8): ## - dbl (8): age, glucose, insulin, mass, pedigree, pregnant, pressure, ## triceps 我们使用rpart中的分类树，并选择我们想要调优的超参数的子集。这通常被称为“调优空间”。</description>
    </item>
    
    <item>
      <title>mlr3（二）基础</title>
      <link>/blog/mlr3-basics/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-basics/</guid>
      <description>来源：https://mlr3book.mlr-org.com/basics.html
本文将教你基本的mlr3知识，以及它的R6类和操作以用于机器学习。典型的机器学习工作流是这样的:
 Figure 1: 机器学习流程 source: https://mlr3book.mlr-org.com/images/ml_abstraction.svg  mlr3将数据封装在任务中，并将其分解为互不重叠的训练集和测试集。由于我们感兴趣的模型外推到新的数据，而不仅仅是记忆训练数据，独立的测试数据允许客观地评估模型的泛化。训练数据被提供给一个机器学习算法，在mlr3中我们称之为learner。learner利用训练数据建立输入特征与输出目标值之间关系的模型。然后使用该模型对测试数据进行预测，并将其与参考真值进行比较，以评估模型的质量。mlr3提供了许多不同的度量方法，根据预测值和实际值之间的差异来量化模型的执行情况。通常这是一个数字分数。
将数据分割为训练集和测试集、建立模型并对其进行评估的过程可能会重复多次，每次从原始数据中重新采样不同的训练集和测试集。多重重采样迭代允许我们对特定类型的模型获得更好、更一般化的性能估计，因为它是在不同的条件下测试的，而且由于数据重采样的特定方式，它不太容易产生偏差。
在许多情况下，这个简单的工作流不足以处理真实世界的数据，可能需要规范化（标准化）、缺失值的输入或特征选择。我们将在以后介绍更复杂的工作流程。
本文涵盖以下小主题：
任务：
任务用元信息封装数据，比如预测目标列的名称。我们将介绍如何：
 访问预定义的任务 指定一个任务类型 创建一个任务 使用任务的API工作 为任务的行和列分配角色 实施任务mutator 获取存储在任务中的数据  学习器
学习器封装机器学习算法来训练模型并对任务进行预测。它们由R和其他包提供。我们将介绍如何：
 访问随mlr3而来的分类和回归学习器集合，并检索特定的学习器 访问学习器的超参数值集并修改它们  如何修改和扩展学习器涵盖在补充高级技术部分。
训练和预测
关于训练和预测方法的部分说明了如何使用任务和学习器训练模型并对新数据集进行预测。特别地，我们将介绍如何：
 正确设置任务和学习器 为一项任务设置训练和测试分割（集） 在训练集上训练学习器以生成模型 生成测试集的预测 通过比较预测值和实际值来评估模型的性能  重采样
重采样是一种创建训练和测试分割（集）的方法。我们将介绍：
 访问和选择重采样策略 通过应用重采样实例化分割到训练集和测试集 执行重采样以获得结果  关于重采样的附加信息可以在嵌套重采样部分和模型优化一章中找到。
基准测试
基准测试用于比较不同模型的性能，例如不同学习器训练的模型，不同任务训练的模型，或不同重采样方法训练的模型。我们介绍如何
 创建一个基准设计 执行设计并汇总结果 将基准测试对象转换为重采样对象  二分类
二值分类是分类的一种特殊情况，预测的目标变量只有两个可能的值。在这种情况下，还需要考虑其他因素。特别是：
 ROC曲线和预测一个类和另一个类的阈值 阈值调整  在详细介绍如何使用mlr3进行机器学习之前，我们先简要介绍一下R6，因为它是R相对较新的一部分。mlr3严重依赖于R6，它提供的所有基本构造都是R6类：
 任务 task 学习器 learner 测量 measure 重采样 resamplings  快速R6入门介绍 R6是R最新的面向对象编程(OO)方言之一。它解决了R中早期OO实现的缺点，比如我们在mlr中使用的S3。如果你以前做过面向对象编程，那么R6应该很熟悉。我们关注的是R6的部分，你需要知道在这里使用mlr3。</description>
    </item>
    
    <item>
      <title>R小技巧：分组应用和排序去重的应用与比较</title>
      <link>/blog/r-tricks-remove-duplicates-after-ordering/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/r-tricks-remove-duplicates-after-ordering/</guid>
      <description>问题与方案 假设我们有这样一个数据集：
df &amp;lt;- data.frame( c1 = c(&amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;a&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;b&amp;quot;, &amp;quot;c&amp;quot;), c2 = c(1, 3, 2, 1, 4, 2) ) df out c1 c2 out 1 a 1 out 2 a 3 out 3 a 2 out 4 b 1 out 5 b 4 out 6 c 2 如果我们想保留每个c1分类和分类下的最大值，你会怎么操作？
思考一分钟。
如果使用惯了tidyverse套装，我们脑子里容易冒出来的是这样的解法：使用分组应用。
library(dplyr) df |&amp;gt; group_by(c1) |&amp;gt; summarize(c2 = max(c2, na.rm = TRUE)) out # A tibble: 3 × 2 out c1 c2 out &amp;lt;chr&amp;gt; &amp;lt;dbl&amp;gt; out 1 a 3 out 2 b 4 out 3 c 2 在数据不是特别大的时候，使用这种策略没有任何问题。但如果分组有成千上万，分组的时间代价就很高了。有没有其他的方式可以解决该问题呢？</description>
    </item>
    
    <item>
      <title>forestmodel给多水平变量添加整体p值</title>
      <link>/blog/forestmode-set-overall-pva-for-variable-with-multiple-levels/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/forestmode-set-overall-pva-for-variable-with-multiple-levels/</guid>
      <description>前段时间收到来信：
Hi Shixiang I am writing to you about the forestmodel package in R. Thank you so much for the wonderful package that you created. I was wondering if there is a way to display the wald test p-value which is important for variables that have more than two levels. I tried to work around the code but did not find a way out. Best Aniket 我不是作者，搞错了人，问我干啥呢～自个提问嘛
Hi Aniket, I am not the author of forestmodel, you can see from https://github.</description>
    </item>
    
    <item>
      <title>mlr3（一）快速入门</title>
      <link>/blog/mlr3-quickstart/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-quickstart/</guid>
      <description>来源：https://mlr3book.mlr-org.com/quickstart.html
安装包：
install.packages(&amp;quot;mlr3&amp;quot;) 作为一个30秒的介绍性示例，我们将在虹膜数据集的前120行训练决策树模型，并对最后30行进行预测，测量训练模型的准确性。
library(&amp;quot;mlr3&amp;quot;) task = tsk(&amp;quot;iris&amp;quot;) learner = lrn(&amp;quot;classif.rpart&amp;quot;) # 为任务的一个子集（前120行）训练这个学习器的模型 learner$train(task, row_ids = 1:120) # 决策树模型 learner$model ## n= 120 ## ## node), split, n, loss, yval, (yprob) ## * denotes terminal node ## ## 1) root 120 70 setosa (0.41666667 0.41666667 0.16666667) ## 2) Petal.Length&amp;lt; 2.45 50 0 setosa (1.00000000 0.00000000 0.00000000) * ## 3) Petal.Length&amp;gt;=2.45 70 20 versicolor (0.00000000 0.71428571 0.28571429) ## 6) Petal.</description>
    </item>
    
    <item>
      <title>PR曲线与AUC</title>
      <link>/blog/pr-curve-and-auc-value/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/pr-curve-and-auc-value/</guid>
      <description>这里直接使用ROCR包提供的数据作为示例：
library(ROCR) data(ROCR.simple) pred &amp;lt;- prediction(ROCR.simple$predictions, ROCR.simple$labels) perf &amp;lt;- performance(pred,&amp;quot;tpr&amp;quot;,&amp;quot;fpr&amp;quot;) plot(perf) ## precision/recall curve (x-axis: recall, y-axis: precision) perf1 &amp;lt;- performance(pred, &amp;quot;prec&amp;quot;, &amp;quot;rec&amp;quot;) plot(perf1, xlim = c(0, 1), ylim = c(0, 1)) 使用 PRROC 包获取PR AUC值并且绘图：
pr &amp;lt;- PRROC::pr.curve(ROCR.simple$predictions, weights.class0 = ROCR.simple$labels, curve = TRUE) pr ## ## Precision-recall curve ## ## Area under curve (Integral): ## 0.7815038 ## ## Area under curve (Davis &amp;amp; Goadrich): ## 0.7814246 ## ## Curve for scores from 0.</description>
    </item>
    
    <item>
      <title>《R语言数据科学导论》笔记</title>
      <link>/blog/note-for-r-data-science-intro/</link>
      <pubDate>Mon, 30 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/note-for-r-data-science-intro/</guid>
      <description>原始资料来源：https://github.com/leovan/data-science-introduction-with-r
特征工程 特征工程是将原始数据转换成特征的过程。更通俗地说，特征工程就是人工设计模型的输入变量 x的过程。
主要分为：
 数据预处理 特征提取和选择 特征变换和编码 特征监控  数据预处理 对赃数据进行清洗，包括括缺失，噪声，不一致等等一系列问题数据。
剔除处理：
 样本去重。同一个ID出现多次重复记录。 特征去重。例如月收入和年收入，它们都是用于表征收入特征，关系只差常数倍。 常量特征剔除。即常量或方差近似为0的特征。caret包中的nearZeroVar()可以帮助我们识别该类特征。  缺失值处理：
 探索缺失值：mice包的md.pattern()，VIM包的aggr()/marginplot()。 处理：  删除法，可以直接使用na.omit()。 插补法，如果该特征对最终的预测结果影响较小，则我们可以直接删除该特征；相反如果该特征对预测结果影响较大，直接删除会对模型造成较大的影 响，此时我们需要利用其它的方法对该特征的缺失值进行填补。其中最简单的方式是利用均值，中位数或众数等统计量对其进行简单插补。这种插补方法是建立在完全随机缺失的前提假设下，同时会造成变量方差变小。    异常值是指样本中存在的同样本整体差异较大的数据。
分为2类：
采样是一种常见的预处理技术。
 随机采样。每个样本单位被抽中的概率相等，样本的每个单位完全独立，彼此间无一定的关联性和排斥性。 分层采样。将抽样单位按某种特征或某种规则划分为不同的层，然后从不同的层中独立、随机地抽取样本。从而保证样本的结构与总体的结构比较相近，从而提高估计的精度。可以利用sampling::strata()。 欠采样和过采样。我们经常会碰到不同分类的样本比例相差较大的问题，这种问题会对我们构建模型造成很大的影响，因此从数据角度出发，我们可以利用欠采样或过采样处理这种现象。可以利用ROSE::ovun.sample()。  特征变换和编码 无量纲化 通过归一化，我们可以消除不同量纲下的数据对最终结果的影响。
normalize &amp;lt;- function(x) { # 计算极值 x_min &amp;lt;- min(x) x_max &amp;lt;- max(x) # 归一化 x_n &amp;lt;- (x - x_min) / (x_max - x_min) # 将极值作为结果的属性 attr(x_n, &amp;#39;min&amp;#39;) &amp;lt;- x_min attr(x_n, &amp;#39;max&amp;#39;) &amp;lt;- x_max # 返回归一化后结果 x_n } 标准化。</description>
    </item>
    
  </channel>
</rss>
