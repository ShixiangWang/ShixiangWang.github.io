<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>stats on ShixiangWang
王诗翔</title>
    <link>/tags/stats/</link>
    <description>Recent content in stats on ShixiangWang
王诗翔</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 04 Nov 2021 00:00:00 +0000</lastBuildDate><atom:link href="/tags/stats/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>读《指北》：多重假设检验记录与思考</title>
      <link>/blog/multiple-stats-testing-and-thinking/</link>
      <pubDate>Thu, 04 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/multiple-stats-testing-and-thinking/</guid>
      <description>本文有记录和思考2个方面，记录是根据《现代科研指北》的统计推断的一部分内容进行记录和学习，思考是在记录和学习的过程中添加一些自己的理解和思索。
首先谈谈为什么是这样的形式，而不是直接转载。对于个人而言，学习的本质是为了掌握知识，而不是记录知识。本文的主题是统计分析特别是组学统计分析中常用却甚少思考的一个基本点：多重比较与假设检验。我不知道有多少人像我一样，在有几年的数据处理经验之后，对这种比较基础的理论还一知半解。 现在，我们可以轻而易举的使用R的p.adj()对p值进行校正，甚至使用 Bioconductor的一些专门的包（如qvalue）进行处理。但我们真的了解它吗？你能简单地说出p.adj()中提供的方法原理和区别吗？如果你的目标是数据分析师，完成工作任务，仅仅作为赚钱养家的技能。ok，没必要深入学习，会调包调函数完全足够了。但如果我们有更高的追求，比如数据科学家， 无论是工业界还是学术界，那么我们必须对概念和问题产生自己的见解。
下面是《指北》中的一些内容。
多重比较的场景 科研里最常用的比较是两独立样本均值比较的t检验与评价单因素多水平影响的方差分析。t检验可以看作方差分析的特例，使用统计量t来比较而方差分析通常是用分类变量所解释的变异比上分类变量以外的变异去进行F检验。换句话讲，如果分类变量可以解释大部分响应变量的变异，我们就说这种分类变量对响应变量的解释有意义。
但是仅仅知道是否受影响是不够的，我们知道的仅仅是存在一种分类方法可以解释响应的全部变化，其内部也是均匀的，但不同分类水平间的差异我们并不知道，这就需要多重比较了。例如，当我们对两组数据做置信度0.05的t检验，我们遇到假阳性的概率为5%。但如果面对多组数据例如3组，进行两两比较的话就有\(3\choose2\)也就是3组对比，那么我们遇到假阳性的概率就为\(1-(1-0.05)^3\)，也就是14.3%，远高于0.05的置信度。组越多，两两对比就越多，整体上假阳性的概率就越来越大，到最后就是两组数据去对比，无论如何你都会检验出差异。
 值得思考的一个点是：这里一般提出的比较是多组，如A、B、C这3个组比较同一个指标的差异。而在组学分析中的比较是固定的A、B这2个组不同的指标的比较。它们能看作一样的事情吗？
  本质上是一样的，关键在对比的数量。我们可以把比较拆开为独立的1对1的比较。那么比较一次假设出现错误的概率是0.05，那么比对的数量越多，整体上的分析结果中出现一次错误的概率会越大于0.05。
 此外就方向而样，虽然我们都不承认零假设（要不然还做什么实验），但当我们默认设定为双尾检验时，假阳性就被默认发生在两个方向上了，这样的多重比较必然导致在其中一个方向上的错误率被夸大了。就影响大小而言，如果我们每次重复都选择效应最强的那一组，重复越多，预设的偏态就越重，换言之，我们的零假设因为重复实验的选择偏好而发生了改变。
 多重比较 那么多重比较如何应对这个问题呢？有两种思路，一种思路是我依旧采取两两对比，进行t检验，但p值的选取方法要修改，例如Bonferroni方法中就把p的阈值调整为进行多重比较的次数乘以计算得到的p值。如果我们关心的因素为2，那么计算得到的p值都要乘2来跟0.05或0.01的边界置信度进行比较；另一种思路则是修改两两比较所用的统计量，给出一个更保守的分布，那么得到p值就会更大。不论怎样，我们这样做都是为了降低假阳性，但同时功效不可避免的降低了。（有得必有失）
多重比较的方法类型包括单步法与逐步法。 单步法只考虑对零假设的影响而不考虑其他影响而逐步法则会考虑其他假设检验对单一检验的影响，例如可以先按不同分组均值差异从大到小排序，先对比第一个，有差异对比下一个，当出现无差异时停止对比；或者从下到大排序，有差异时停止对比，之后均认为有差异。此时还要注意一种特殊情况，因为F检验是从方差角度来考虑影响显著性与否，所以可能存在F检验显著但组间均值差异均不显著的情况，此时要考虑均值间线性组合的新均值的差异性（？？？）。不过，大多数情况我们只用考虑不同组间两两差异比较即可。
具体而言，单步法等方差多重比较最常见的是Tukey’s HSD方法，这是一个两两比较的方法，基于 studentized range 分布计算出q统计量，然后基于这个统计量进行两两间差异的假设检验。该方法适用于分组间等方差等数目的场景，如果分组内数目不同，需要用 Tukey-Kranmer 方法。该方法适用于两两比较，在分组数目相同时统计功效等同于从大到小排序的逐步法。
此外，还有些多重比较的方法在特定学科里也很常见。从总体控制错误率的角度，如果是两两比较应该选 Tukey’s HSD方法；如果侧重组间差异线性组合的均值用 Scheffe test；如果对比数指定了，功效按 Gabriel、GT2、DST、 Bonferroni顺序来选；如果是各分组都跟控制组比，应该选Dunnett法；如果各分组方差不相等，用GH，C，T3等方法。此外，如果打算保证每个比较中的置信水平，应该选 Tukey、 Scheffe、Dunnett法。
 远比想象中要复杂。
  多重检验 与多重比较类似的一个统计推断问题是多重检验问题。多重检验指的是同时进行多次假设检验的场景，其实多重比较可以看作多重检验在方差分析里的一个特例。
举例而言，我对两组样品（暴露组跟对照组）中每一个样品测定了10000个指标，每组有10个样品，那么如果我想知道差异有多大就需要对比10000次，具体说就是10000次双样本t检验。那么如果我对t检验的置信水平设置在95%，也就是5%假阳性，做完这10000次检验，我会期望看到500个假阳性，而这500个有显著差异的指标其实对分组不敏感也可以随机生成。假如真实测到了600个有显著差异的指标，那么如何区分其中哪些是对分组敏感？哪些又仅仅只是随机的呢？随机的会不会只有500个整呢？这个场景在组学技术与传感器技术采集高通量高维数据的今天变得越来越普遍。
这个问题在做经典科研实验时往往会忽略，深层次的原因是经典的科研实验往往是理论或经验主导需要进行检验的假说（注：经典实验比较的数目量也上不去）。例如，我测定血液中白血球的数目就可以知道你是不是处于炎症中，其背后是医学知识的支撑。然而，在组学或其他高通量实验中，研究实际是数据导向的，也就是不管有用没用反正我测了一堆指标，然后就去对比差异，然后就是上面的问题了，我们可能分不清楚哪些是真的相关，哪些又是随机出现的。
对于单次比较，当我们看到显著差异的p值脑子里想的是零假设为真时发生的概率，当我们置信水平设定在0.95而p值低于对应的阈值，那么我们应该拒绝零假设。但对比次数多了从概率上就会出现已经被拒绝的假设实际是错误的而你不知道是哪一个。整体错误率控制的思路就是我不管单次比较了，我只对你这所有的对比次数的总错误率进行控制。还是上面的例子，对于10000次假设检验我只能接受1个错误，整体犯错概率为0.0001，那么对于单次比较，其假阳性也得设定在这个水平上去进行假设检验，结果整体上错误率是控制住了，但对于单次比较就显得十分严格了。下面用一个仿真实验来说明：
# 随机数的10000次比较 set.seed(42) pvalue &amp;lt;- NULL for (i in 1:10000){ a &amp;lt;- rnorm(10) b &amp;lt;- rnorm(10) c &amp;lt;- t.test(a,b) pvalue[i] &amp;lt;- c$p.value } # 看下p值分布 hist(pvalue) # 小于0.</description>
    </item>
    
    <item>
      <title>rstatix使用fisher检验处理比例关系</title>
      <link>/blog/rstatix-fisher-test/</link>
      <pubDate>Tue, 19 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/rstatix-fisher-test/</guid>
      <description>Fisher检验R默认就可以做，但是只支持一次检验，为了更好地处理数据，这篇文章通过rstatix包的相关功能来 学习一些新知识。
library(rstatix)  本文的相关代码文档可以运行?rstatix::fisher_test()查看。
 比较2个比例值 生成数据：
xtab &amp;lt;- as.table(rbind(c(490, 10), c(400, 100))) dimnames(xtab) &amp;lt;- list( group = c(&amp;quot;grp1&amp;quot;, &amp;quot;grp2&amp;quot;), smoker = c(&amp;quot;yes&amp;quot;, &amp;quot;no&amp;quot;) ) xtab ## smoker ## group yes no ## grp1 490 10 ## grp2 400 100 进行比较：
fisher_test(xtab) ## # A tibble: 1 × 3 ## n p p.signif ## * &amp;lt;dbl&amp;gt; &amp;lt;dbl&amp;gt; &amp;lt;chr&amp;gt; ## 1 1000 8.77e-22 **** # 给出更多的比较信息 fisher_test(xtab, detailed = TRUE) ## # A tibble: 1 × 8 ## n estimate p conf.</description>
    </item>
    
  </channel>
</rss>
