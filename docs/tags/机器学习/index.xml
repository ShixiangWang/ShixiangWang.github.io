<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>机器学习 on ShixiangWang
(王诗翔)</title>
    <link>/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/</link>
    <description>Recent content in 机器学习 on ShixiangWang
(王诗翔)</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>en-us</language>
    <lastBuildDate>Thu, 13 Jan 2022 00:00:00 +0000</lastBuildDate><atom:link href="/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>dials自定义grid示例</title>
      <link>/blog/dials-grid/</link>
      <pubDate>Thu, 13 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/dials-grid/</guid>
      <description>library(dials)library(dplyr)param_quant = function (label, range = c(10L, 1000L), type = &amp;quot;integer&amp;quot;, trans = NULL) {stopifnot(length(label) == 1L)names(label) = labelnew_quant_param(type = type, range = range, inclusive = c(TRUE, TRUE),trans = trans, label = label, finalize = NULL)}param_class = function (label, values) {stopifnot(length(label) == 1L)names(label) = labelnew_qual_param(type = &amp;quot;character&amp;quot;, values = values, label = label, finalize = NULL)}abc = grid_max_entropy(param_quant(&amp;quot;scale&amp;quot;),param_quant(&amp;quot;abc&amp;quot;, range = c(0, 1), trans = scales::log10_trans()),param_class(&amp;quot;gender&amp;quot;, c(&amp;quot;F&amp;quot;, &amp;quot;M&amp;quot;)),size = 100, original = FALSE)plot(abc$scale, abc$abc)</description>
    </item>
    
    <item>
      <title>通过tidymodels使用XGBOOST</title>
      <link>/blog/using-xgboost-with-tidymodels/</link>
      <pubDate>Thu, 06 Jan 2022 00:00:00 +0000</pubDate>
      
      <guid>/blog/using-xgboost-with-tidymodels/</guid>
      <description>原文：https://www.r-bloggers.com/2020/05/using-xgboost-with-tidymodels/
XGBoost是一个最初用C++编写的机器学习库，通过XGBoost R包中移植到R。在过去的几年里，XGBoost在Kaggle竞赛中的有效性让它大受欢迎。在Tychobra, XGBoost是我们的首选机器学习库。
在2016年和2017年，Kaggle被两种方法所主导:梯度升压机和深度学习。具体来说，梯度增强用于结构化数据可用的问题，而深度学习用于图像分类等感知问题。前者的实践者几乎总是使用优秀的XGBoost库。
Max Kuhn和Rstudio的其他人最近将他们的注意力从caret转向了 tidymodels （caret的继承者）。“tidymodels”是一个R包的集合，它们一起工作来简化和加强模型训练和优化。随着最近发布的tidymodels.org，我们觉得是时候给tidymodels R包一个机会了。
概览这篇文章中我们使用tidymodels包训练和优化XGBoost模型。我们使用的AmesHousing数据集，其中包含来自艾奥瓦州艾姆斯的住房数据。我们的模型将预测房屋销售价格。
加载包：
# datalibrary(AmesHousing)# data cleaninglibrary(janitor)# data preplibrary(dplyr)# tidymodelslibrary(rsample)library(recipes)library(parsnip)library(tune)library(dials)library(workflows)library(yardstick)# speed up computation with parrallel processing (optional)library(doParallel)all_cores &amp;lt;- parallel::detectCores(logical = FALSE)registerDoParallel(cores = all_cores)加载数据：
# set the random seed so we can reproduce any simulated results.set.seed(1234)# load the housing data and clean namesames_data &amp;lt;- make_ames() %&amp;gt;%janitor::clean_names()Step 0：探索性数据分析在这一点上，我们通常会对数据做一些简单的图表和总结，以获得对数据的高层次理解。为了简单起见，我们将从这篇文章中删除EDA过程，但是，在实际分析中，理解业务问题和执行有效的EDA通常是分析中最耗时和最关键的方面。</description>
    </item>
    
    <item>
      <title>Flux Overview：建立一个简单的预测</title>
      <link>/blog/flux-overview/</link>
      <pubDate>Fri, 31 Dec 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/flux-overview/</guid>
      <description>julia&amp;gt; using Flux julia&amp;gt; actual(x) = 4x + 2 actual (generic function with 1 method) 提供训练和测试集 julia&amp;gt; x_train, x_test = hcat(0:5...), hcat(6:10...) ([0 1 … 4 5], [6 7 … 9 10]) julia&amp;gt; y_train, y_test = actual.(x_train), actual.(x_test) ([2 6 … 18 22], [26 30 … 38 42]) 通常，你的训练和测试数据来自真实世界的观察，但这个函数将模拟真实世界的观察。
构建一个模型预测 julia&amp;gt; model = Dense(1, 1) Dense(1, 1) # 2 parameters julia&amp;gt; model.weight 1×1 Matrix{Float32}: -1.0924082 julia&amp;gt; model.bias 1-element Vector{Float32}: 0.0 在底层，一个全连接层是一个含有weight和bias的结构体。weight代表权重矩阵，bias代表偏置向量。 我们可以使用其他方式思考一个模型。在Flux中，模型是概念上的预测函数：</description>
    </item>
    
    <item>
      <title>autoxgboost例子</title>
      <link>/blog/autoxgboost-example/</link>
      <pubDate>Wed, 17 Nov 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/autoxgboost-example/</guid>
      <description>library(OpenML) library(autoxgboost) data = getOMLDataSet(31) GermanCredit = convertOMLDataSetToMlr(data) # reg_task &amp;lt;- makeRegrTask(data = data_train, target = &amp;#34;Share_Temporary&amp;#34;) # reg_task &amp;lt;- makeRegrTask(data = data_train, target = &amp;#34;Share_Temporary&amp;#34;) autoxgbparset.mixed = makeParamSet( makeDiscreteParam(&amp;#34;booster&amp;#34;, values = c(&amp;#34;gbtree&amp;#34;, &amp;#34;gblinear&amp;#34;, &amp;#34;dart&amp;#34;)), makeDiscreteParam(&amp;#34;sample_type&amp;#34;, values = c(&amp;#34;uniform&amp;#34;, &amp;#34;weighted&amp;#34;), requires = quote(booster == &amp;#34;dart&amp;#34;)), makeDiscreteParam(&amp;#34;normalize_type&amp;#34;, values = c(&amp;#34;tree&amp;#34;, &amp;#34;forest&amp;#34;), requires = quote(booster == &amp;#34;dart&amp;#34;)), makeNumericParam(&amp;#34;rate_drop&amp;#34;, lower = 0, upper = 1, requires = quote(booster == &amp;#34;dart&amp;#34;)), makeNumericParam(&amp;#34;skip_drop&amp;#34;, lower = 0, upper = 1, requires = quote(booster == &amp;#34;dart&amp;#34;)), makeLogicalParam(&amp;#34;one_drop&amp;#34;, requires = quote(booster == &amp;#34;dart&amp;#34;)), makeDiscreteParam(&amp;#34;grow_policy&amp;#34;, values = c(&amp;#34;depthwise&amp;#34;, &amp;#34;lossguide&amp;#34;)), makeIntegerParam(&amp;#34;max_leaves&amp;#34;, lower = 0, upper = 8, trafo = function(x) 2^x, requires = quote(grow_policy == &amp;#34;lossguide&amp;#34;)), makeIntegerParam(&amp;#34;max_bin&amp;#34;, lower = 2L, upper = 9, trafo = function(x) 2^x), makeNumericParam(&amp;#34;eta&amp;#34;, lower = 0.</description>
    </item>
    
    <item>
      <title>机器学习分类性能常用一些指标</title>
      <link>/blog/measures-for-classification-in-ml/</link>
      <pubDate>Sun, 31 Oct 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/measures-for-classification-in-ml/</guid>
      <description>这篇文章的目的主要是记录一些分类器相关的度量指标。 从混淆矩阵中衍生出来的指标特别多，而我们中文与英文可能又存在多种对应 关系，这造成了记忆和理解上的困难。
 来源：https://zhuanlan.zhihu.com/p/111274912
 灵敏度与特异性 灵敏度 灵敏度（sensitivity），又称真阳性率，即实际有病，并且按照该诊断试验的标准被正确地判为有病的百分比。它反映了诊断试验发现病人的能力。
该研究中，根据手术病理结果有100例乳腺癌患者，但胸部扪诊只检测出其中80例患者。这说明该诊断试验只能发现80%的病人。
特异性 特异度（specificity），又称真阴性率，即实际没病，同时被诊断试验正确地判为无病的百分比。它反映了诊断试验确定非病人的能力。
例如有900例不是乳腺癌患者，但胸部扪诊只识别了其中的800例。特异性为89%。
比较 如果一项诊断试验的灵敏度比较低，那么会出现很多假阴性的患者。这会延误患者的就诊，影响病程发展和愈后，甚至导致患者过早死亡。
如果一项诊断试验的特异度比较低，那么会出现很多假阳性的患者。这样会浪费医疗资源、造成患者无端的恐慌和焦虑。
这两个指标主要可以通过ROC曲线同时查看。
 本节参考：https://www.mediecogroup.com/zhuanlan/lessons/229/  精度与召回率 首先需要说明的是这两者类似于ROC曲线，可以通过PR曲线同时进行观测。
精度 精度，precision。预测所关注的事件的结果中，预测正确的概率（共预测了 20 次，8 次正确，12 次错误）。
与Accuracy的区别：Accuracy不管正负类，算全部预测正确占总数的比率。而精度关注 预测正确的正类数目占全部正类数目的比率。
召回率/查全率 recall。对所有所关注的类型（一般就是正类），将其预测出的概率（共 10 个癌症患者，预测出 8 个）。
 本节参考：https://www.jianshu.com/p/dcf4deddff9f  </description>
    </item>
    
    <item>
      <title>处理glm.fit: fitted probabilities numerically 0 or 1 occurred</title>
      <link>/blog/process-glm-logistic-warning/</link>
      <pubDate>Sun, 26 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/process-glm-logistic-warning/</guid>
      <description>原文：https://www.statology.org/glm-fit-fitted-probabilities-numerically-0-or-1-occurred/
 在建立逻辑回归模型时遇到这个警告：
Warning message: glm.fit: fitted probabilities numerically 0 or 1 occurred 当拟合逻辑回归模型，且数据框中一个或多个观测值的预测概率与0或1难以区分时，会出现此警告。
值得注意的是，这是一个警告消息，而不是一个错误。即使你收到这个错误，你的逻辑回归模型仍然是合适的，但是可能值得分析原始数据框，看看是否有任何异常值导致此警告消息出现。
本教程将分享如何在实践中处理此警告消息。
重复警告 假设我们将logistic回归模型拟合到R中的以下数据框：
#create data frame df &amp;lt;- data.frame(y = c(0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1), x1 = c(3, 3, 4, 4, 3, 2, 5, 8, 9, 9, 9, 8, 9, 9, 9), x2 = c(8, 7, 7, 6, 5, 6, 5, 2, 2, 3, 4, 3, 7, 4, 4)) #fit logistic regression model model &amp;lt;- glm(y ~ x1 + x2, data=df, family=binomial) #view model summary summary(model) Warning message: glm.</description>
    </item>
    
    <item>
      <title>mlr3（三）模型优化</title>
      <link>/blog/mlr3-model-optimization/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-model-optimization/</guid>
      <description>来源：https://mlr3book.mlr-org.com/optimization.html
模型优化
机器学习算法为其超参数设置了默认值。不管怎样，用户需要更改这些超参数，以在给定的数据集上实现最佳性能。不建议手动选择超参数值，因为这种方法很少能获得最佳性能。为了证实所选超参数（=调优）的有效性，建议进行数据驱动的优化。为了优化机器学习算法，必须指定（1）搜索空间，（2）优化算法(又称调优方法)，（3）评估方法，即重采样策略，（4）性能度量。
总而言之，关于调优的小节介绍：
进行经验超参数选择选择优化算法简洁地指定搜索空间触发调优自动调优本小节还需要包mlr3tuning，这是一个支持超参数调优的扩展包。
特征选择
本章的第二部分介绍特征选择，也称为变量选择。特征选择是寻找数据相关特征子集的过程。执行选择的一些原因：
增强模型的可解释性加速模型拟合通过降低数据中的噪声来提高学习性能在本文中，我们主要集中在最后一个方面。有不同的方法来识别相关的特征。在特征选择的分章中，我们强调了三种方法：
运用过滤算法根据分数独立地选择特征根据变量重要性过滤选择特征包装器方法迭代地选择特性以优化性能度量注意，过滤器不需要学习器。变量重要性过滤器需要一个学习器，该学习器在训练时可以计算特征的重要性值。获得的重要值可用于数据子集，然后可用于训练学习器。包装器方法可以用于任何学习器，但需要对学习器进行多次训练。
嵌套重采样
为了更好地估计泛化性能并避免数据泄漏，外部（性能）和内部（调优/特征选择）重采样过程都是必要的。本章将讨论以下特点：
嵌套重采样中的内重采样和外重采样策略嵌套重采样的执行执行重采样迭代的评估本小节将提供如何实现嵌套重采样的说明，包括mlr3中的内重采样和外重采样。
超参数调优超参数是机器学习模型的二阶参数，虽然在模型估计过程中往往没有明确优化，但会对模型的结果和预测性能产生重要影响。通常，超参数在训练模型之前是固定的。但是，由于模型的输出可能对超参数的规范很敏感，因此通常建议对哪些超参数设置可以产生更好的模型性能做出明智的决定。在许多情况下，超参数设置可能是预先选择的，但在将模型拟合到训练数据上之前，尝试不同的设置可能是有利的。这个过程通常被称为模型“调优”。
超参数调优是通过mlr3tuning扩展包支持的。下面是这个过程的说明：
mlr3tuning的核心是R6类：
TuningInstanceSingleCrit，TuningInstanceMultiCrit：这两个类描述调优问题并存储结果。
Tuner：这个类是调优算法实现的基类。
TuningInstance* 类下面的小节审查了皮马印度糖尿病数据集上的简单分类树的优化。
library(&amp;quot;mlr3verse&amp;quot;)task = tsk(&amp;quot;pima&amp;quot;)print(task)## &amp;lt;TaskClassif:pima&amp;gt; (768 x 9)## * Target: diabetes## * Properties: twoclass## * Features (8):## - dbl (8): age, glucose, insulin, mass, pedigree, pregnant, pressure,## triceps我们使用rpart中的分类树，并选择我们想要调优的超参数的子集。这通常被称为“调优空间”。</description>
    </item>
    
    <item>
      <title>mlr3（二）基础</title>
      <link>/blog/mlr3-basics/</link>
      <pubDate>Wed, 01 Sep 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-basics/</guid>
      <description>来源：https://mlr3book.mlr-org.com/basics.html
本文将教你基本的mlr3知识，以及它的R6类和操作以用于机器学习。典型的机器学习工作流是这样的:
Figure 1: 机器学习流程 source: https://mlr3book.mlr-org.com/images/ml_abstraction.svgmlr3将数据封装在任务中，并将其分解为互不重叠的训练集和测试集。由于我们感兴趣的模型外推到新的数据，而不仅仅是记忆训练数据，独立的测试数据允许客观地评估模型的泛化。训练数据被提供给一个机器学习算法，在mlr3中我们称之为learner。learner利用训练数据建立输入特征与输出目标值之间关系的模型。然后使用该模型对测试数据进行预测，并将其与参考真值进行比较，以评估模型的质量。mlr3提供了许多不同的度量方法，根据预测值和实际值之间的差异来量化模型的执行情况。通常这是一个数字分数。
将数据分割为训练集和测试集、建立模型并对其进行评估的过程可能会重复多次，每次从原始数据中重新采样不同的训练集和测试集。多重重采样迭代允许我们对特定类型的模型获得更好、更一般化的性能估计，因为它是在不同的条件下测试的，而且由于数据重采样的特定方式，它不太容易产生偏差。
在许多情况下，这个简单的工作流不足以处理真实世界的数据，可能需要规范化（标准化）、缺失值的输入或特征选择。我们将在以后介绍更复杂的工作流程。
本文涵盖以下小主题：
任务：
任务用元信息封装数据，比如预测目标列的名称。我们将介绍如何：
访问预定义的任务指定一个任务类型创建一个任务使用任务的API工作为任务的行和列分配角色实施任务mutator获取存储在任务中的数据学习器
学习器封装机器学习算法来训练模型并对任务进行预测。它们由R和其他包提供。我们将介绍如何：
访问随mlr3而来的分类和回归学习器集合，并检索特定的学习器访问学习器的超参数值集并修改它们如何修改和扩展学习器涵盖在补充高级技术部分。
训练和预测
关于训练和预测方法的部分说明了如何使用任务和学习器训练模型并对新数据集进行预测。特别地，我们将介绍如何：
正确设置任务和学习器为一项任务设置训练和测试分割（集）在训练集上训练学习器以生成模型生成测试集的预测通过比较预测值和实际值来评估模型的性能重采样
重采样是一种创建训练和测试分割（集）的方法。我们将介绍：
访问和选择重采样策略通过应用重采样实例化分割到训练集和测试集执行重采样以获得结果关于重采样的附加信息可以在嵌套重采样部分和模型优化一章中找到。
基准测试
基准测试用于比较不同模型的性能，例如不同学习器训练的模型，不同任务训练的模型，或不同重采样方法训练的模型。我们介绍如何
创建一个基准设计执行设计并汇总结果将基准测试对象转换为重采样对象二分类
二值分类是分类的一种特殊情况，预测的目标变量只有两个可能的值。在这种情况下，还需要考虑其他因素。特别是：
ROC曲线和预测一个类和另一个类的阈值阈值调整在详细介绍如何使用mlr3进行机器学习之前，我们先简要介绍一下R6，因为它是R相对较新的一部分。mlr3严重依赖于R6，它提供的所有基本构造都是R6类：
任务 task学习器 learner测量 measure重采样 resamplings快速R6入门介绍R6是R最新的面向对象编程(OO)方言之一。它解决了R中早期OO实现的缺点，比如我们在mlr中使用的S3。如果你以前做过面向对象编程，那么R6应该很熟悉。我们关注的是R6的部分，你需要知道在这里使用mlr3。</description>
    </item>
    
    <item>
      <title>mlr3（一）快速入门</title>
      <link>/blog/mlr3-quickstart/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/mlr3-quickstart/</guid>
      <description>来源：https://mlr3book.mlr-org.com/quickstart.html
安装包：
install.packages(&amp;quot;mlr3&amp;quot;)作为一个30秒的介绍性示例，我们将在虹膜数据集的前120行训练决策树模型，并对最后30行进行预测，测量训练模型的准确性。
library(&amp;quot;mlr3&amp;quot;)task = tsk(&amp;quot;iris&amp;quot;)learner = lrn(&amp;quot;classif.rpart&amp;quot;)# 为任务的一个子集（前120行）训练这个学习器的模型learner$train(task, row_ids = 1:120)# 决策树模型learner$model## n= 120 ## ## node), split, n, loss, yval, (yprob)## * denotes terminal node## ## 1) root 120 70 setosa (0.41666667 0.41666667 0.16666667) ## 2) Petal.Length&amp;lt; 2.45 50 0 setosa (1.00000000 0.00000000 0.00000000) *## 3) Petal.Length&amp;gt;=2.45 70 20 versicolor (0.00000000 0.71428571 0.28571429) ## 6) Petal.</description>
    </item>
    
    <item>
      <title>PR曲线与AUC</title>
      <link>/blog/pr-curve-and-auc-value/</link>
      <pubDate>Tue, 31 Aug 2021 00:00:00 +0000</pubDate>
      
      <guid>/blog/pr-curve-and-auc-value/</guid>
      <description>这里直接使用ROCR包提供的数据作为示例：
library(ROCR)data(ROCR.simple)pred &amp;lt;- prediction(ROCR.simple$predictions, ROCR.simple$labels)perf &amp;lt;- performance(pred,&amp;quot;tpr&amp;quot;,&amp;quot;fpr&amp;quot;)plot(perf)## precision/recall curve (x-axis: recall, y-axis: precision)perf1 &amp;lt;- performance(pred, &amp;quot;prec&amp;quot;, &amp;quot;rec&amp;quot;)plot(perf1, xlim = c(0, 1), ylim = c(0, 1))使用 PRROC 包获取PR AUC值并且绘图：
pr &amp;lt;- PRROC::pr.curve(ROCR.simple$predictions, weights.class0 = ROCR.simple$labels, curve = TRUE)pr## ## Precision-recall curve## ## Area under curve (Integral):## 0.7815038 ## ## Area under curve (Davis &amp;amp; Goadrich):## 0.7814246 ## ## Curve for scores from 0.</description>
    </item>
    
  </channel>
</rss>
